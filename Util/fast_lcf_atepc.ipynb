{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pyabsa import ATEPCCheckpointManager\n",
    "import torch\n",
    "import psutil\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_memory_status():\n",
    "    # GPU 메모리 상태\n",
    "    gpu = GPUtil.getGPUs()[0]  # 첫 번째 GPU 정보 가져오기\n",
    "    print(f\"\\n=== GPU 메모리 상태 ===\")\n",
    "    print(f\"GPU 메모리 사용량: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB\")\n",
    "    print(f\"GPU 메모리 사용률: {gpu.memoryUtil*100:.1f}%\")\n",
    "    print(f\"GPU 온도: {gpu.temperature}°C\")\n",
    "\n",
    "    # PyTorch 메모리 상태\n",
    "    print(f\"\\n=== PyTorch 메모리 상태 ===\")\n",
    "    print(f\"할당된 메모리: {torch.cuda.memory_allocated()/1024**2:.1f}MB\")\n",
    "    print(f\"캐시된 메모리: {torch.cuda.memory_reserved()/1024**2:.1f}MB\")\n",
    "\n",
    "    # 시스템 메모리 상태\n",
    "    print(f\"\\n=== 시스템 메모리 상태 ===\")\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(\n",
    "        f\"시스템 메모리 사용량: {memory.used/1024**2:.1f}MB / {memory.total/1024**2:.1f}MB\"\n",
    "    )\n",
    "    print(f\"시스템 메모리 사용률: {memory.percent}%\")\n",
    "\n",
    "\n",
    "# === 모델 로드 ===\n",
    "aspect_extractor = ATEPCCheckpointManager.get_aspect_extractor(checkpoint=\"english\")\n",
    "print(\"\\n=== 모델 로드 후 메모리 상태 ===\")\n",
    "print_memory_status()\n",
    "\n",
    "# === 파일 경로 ===\n",
    "input_file = \"review_5up.json\"\n",
    "output_file = \"absa_atepc_results.jsonl\"\n",
    "\n",
    "# === 버퍼 및 설정 ===\n",
    "buffer = []\n",
    "save_every = 1000\n",
    "batch_size = 128\n",
    "count = 0\n",
    "\n",
    "# === 중복 방지: 이미 처리한 리뷰 불러오기 ===\n",
    "done_texts = set()\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                done_texts.add(item[\"text\"])\n",
    "            except:\n",
    "                continue\n",
    "    print(f\"\\n=== 처리 현황 ===\")\n",
    "    print(f\"이미 처리된 리뷰 수: {len(done_texts)}개\")\n",
    "    print(f\"이제부터 새로운 리뷰를 처리합니다.\")\n",
    "\n",
    "# === 리뷰 분석 + 중간 저장 ===\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "    # 전체 리뷰 수 계산\n",
    "    total_reviews = sum(1 for _ in f_in)\n",
    "    f_in.seek(0)  # 파일 포인터를 다시 처음으로\n",
    "\n",
    "    batch_texts = []\n",
    "    batch_items = []\n",
    "\n",
    "    for line in tqdm(f_in, desc=\"ABSA 추론 중\"):\n",
    "        try:\n",
    "            item = json.loads(line)\n",
    "            text = item[\"text\"]\n",
    "\n",
    "            if text in done_texts:\n",
    "                continue\n",
    "\n",
    "            batch_texts.append(text)\n",
    "            batch_items.append(item)\n",
    "\n",
    "            # 배치 크기에 도달하면 처리\n",
    "            if len(batch_texts) >= batch_size:\n",
    "                # # numpy 배열을 미리 변환하여 tensor 생성 속도 개선\n",
    "                # batch_texts = np.array(batch_texts)\n",
    "\n",
    "                # 배치 처리\n",
    "                results = aspect_extractor.extract_aspect(\n",
    "                    inference_source=batch_texts,\n",
    "                    print_result=False,\n",
    "                    pred_sentiment=True,\n",
    "                    save_result=False,\n",
    "                )\n",
    "\n",
    "                # 결과 처리\n",
    "                for item, result in zip(batch_items, results):\n",
    "                    final_result = {\n",
    "                        \"review_id\": item.get(\"review_id\"),\n",
    "                        \"user_id\": item.get(\"user_id\"),\n",
    "                        \"business_id\": item.get(\"business_id\"),\n",
    "                        \"text\": item[\"text\"],\n",
    "                        \"aspects\": [\n",
    "                            {\"term\": t, \"sentiment\": s}\n",
    "                            for t, s in zip(result[\"aspect\"], result[\"sentiment\"])\n",
    "                        ],\n",
    "                    }\n",
    "                    buffer.append(final_result)\n",
    "                    count += 1\n",
    "\n",
    "                # 중간 저장\n",
    "                if len(buffer) >= save_every:\n",
    "                    with open(output_file, \"a\", encoding=\"utf-8\") as f_out:\n",
    "                        for r in buffer:\n",
    "                            f_out.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "                    buffer = []\n",
    "\n",
    "                    # 진행 상황 출력\n",
    "                    print(f\"\\n=== 처리 현황 ===\")\n",
    "                    print(f\"처리된 리뷰: {count}개\")\n",
    "                    print(f\"남은 리뷰: {total_reviews - count}개\")\n",
    "                    print(f\"전체 진행률: {(count/total_reviews)*100:.1f}%\")\n",
    "\n",
    "                    # 500개마다 메모리 상태 출력\n",
    "                    print(f\"\\n=== {count}개 처리 후 메모리 상태 ===\")\n",
    "                    print_memory_status()\n",
    "\n",
    "                # 배치 초기화\n",
    "                batch_texts = []\n",
    "                batch_items = []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"에러 발생: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # 남은 배치 처리\n",
    "    if batch_texts:\n",
    "        results = aspect_extractor.extract_aspect(\n",
    "            inference_source=batch_texts,\n",
    "            print_result=False,\n",
    "            pred_sentiment=True,\n",
    "            save_result=False,\n",
    "        )\n",
    "\n",
    "        for item, result in zip(batch_items, results):\n",
    "            final_result = {\n",
    "                \"review_id\": item.get(\"review_id\"),\n",
    "                \"user_id\": item.get(\"user_id\"),\n",
    "                \"business_id\": item.get(\"business_id\"),\n",
    "                \"text\": item[\"text\"],\n",
    "                \"aspects\": [\n",
    "                    {\"term\": t, \"sentiment\": s}\n",
    "                    for t, s in zip(result[\"aspect\"], result[\"sentiment\"])\n",
    "                ],\n",
    "            }\n",
    "            buffer.append(final_result)\n",
    "            count += 1\n",
    "\n",
    "# === 마지막 남은 버퍼 저장 ===\n",
    "if buffer:\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f_out:\n",
    "        for r in buffer:\n",
    "            f_out.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"\\n=== 최종 메모리 상태 ===\")\n",
    "print_memory_status()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
