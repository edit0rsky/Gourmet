{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import psutil\n",
    "import GPUtil\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "# 메모리 상태 출력 함수\n",
    "def print_memory_status():\n",
    "    try:\n",
    "        # GPU 메모리 상태\n",
    "        if torch.cuda.is_available():\n",
    "            gpu = GPUtil.getGPUs()[0]  # 첫 번째 GPU 정보 가져오기\n",
    "            print(f\"\\n=== GPU 메모리 상태 ===\")\n",
    "            print(f\"GPU 메모리 사용량: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB\")\n",
    "            print(f\"GPU 메모리 사용률: {gpu.memoryUtil*100:.1f}%\")\n",
    "            print(f\"GPU 온도: {gpu.temperature}°C\")\n",
    "\n",
    "            # PyTorch 메모리 상태\n",
    "            print(f\"\\n=== PyTorch 메모리 상태 ===\")\n",
    "            print(f\"할당된 메모리: {torch.cuda.memory_allocated()/1024**2:.1f}MB\")\n",
    "            print(f\"캐시된 메모리: {torch.cuda.memory_reserved()/1024**2:.1f}MB\")\n",
    "\n",
    "        # 시스템 메모리 상태\n",
    "        print(f\"\\n=== 시스템 메모리 상태 ===\")\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(\n",
    "            f\"시스템 메모리 사용량: {memory.used/1024**2:.1f}MB / {memory.total/1024**2:.1f}MB\"\n",
    "        )\n",
    "        print(f\"시스템 메모리 사용률: {memory.percent}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"메모리 상태 확인 중 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 중인 장치: {device}\")\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n=== 모델 로드 후 메모리 상태 ===\")\n",
    "print_memory_status()\n",
    "\n",
    "# 분석할 측면\n",
    "aspects = [\"food\", \"service\", \"price\", \"ambience\", \"location\"]\n",
    "\n",
    "\n",
    "# 감정 분석 수행\n",
    "def analyze_sentiment(text, aspect):\n",
    "    try:\n",
    "        # 토큰화 (max_length 제거)\n",
    "        inputs = tokenizer(text, aspect, return_tensors=\"pt\")\n",
    "        # 입력 텐서를 GPU로 이동\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # 모델 실행\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)[0]\n",
    "\n",
    "        # 각 감정 점수\n",
    "        sentiment_scores = {}\n",
    "        for i, label in model.config.id2label.items():\n",
    "            sentiment_scores[label] = float(\n",
    "                probs[i].item()\n",
    "            )  # JSON 직렬화를 위해 float로 변환\n",
    "\n",
    "        return {\"scores\": sentiment_scores, \"status\": \"success\"}\n",
    "    except Exception as e:\n",
    "        print(f\"감정 분석 중 오류 발생: {e} (텍스트: {text[:50]}...)\")\n",
    "        # null 값 반환 (계산에 반영되지 않게)\n",
    "        return {\"scores\": None, \"status\": \"error\", \"error_message\": str(e)}\n",
    "\n",
    "\n",
    "# 리뷰 처리 및 JSONL 형식으로 저장\n",
    "def process_reviews(input_file, output_file, batch_size=100, save_every=500):\n",
    "    # 이미 처리한 리뷰 ID 불러오기\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"기존 결과 파일 {output_file}에서 처리된 리뷰 ID 불러오는 중...\")\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    item = json.loads(line)\n",
    "                    processed_ids.add(item[\"review_id\"])\n",
    "                except:\n",
    "                    continue\n",
    "        print(f\"{len(processed_ids)}개의 처리된 리뷰 ID를 불러왔습니다.\")\n",
    "\n",
    "    # 배치 처리를 위한 변수\n",
    "    buffer = []\n",
    "    count = 0\n",
    "    skipped = 0\n",
    "\n",
    "    try:\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "            for line in tqdm.tqdm(f_in, desc=\"리뷰 처리 중\"):\n",
    "                try:\n",
    "                    line = line.strip()\n",
    "                    if not line:  # 빈 줄 무시\n",
    "                        continue\n",
    "\n",
    "                    review = json.loads(line)\n",
    "                    review_id = review[\"review_id\"]\n",
    "\n",
    "                    # 이미 처리한 리뷰는 건너뛰기\n",
    "                    if review_id in processed_ids:\n",
    "                        skipped += 1\n",
    "                        if skipped % 10000 == 0:\n",
    "                            print(f\"{skipped}개의 리뷰 건너뜀\")\n",
    "                        continue\n",
    "\n",
    "                    text = review[\"text\"]\n",
    "\n",
    "                    # 각 aspect별 감정 분석 결과\n",
    "                    sentiment_results = {}\n",
    "                    for aspect in aspects:\n",
    "                        sentiment_results[aspect] = analyze_sentiment(text, aspect)\n",
    "\n",
    "                    # 결과 저장\n",
    "                    result = {\n",
    "                        \"review_id\": review_id,\n",
    "                        \"text\": text,\n",
    "                        \"sentiment\": sentiment_results,\n",
    "                    }\n",
    "                    buffer.append(result)\n",
    "                    count += 1\n",
    "\n",
    "                    # 일정 개수마다 저장\n",
    "                    if len(buffer) >= save_every:\n",
    "                        # 파일에 추가 모드로 저장\n",
    "                        with open(output_file, \"a\", encoding=\"utf-8\") as f_out:\n",
    "                            for r in buffer:\n",
    "                                f_out.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                        print(f\"{count}개의 리뷰 처리 완료 ({skipped}개 건너뜀)\")\n",
    "                        print_memory_status()\n",
    "\n",
    "                        # 버퍼 초기화\n",
    "                        buffer = []\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"리뷰 처리 중 오류 발생: {e}\")\n",
    "                    continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"파일 처리 중 오류 발생: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # 남은 결과 저장\n",
    "        if buffer:\n",
    "            with open(output_file, \"a\", encoding=\"utf-8\") as f_out:\n",
    "                for r in buffer:\n",
    "                    f_out.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"총 {count}개의 리뷰 처리 완료 ({skipped}개 건너뜀)\")\n",
    "    print(f\"결과가 {output_file}에 저장되었습니다.\")\n",
    "    print(\"\\n=== 최종 메모리 상태 ===\")\n",
    "    print_memory_status()\n",
    "\n",
    "\n",
    "# 메인 실행 함수\n",
    "def main():\n",
    "    input_file = \"../dataset/merged_dataset.json\"\n",
    "    output_file = (\n",
    "        \"../dataset/review_5up_5aspect_3sentiment.jsonl\"  # JSONL 형식으로 변경\n",
    "    )\n",
    "\n",
    "    print(f\"리뷰 파일: {input_file}\")\n",
    "    print(f\"결과 파일: {output_file}\")\n",
    "\n",
    "    # 배치 단위로 처리\n",
    "    process_reviews(input_file, output_file, batch_size=100, save_every=500)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
