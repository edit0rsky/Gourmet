{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84f0b5-a586-4bc5-aae9-e76858b332d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# PyABSA 라이브러리 임포트 (Quickstart 예시 기반)\n",
    "from pyabsa import AspectTermExtraction as ATEPC, available_checkpoints # available_checkpoints도 함께 임포트합니다.\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return np.nan # 모든 y_true가 0인 경우 NaN 반환\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# 1단계: 데이터 로드 및 전처리\n",
    "print(\"--- 1단계: 데이터 로드 및 전처리 시작 ---\")\n",
    "try:\n",
    "    data = []\n",
    "    with open('review.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"'{len(df)}'개의 리뷰 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'review.json' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['business_idx'] = business_encoder.fit_transform(df['business_id'])\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"'{num_users}'명의 고유 사용자와 '{num_businesses}'개의 고유 레스토랑을 매핑했습니다.\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], unit='ms')\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "total_reviews = len(df)\n",
    "train_split = int(total_reviews * 0.7)\n",
    "val_split = int(total_reviews * (0.7 + 0.1))\n",
    "train_df = df.iloc[:train_split].copy()\n",
    "val_df = df.iloc[train_split:val_split].copy()\n",
    "test_df = df.iloc[val_split:].copy()\n",
    "print(f\"학습 세트 크기: {len(train_df)}개 리뷰\")\n",
    "print(f\"검증 세트 크기: {len(val_df)}개 리뷰\")\n",
    "print(f\"테스트 세트 크기: {len(test_df)}개 리뷰\")\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_indices = torch.tensor(df['user_idx'].values, dtype=torch.long)\n",
    "        self.business_indices = torch.tensor(df['business_idx'].values, dtype=torch.long)\n",
    "        self.review_texts = df['text'].values.tolist()\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_indices[idx], self.business_indices[idx], self.review_texts[idx], self.stars[idx]\n",
    "print(\"데이터 로드 및 전처리 완료.\")\n",
    "\n",
    "# 2단계: PyABSA ATE 모델 로드 및 동적 어휘집 구축\n",
    "print(\"\\n--- 2단계: PyABSA ATE 모델 로드 및 동적 어휘집 구축 시작 ---\")\n",
    "\n",
    "ate_extractor = None\n",
    "try:\n",
    "    # Quickstart 예시를 사용하여 ATEPC 모델 로드\n",
    "    # 'multilingual' 체크포인트를 사용하며, auto_device=True로 GPU/CPU 자동 감지\n",
    "    ate_extractor = ATEPC.AspectExtractor('multilingual', auto_device=True) # <-- 이 줄이 Quickstart 기반으로 수정되었습니다.\n",
    "    print(\"PyABSA ATEPC 모델 로더를 성공적으로 초기화했습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: PyABSA ATEPC 모델 로더 초기화 실패: {e}\")\n",
    "    print(\"PyABSA 설치를 확인하고, 시스템에 Git이 올바르게 설정되어 있는지 다시 확인해주세요.\")\n",
    "    print(\"모델 로드 실패 시, 속성 추출 모듈은 폴백(Fallback) 로직으로 동작합니다.\")\n",
    "    ate_extractor = None\n",
    "    \n",
    "train_review_texts = train_df['text'].values.tolist()\n",
    "print(\"\\n학습 데이터 리뷰 텍스트에서 속성 키워드 추출 중 (어휘집 구축을 위해)...\")\n",
    "all_extracted_aspect_terms_from_train = []\n",
    "if ate_extractor:\n",
    "    results = ate_extractor.predict(\n",
    "        train_review_texts,\n",
    "        print_result=False,\n",
    "        ignore_warnings=True\n",
    "    )\n",
    "    for result in results:\n",
    "        if 'aspect' in result and result['aspect']:\n",
    "            aspect_list = result['aspect'] if isinstance(result['aspect'], list) else [result['aspect']]\n",
    "            for term in aspect_list:\n",
    "                all_extracted_aspect_terms_from_train.append(term.lower())\n",
    "else:\n",
    "    print(\"경고: PyABSA ATE 모델이 로드되지 않아 동적 어휘집 구축이 제한됩니다.\")\n",
    "\n",
    "term_counts = Counter(all_extracted_aspect_terms_from_train)\n",
    "ASPECT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'general': 2}\n",
    "next_id = 3\n",
    "for term, count in term_counts.most_common():\n",
    "    if term not in ASPECT_TO_ID:\n",
    "        ASPECT_TO_ID[term] = next_id\n",
    "        next_id += 1\n",
    "if 'general' not in ASPECT_TO_ID:\n",
    "    ASPECT_TO_ID['general'] = next_id\n",
    "    next_id += 1\n",
    "NUM_ASPECT_TERMS = len(ASPECT_TO_ID)\n",
    "print(f\"동적으로 구축된 어휘집 크기 (학습 데이터 기반): {NUM_ASPECT_TERMS}개 키워드\")\n",
    "print(f\"어휘집 상위 10개 키워드: {list(ASPECT_TO_ID.items())[3:13]}...\")\n",
    "print(\"PyABSA 모델 로드 및 동적 어휘집 구축 완료 (학습 데이터 기반).\")\n",
    "\n",
    "# 3단계: AAT-Rec 모델 구성 요소 정의\n",
    "print(\"\\n--- 3단계: AAT-Rec 모델 구성 요소 정의 시작 ---\")\n",
    "\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "    def forward(self, user_indices, business_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        business_emb = self.business_embedding(business_indices)\n",
    "        combined_emb = torch.cat((user_emb, business_emb), dim=-1)\n",
    "        interaction_features = self.mlp(combined_emb)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectTermExtractionModule(nn.Module):\n",
    "    def __init__(self, num_aspect_terms, aspect_embedding_dim, num_heads, mlp_dims, ate_extractor_instance, aspect_to_id_map):\n",
    "        super(ReviewAspectTermExtractionModule, self).__init__()\n",
    "        self.ate_extractor = ate_extractor_instance\n",
    "        self.aspect_to_id = aspect_to_id_map\n",
    "        self.aspect_embedding = nn.Embedding(num_aspect_terms, aspect_embedding_dim, padding_idx=0)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=aspect_embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "        layers = []\n",
    "        input_dim = aspect_embedding_dim\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "    def forward(self, review_texts):\n",
    "        extracted_aspect_ids_batch = self._extract_aspect_terms_with_pyabsa(review_texts)\n",
    "        batch_aspect_features = []\n",
    "        for aspect_ids_for_review in extracted_aspect_ids_batch:\n",
    "            if not aspect_ids_for_review:\n",
    "                unk_aspect_id = self.aspect_to_id['<UNK>']\n",
    "                embedded_terms = self.aspect_embedding(\n",
    "                    torch.tensor([unk_aspect_id], dtype=torch.long).to(self.aspect_embedding.weight.device)\n",
    "                )\n",
    "                attn_output, _ = self.multihead_attn(\n",
    "                    embedded_terms.unsqueeze(0), embedded_terms.unsqueeze(0), embedded_terms.unsqueeze(0)\n",
    "                )\n",
    "                pooled_output = attn_output.squeeze(0)\n",
    "            else:\n",
    "                embedded_terms = self.aspect_embedding(\n",
    "                    torch.tensor(aspect_ids_for_review, dtype=torch.long).to(self.aspect_embedding.weight.device)\n",
    "                )\n",
    "                input_tensor = embedded_terms.unsqueeze(0)\n",
    "                attn_output, _ = self.multihead_attn(input_tensor, input_tensor, input_tensor)\n",
    "                pooled_output = attn_output.mean(dim=1)\n",
    "            aspect_features = self.mlp(pooled_output)\n",
    "            batch_aspect_features.append(aspect_features)\n",
    "        return torch.cat(batch_aspect_features, dim=0)\n",
    "\n",
    "    def _extract_aspect_terms_with_pyabsa(self, texts):\n",
    "        extracted_indices_batch = []\n",
    "        if self.ate_extractor is None:\n",
    "            for _ in texts:\n",
    "                extracted_indices_batch.append([self.aspect_to_id['<UNK>']])\n",
    "            return extracted_indices_batch\n",
    "        results = self.ate_extractor.predict(\n",
    "            texts,\n",
    "            print_result=False,\n",
    "            ignore_warnings=True\n",
    "        )\n",
    "        for result in results:\n",
    "            aspect_terms_for_review = []\n",
    "            if 'aspect' in result and result['aspect']:\n",
    "                aspect_list = result['aspect'] if isinstance(result['aspect'], list) else [result['aspect']]\n",
    "                for aspect_term_str in aspect_list:\n",
    "                    aspect_id = self.aspect_to_id.get(aspect_term_str.lower(), self.aspect_to_id['<UNK>'])\n",
    "                    aspect_terms_for_review.append(aspect_id)\n",
    "            if not aspect_terms_for_review:\n",
    "                aspect_terms_for_review.append(self.aspect_to_id['<UNK>'])\n",
    "            extracted_indices_batch.append(aspect_terms_for_review)\n",
    "        return extracted_indices_batch\n",
    "\n",
    "class RatingPredictionModule(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dims):\n",
    "        super(RatingPredictionModule, self).__init__()\n",
    "        layers = []\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    def forward(self, combined_features):\n",
    "        raw_prediction = self.mlp(combined_features)\n",
    "        prediction = torch.sigmoid(raw_prediction) * 4 + 1\n",
    "        return prediction\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, num_aspect_terms, aspect_embedding_dim, num_attn_heads,\n",
    "                 aspect_mlp_dims, final_mlp_dims, ate_extractor_instance, aspect_to_id_map):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        self.aspect_extraction_module = ReviewAspectTermExtractionModule(\n",
    "            num_aspect_terms, aspect_embedding_dim, num_attn_heads, aspect_mlp_dims,\n",
    "            ate_extractor_instance, aspect_to_id_map\n",
    "        )\n",
    "        combined_feature_dim = self.customer_restaurant_module.output_dim + \\\n",
    "                               self.aspect_extraction_module.output_dim\n",
    "        self.rating_prediction_module = RatingPredictionModule(\n",
    "            combined_feature_dim, final_mlp_dims\n",
    "        )\n",
    "    def forward(self, user_indices, business_indices, review_texts):\n",
    "        interaction_features = self.customer_restaurant_module(user_indices, business_indices)\n",
    "        aspect_features = self.aspect_extraction_module(review_texts)\n",
    "        combined_features = torch.cat((interaction_features, aspect_features), dim=-1)\n",
    "        predicted_rating = self.rating_prediction_module(combined_features).squeeze()\n",
    "        return predicted_rating\n",
    "\n",
    "print(\"AATRec 모델 구성 요소 정의 완료.\")\n",
    "\n",
    "# 4단계: 모델 학습 및 평가\n",
    "print(\"\\n--- 4단계: 모델 학습 및 평가 시작 ---\")\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "USER_BIZ_MLP_DIMS = [128, 64]\n",
    "ASPECT_EMBEDDING_DIM = 128\n",
    "NUM_ATTN_HEADS = 8\n",
    "ASPECT_MLP_DIMS = [64, 32]\n",
    "FINAL_MLP_DIMS = [32, 16]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(ReviewDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(ReviewDataset(val_df), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(ReviewDataset(test_df), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = AATRec(\n",
    "    num_users, num_businesses, EMBEDDING_DIM,\n",
    "    USER_BIZ_MLP_DIMS, NUM_ASPECT_TERMS, ASPECT_EMBEDDING_DIM, NUM_ATTN_HEADS,\n",
    "    ASPECT_MLP_DIMS, FINAL_MLP_DIMS, ate_extractor, ASPECT_TO_ID\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"모델을 '{device}' 장치로 이동했습니다.\")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "MIN_DELTA = 0.001\n",
    "MODEL_SAVE_PATH = 'best_aatrec_model_pyabsa.pt'\n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(f\"\\n모델 학습 시작 (총 {NUM_EPOCHS} 에포크, 배치 크기: {BATCH_SIZE}, 학습률: {LEARNING_RATE})\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_indices, business_indices, review_texts, stars in train_loader:\n",
    "        user_indices, business_indices, stars = user_indices.to(device), business_indices.to(device), stars.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predicted_stars = model(user_indices, business_indices, review_texts)\n",
    "        loss = criterion(predicted_stars, stars)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for user_indices, business_indices, review_texts, stars in val_loader:\n",
    "            user_indices, business_indices, stars = user_indices.to(device), business_indices.to(device), stars.to(device)\n",
    "            predicted_stars = model(user_indices, business_indices, review_texts)\n",
    "            total_val_loss += criterion(predicted_stars, stars).item()\n",
    "            val_preds.extend(predicted_stars.cpu().numpy())\n",
    "            val_true.extend(stars.cpu().numpy())\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true, val_preds))\n",
    "\n",
    "    sys.stdout.write(f\"\\rEpoch {epoch+1}/{NUM_EPOCHS}, \"\n",
    "                     f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                     f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                     f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "    if current_val_rmse < best_val_rmse - MIN_DELTA:\n",
    "        best_val_rmse = current_val_rmse\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        sys.stdout.write(f\" --> 검증 RMSE 개선됨. 최적 모델 저장됨: {best_val_rmse:.4f}\\n\")\n",
    "        sys.stdout.flush()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == PATIENCE:\n",
    "            sys.stdout.write(f\" --> 조기 종료! {PATIENCE} 에포크 동안 검증 RMSE 개선이 없었습니다.\\n\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "        else:\n",
    "            sys.stdout.write(f\" --> 검증 RMSE 개선되지 않음. 대기 중... ({epochs_no_improve}/{PATIENCE})\\n\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "sys.stdout.write(\"\\n\")\n",
    "print(\"모델 학습 완료!\")\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(f\"최적의 모델 가중치 '{MODEL_SAVE_PATH}' 로드 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 최적의 모델 가중치 '{MODEL_SAVE_PATH}'를 찾을 수 없습니다. 현재 모델 상태로 테스트를 진행합니다.\")\n",
    "\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for user_indices, business_indices, review_texts, stars in test_loader:\n",
    "        user_indices, business_indices, stars = user_indices.to(device), business_indices.to(device), stars.to(device)\n",
    "        predicted_stars = model(user_indices, business_indices, review_texts)\n",
    "        test_preds.extend(predicted_stars.cpu().numpy())\n",
    "        test_true.extend(stars.cpu().numpy())\n",
    "\n",
    "mse = mean_squared_error(test_true, test_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true, test_preds)\n",
    "mape = mean_absolute_percentage_error(test_true, test_preds)\n",
    "\n",
    "print(f\"\\n--- 최종 모델 성능 평가 (학습률: {LEARNING_RATE}, 배치 크기: {BATCH_SIZE}) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad555e-4a87-4b56-8b20-4d699f99c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16da2400-9c55-4eac-bb94-e7afed8161c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alche\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1.16.25 of pyabsa is outdated. Version 2.4.1 was released Friday February 23, 2024.\n",
      "check release notes at https://github.com/yangheng95/PyABSA/blob/release/release-note.json\n",
      "--- 1단계: 데이터 로드 및 전처리 시작 ---\n",
      "'447796'개의 리뷰 데이터를 성공적으로 로드했습니다.\n",
      "DEBUG: 데이터셋 크기를 50개 리뷰로 축소했습니다.\n",
      "'50'명의 고유 사용자와 '50'개의 고유 레스토랑을 매핑했습니다.\n",
      "학습 세트 크기: 35개 리뷰\n",
      "검증 세트 크기: 5개 리뷰\n",
      "테스트 세트 크기: 10개 리뷰\n",
      "\n",
      "--- 2단계: PyABSA ATE 모델 로드 및 동적 어휘집 구축 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alche\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote ABSADataset version: 2022.10.25 Local ABSADatasets version: 2022.10.25\n",
      "Dataset is not a path, treat dataset as keywords to Load 114.Restaurant14 from: 114.Restaurant14 or Search https://github.com/yangheng95/ABSADatasets locally using findfile\n",
      "You can set load_aug=True in a trainer to augment your dataset (English only yet) and improve performance.\n",
      "Please use a new folder to perform new text augmentation if the former augmentation exited unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at yangheng/deberta-v3-base-absa-v1.1 were not used when initializing DebertaV2Model: ['pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset cache: fast_lcf_atepc.Restaurant14.dataset.93573f0f850a88e9b1e40b3b6655765169db8323699cf1d2c823b3ee432591ce.cache\n",
      "2025-05-26 14:19:38,987 INFO: cuda memory allocated:764963840\n",
      "2025-05-26 14:19:38,988 INFO: ABSADatasetsVersion:2022.10.25\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,989 INFO: IOB_label_to_index:{'B-ASP': 1, 'I-ASP': 2, 'O': 3, '[CLS]': 4, '[SEP]': 5}\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:38,989 INFO: MV:<metric_visualizer.metric_visualizer.MetricVisualizer object at 0x0000028571556170>\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,990 INFO: PyABSAVersion:1.16.25\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,990 INFO: SRD:3\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,991 INFO: TorchVersion:2.7.0+cu126+cuda12.6\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,991 INFO: TransformersVersion:4.29.0\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,992 INFO: auto_device:True\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:38,992 INFO: batch_size:16\t-->\tCalling Count:4\n",
      "2025-05-26 14:19:38,992 INFO: cache_dataset:True\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,993 INFO: dataset_file:{'train': ['integrated_datasets\\\\atepc_datasets\\\\110.SemEval\\\\114.restaurant14\\\\Restaurants_Train.xml.seg.atepc'], 'test': ['integrated_datasets\\\\atepc_datasets\\\\110.SemEval\\\\114.restaurant14\\\\Restaurants_Test_Gold.xml.seg.atepc'], 'valid': []}\t-->\tCalling Count:2\n",
      "2025-05-26 14:19:38,993 INFO: dataset_name:Restaurant14\t-->\tCalling Count:3\n",
      "2025-05-26 14:19:38,994 INFO: device:cuda:0\t-->\tCalling Count:5\n",
      "2025-05-26 14:19:38,994 INFO: device_name:NVIDIA GeForce RTX 3070\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,995 INFO: dropout:0.5\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:38,996 INFO: dynamic_truncate:True\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,996 INFO: embed_dim:768\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,997 INFO: evaluate_begin:0\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,998 INFO: gradient_accumulation_steps:1\t-->\tCalling Count:3\n",
      "2025-05-26 14:19:38,998 INFO: hidden_dim:768\t-->\tCalling Count:6\n",
      "2025-05-26 14:19:38,999 INFO: index_to_IOB_label:{1: 'B-ASP', 2: 'I-ASP', 3: 'O', 4: '[CLS]', 5: '[SEP]'}\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:38,999 INFO: index_to_label:{0: 'Negative', 1: 'Neutral', 2: 'Positive'}\t-->\tCalling Count:2\n",
      "2025-05-26 14:19:38,999 INFO: initializer:xavier_uniform_\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,000 INFO: l2reg:1e-05\t-->\tCalling Count:2\n",
      "2025-05-26 14:19:39,000 INFO: label_list:['B-ASP', 'I-ASP', 'O', '[CLS]', '[SEP]']\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:39,001 INFO: label_to_index:{'Negative': 0, 'Neutral': 1, 'Positive': 2}\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,001 INFO: lcf:fusion\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,001 INFO: learning_rate:2e-05\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:39,001 INFO: log_step:50\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,003 INFO: max_seq_len:512\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,003 INFO: model:<class 'pyabsa.core.atepc.models.fast_lcf_atepc.FAST_LCF_ATEPC'>\t-->\tCalling Count:5\n",
      "2025-05-26 14:19:39,003 INFO: model_name:fast_lcf_atepc\t-->\tCalling Count:2\n",
      "2025-05-26 14:19:39,004 INFO: model_path_to_save:checkpoints\t-->\tCalling Count:2\n",
      "2025-05-26 14:19:39,005 INFO: num_epoch:10\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:39,005 INFO: num_labels:6\t-->\tCalling Count:3\n",
      "2025-05-26 14:19:39,005 INFO: optimizer:adamw\t-->\tCalling Count:2\n",
      "2025-05-26 14:19:39,006 INFO: patience:99999\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,006 INFO: polarities_dim:3\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:39,007 INFO: pretrained_bert:yangheng/deberta-v3-base-absa-v1.1\t-->\tCalling Count:4\n",
      "2025-05-26 14:19:39,007 INFO: save_mode:1\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,008 INFO: seed:52\t-->\tCalling Count:7\n",
      "2025-05-26 14:19:39,008 INFO: sep_indices:2\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,008 INFO: show_metric:False\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,009 INFO: spacy_model:en_core_web_sm\t-->\tCalling Count:3\n",
      "2025-05-26 14:19:39,009 INFO: srd_alignment:True\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,009 INFO: use_amp:False\t-->\tCalling Count:1\n",
      "2025-05-26 14:19:39,010 INFO: use_bert_spc:True\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,010 INFO: use_syntax_based_SRD:False\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,011 INFO: warmup_step:-1\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,011 INFO: window:lr\t-->\tCalling Count:0\n",
      "2025-05-26 14:19:39,012 INFO: ***** Running training for Aspect Term Extraction *****\n",
      "2025-05-26 14:19:39,012 INFO:   Num examples = 3604\n",
      "2025-05-26 14:19:39,013 INFO:   Batch size = 16\n",
      "2025-05-26 14:19:39,013 INFO:   Num steps = 2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [1:12:11<00:00, 19.17s/it, Epoch:0 | loss_apc:0.6523 | loss_ate:0.0715 | APC_ACC: 85.87(max:85.87) | APC_F1: 78.35(max:78.35) | ATE_F1: 82.85(max:83.47)]\n",
      "100%|██████████| 226/226 [1:07:55<00:00, 18.03s/it, Epoch:1 | loss_apc:0.1280 | loss_ate:0.1060 | APC_ACC: 86.94(max:87.84) | APC_F1: 81.74(max:82.31) | ATE_F1: 82.51(max:84.2)]\n",
      "100%|██████████| 226/226 [1:07:33<00:00, 17.94s/it, Epoch:2 | loss_apc:0.3954 | loss_ate:0.0603 | APC_ACC: 85.87(max:87.92) | APC_F1: 75.88(max:82.31) | ATE_F1: 85.14(max:85.14)]\n",
      "100%|██████████| 226/226 [1:08:26<00:00, 18.17s/it, Epoch:3 | loss_apc:0.3144 | loss_ate:0.0690 | APC_ACC: 86.94(max:88.46) | APC_F1: 81.88(max:83.07) | ATE_F1: 85.18(max:86.22)]\n",
      "  9%|▉         | 21/226 [07:43<1:15:21, 22.05s/it, Epoch:4 | loss_apc:0.0715 | loss_ate:0.0768 | APC_ACC: 87.92(max:88.46) | APC_F1: 82.81(max:83.07) | ATE_F1: 84.06(max:86.22)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     atepc_config\u001b[38;5;241m.\u001b[39mpretrained_bert \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myangheng/deberta-v3-base-absa-v1.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     76\u001b[0m     atepc_config\u001b[38;5;241m.\u001b[39mmax_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m \u001b[38;5;66;03m# 논문에 명시된 max_seq_len\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     ate_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mATEPCTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matepc_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mABSADatasetList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRestaurant14\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 내장 데이터셋 중 하나를 더미로 전달\u001b[39;49;00m\n\u001b[0;32m     80\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcheckpoint_save_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mauto_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     83\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_trained_model()\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyABSA ATEPC 모델 로더를 성공적으로 초기화했습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\pyabsa\\functional\\trainer\\trainer.py:151\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, config, dataset, from_checkpoint, checkpoint_save_mode, auto_device, path_to_save, load_aug)\u001b[0m\n\u001b[0;32m    147\u001b[0m     config\u001b[38;5;241m.\u001b[39mmodel_path_to_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\pyabsa\\functional\\trainer\\trainer.py:166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m s\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_save_mode:\n\u001b[1;32m--> 166\u001b[0m     model_path\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# always return the last trained model if dont save trained model\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_class(model_arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_checkpoint, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\pyabsa\\utils\\pyabsa_utils.py:265\u001b[0m, in \u001b[0;36mretry.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    267\u001b[0m         TransformerConnectionError,\n\u001b[0;32m    268\u001b[0m         requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m         requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mBaseHTTPError,\n\u001b[0;32m    275\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Exception: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, will retry later\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\pyabsa\\core\\atepc\\training\\atepc_trainer.py:511\u001b[0m, in \u001b[0;36mtrain4atepc\u001b[1;34m(opt, from_checkpoint_path, logger)\u001b[0m\n\u001b[0;32m    508\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Instructor(opt, logger)\n\u001b[0;32m    509\u001b[0m resume_from_checkpoint(trainer, from_checkpoint_path)\n\u001b[1;32m--> 511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\pyabsa\\core\\atepc\\training\\atepc_trainer.py:274\u001b[0m, in \u001b[0;36mInstructor.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mwarmup_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_absa_project_py310\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "from collections import Counter\n",
    "import os\n",
    "import time\n",
    "\n",
    "# PyABSA 라이브러리 임포트 (PyABSA 1.16.25 버전에 맞춤)\n",
    "from pyabsa.functional import ATEPCModelList, ATEPCTrainer\n",
    "from pyabsa.functional import ATEPCConfigManager\n",
    "from pyabsa.functional import ABSADatasetList\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return np.nan # 모든 y_true가 0인 경우 NaN 반환\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# 1단계: 데이터 로드 및 전처리\n",
    "print(\"--- 1단계: 데이터 로드 및 전처리 시작 ---\")\n",
    "try:\n",
    "    data = []\n",
    "    with open('review.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"'{len(df)}'개의 리뷰 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'review.json' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- 데이터셋 크기 조절 ---\n",
    "SUBSET_SIZE = 50 # 테스트를 위한 데이터의 총 개수를 50개로 더욱 축소\n",
    "if len(df) > SUBSET_SIZE:\n",
    "    df = df.sample(n=SUBSET_SIZE, random_state=42).reset_index(drop=True)\n",
    "    print(f\"DEBUG: 데이터셋 크기를 {SUBSET_SIZE}개 리뷰로 축소했습니다.\")\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['business_idx'] = business_encoder.fit_transform(df['business_id'])\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"'{num_users}'명의 고유 사용자와 '{num_businesses}'개의 고유 레스토랑을 매핑했습니다.\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], unit='ms')\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "total_reviews = len(df)\n",
    "train_split = int(total_reviews * 0.7)\n",
    "val_split = int(total_reviews * (0.7 + 0.1))\n",
    "train_df = df.iloc[:train_split].copy()\n",
    "val_df = df.iloc[train_split:val_split].copy()\n",
    "test_df = df.iloc[val_split:].copy()\n",
    "print(f\"학습 세트 크기: {len(train_df)}개 리뷰\")\n",
    "print(f\"검증 세트 크기: {len(val_df)}개 리뷰\")\n",
    "print(f\"테스트 세트 크기: {len(test_df)}개 리뷰\")\n",
    "\n",
    "# 2단계: PyABSA ATE 모델 로드 및 동적 어휘집 구축 (PyABSA 1.16.25 functional 호환)\n",
    "print(\"\\n--- 2단계: PyABSA ATE 모델 로드 및 동적 어휘집 구축 시작 ---\")\n",
    "\n",
    "ate_extractor = None\n",
    "try:\n",
    "    atepc_config = ATEPCConfigManager.get_atepc_config_english()\n",
    "    atepc_config.model = ATEPCModelList.FAST_LCF_ATEPC\n",
    "    atepc_config.lcf = 'fusion'\n",
    "    atepc_config.auto_device = True\n",
    "    atepc_config.pretrained_bert = 'yangheng/deberta-v3-base-absa-v1.1'\n",
    "    atepc_config.max_seq_len = 512 # 논문에 명시된 max_seq_len\n",
    "\n",
    "    ate_extractor = ATEPCTrainer(config=atepc_config,\n",
    "                                 dataset=ABSADatasetList.Restaurant14, # 내장 데이터셋 중 하나를 더미로 전달\n",
    "                                 from_checkpoint='',\n",
    "                                 checkpoint_save_mode=1,\n",
    "                                 auto_device=True\n",
    "                                 ).load_trained_model()\n",
    "    print(\"PyABSA ATEPC 모델 로더를 성공적으로 초기화했습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: PyABSA ATEPC 모델 로더 초기화 실패: {e}\")\n",
    "    print(\"PyABSA 설치를 확인하고, 시스템에 Git이 올바르게 설정되어 있는지 다시 확인해주세요.\")\n",
    "    print(\"PyABSA 1.16.25 버전이 올바르게 설치되었는지 확인해주세요.\")\n",
    "    print(\"모델 로드 실패 시, 속성 추출 모듈은 폴백(Fallback) 로직으로 동작합니다.\")\n",
    "    ate_extractor = None\n",
    "\n",
    "train_review_texts = train_df['text'].values.tolist()\n",
    "print(\"\\n학습 데이터 리뷰 텍스트에서 속성 키워드 추출 중 (어휘집 구축을 위해)...\")\n",
    "all_extracted_aspect_terms_from_train = []\n",
    "\n",
    "if ate_extractor:\n",
    "    initial_results = ate_extractor.extract_aspect(\n",
    "        inference_source=train_review_texts,\n",
    "        print_result=False,\n",
    "    )\n",
    "\n",
    "    if initial_results is not None:\n",
    "        for result in initial_results:\n",
    "            if 'aspect' in result and result['aspect']:\n",
    "                aspect_list = result['aspect'] if isinstance(result['aspect'], list) else [result['aspect']]\n",
    "                for term in aspect_list:\n",
    "                    all_extracted_aspect_terms_from_train.append(term.lower())\n",
    "    else:\n",
    "        print(\"경고: 초기 어휘집 구축 단계에서 PyABSA.extract_aspect가 None을 반환했습니다. 어휘집 구축이 제한됩니다.\")\n",
    "else:\n",
    "    print(\"경고: PyABSA ATE 모델이 로드되지 않아 동적 어휘집 구축이 제한됩니다.\")\n",
    "\n",
    "term_counts = Counter(all_extracted_aspect_terms_from_train)\n",
    "ASPECT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'general': 2}\n",
    "next_id = 3\n",
    "MIN_TERM_FREQUENCY = 1 # 테스트를 위해 최소 빈도수를 1로 설정하여 어휘집 크기 확보\n",
    "filtered_terms = [term for term, count in term_counts.items() if count >= MIN_TERM_FREQUENCY]\n",
    "filtered_terms.sort(key=lambda x: term_counts[x], reverse=True)\n",
    "\n",
    "for term in filtered_terms:\n",
    "    if term not in ASPECT_TO_ID:\n",
    "        ASPECT_TO_ID[term] = next_id\n",
    "        next_id += 1\n",
    "if 'general' not in ASPECT_TO_ID:\n",
    "    ASPECT_TO_ID['general'] = next_id\n",
    "    next_id += 1\n",
    "NUM_ASPECT_TERMS = len(ASPECT_TO_ID)\n",
    "print(f\"동적으로 구축된 어휘집 크기 (학습 데이터 기반): {NUM_ASPECT_TERMS}개 키워드\")\n",
    "print(f\"어휘집 상위 10개 키워드: {list(ASPECT_TO_ID.items())[3:13]}...\")\n",
    "print(\"PyABSA 모델 로드 및 동적 어휘집 구축 완료 (학습 데이터 기반).\")\n",
    "\n",
    "# --- 2.5단계: 모든 리뷰 텍스트에 대해 PyABSA 속성 사전 추출 및 캐싱 ---\n",
    "print(\"\\n--- 2.5단계: PyABSA 속성 사전 추출 및 캐싱 시작 ---\")\n",
    "\n",
    "# 이 함수는 ReviewAspectTermExtractionModule의 _extract_aspect_terms_with_pyabsa와 유사하지만\n",
    "# Dataset.__init__ 단계에서 전체 데이터를 미리 처리하기 위해 별도로 정의\n",
    "def pre_extract_aspect_ids_for_df(df_subset, ate_extractor_instance, aspect_to_id_map, device_for_pyabsa):\n",
    "    all_texts = df_subset['text'].values.tolist()\n",
    "    extracted_indices_batch = []\n",
    "    if ate_extractor_instance is None:\n",
    "        for _ in all_texts:\n",
    "            extracted_indices_batch.append([aspect_to_id_map['<UNK>']])\n",
    "        return extracted_indices_batch\n",
    "            \n",
    "    SUB_BATCH_SIZE_PYABSA = 32 # PyABSA의 내부 처리 배치 크기, GPU 메모리에 따라 조절\n",
    "    \n",
    "    # tqdm을 사용하여 진행률 표시 (설치 필요: pip install tqdm)\n",
    "    # from tqdm import tqdm\n",
    "    # for i in tqdm(range(0, len(all_texts), SUB_BATCH_SIZE_PYABSA), desc=\"PyABSA Pre-extraction\"):\n",
    "\n",
    "    for i in range(0, len(all_texts), SUB_BATCH_SIZE_PYABSA):\n",
    "        sub_texts = all_texts[i:i + SUB_BATCH_SIZE_PYABSA]\n",
    "        \n",
    "        sub_results = None\n",
    "        retry_count = 0\n",
    "        MAX_RETRIES = 3\n",
    "\n",
    "        while retry_count < MAX_RETRIES:\n",
    "            try:\n",
    "                # PyABSA 1.16.25의 extract_aspect는 device 인자를 직접 받지 않음\n",
    "                # config.auto_device=True가 이를 처리함\n",
    "                sub_results = ate_extractor_instance.extract_aspect(\n",
    "                    inference_source=sub_texts,\n",
    "                    print_result=False,\n",
    "                )\n",
    "                if sub_results is not None:\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"\\n경고: PyABSA.extract_aspect가 None을 반환했습니다. 재시도 ({retry_count+1}/{MAX_RETRIES})...\")\n",
    "                    retry_count += 1\n",
    "                    torch.cuda.empty_cache()\n",
    "                    time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"\\n경고: PyABSA.extract_aspect 중 예외 발생: {e}. 재시도 ({retry_count+1}/{MAX_RETRIES})...\")\n",
    "                sub_results = None\n",
    "                retry_count += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                time.sleep(1)\n",
    "        \n",
    "        if sub_results is None:\n",
    "            print(f\"\\n오류: PyABSA.extract_aspect가 {MAX_RETRIES}번 재시도 후에도 실패했습니다. 해당 서브 배치에 대해 <UNK> 처리합니다.\")\n",
    "            for _ in sub_texts:\n",
    "                extracted_indices_batch.append([aspect_to_id_map['<UNK>']])\n",
    "            continue\n",
    "\n",
    "        for result in sub_results:\n",
    "            aspect_terms_for_review = []\n",
    "            if 'aspect' in result and result['aspect']:\n",
    "                aspect_list = result['aspect'] if isinstance(result['aspect'], list) else [result['aspect']]\n",
    "                for aspect_term_str in aspect_list:\n",
    "                    aspect_id = aspect_to_id_map.get(aspect_term_str.lower(), aspect_to_id_map['<UNK>'])\n",
    "                    aspect_terms_for_review.append(aspect_id)\n",
    "            if not aspect_terms_for_review:\n",
    "                aspect_terms_for_review.append(aspect_to_id_map['<UNK>'])\n",
    "            extracted_indices_batch.append(aspect_terms_for_review)\n",
    "    return extracted_indices_batch\n",
    "\n",
    "# PyABSA 추출 시 사용할 디바이스 설정\n",
    "pyabsa_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_df['extracted_aspect_ids'] = pre_extract_aspect_ids_for_df(train_df, ate_extractor, ASPECT_TO_ID, pyabsa_device)\n",
    "val_df['extracted_aspect_ids'] = pre_extract_aspect_ids_for_df(val_df, ate_extractor, ASPECT_TO_ID, pyabsa_device)\n",
    "test_df['extracted_aspect_ids'] = pre_extract_aspect_ids_for_df(test_df, ate_extractor, ASPECT_TO_ID, pyabsa_device)\n",
    "\n",
    "print(\"PyABSA 속성 사전 추출 및 캐싱 완료.\")\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_indices = torch.tensor(df['user_idx'].values, dtype=torch.long)\n",
    "        self.business_indices = torch.tensor(df['business_idx'].values, dtype=torch.long)\n",
    "        # 원본 review_texts는 이제 필요 없음\n",
    "        self.extracted_aspect_ids = df['extracted_aspect_ids'].values.tolist() # 미리 추출된 ID 사용\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "    def __getitem__(self, idx):\n",
    "        # review_texts 대신 추출된 aspect_ids를 반환\n",
    "        return self.user_indices[idx], self.business_indices[idx], self.extracted_aspect_ids[idx], self.stars[idx]\n",
    "\n",
    "# 3단계: AAT-Rec 모델 구성 요소 정의\n",
    "print(\"\\n--- 3단계: AAT-Rec 모델 구성 요소 정의 시작 ---\")\n",
    "\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "    def forward(self, user_indices, business_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        business_emb = self.business_embedding(business_indices)\n",
    "        combined_emb = torch.cat((user_emb, business_emb), dim=-1)\n",
    "        interaction_features = self.mlp(combined_emb)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectTermExtractionModule(nn.Module):\n",
    "    def __init__(self, num_aspect_terms, aspect_embedding_dim, num_heads, mlp_dims):\n",
    "        super(ReviewAspectTermExtractionModule, self).__init__()\n",
    "        # ate_extractor_instance와 aspect_to_id_map는 더 이상 이 모듈의 __init__에서 받지 않음\n",
    "        # (미리 추출된 ID를 사용하므로 PyABSA 모델이 더 이상 필요 없음)\n",
    "        self.aspect_embedding = nn.Embedding(num_aspect_terms, aspect_embedding_dim, padding_idx=0)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=aspect_embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "        layers = []\n",
    "        input_dim = aspect_embedding_dim\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "    \n",
    "    # review_texts 대신 미리 추출된 aspect_ids 리스트를 직접 입력으로 받음\n",
    "    def forward(self, pre_extracted_aspect_ids_batch):\n",
    "        batch_aspect_features = []\n",
    "        # 각 리뷰의 속성 ID 리스트에 대해 처리\n",
    "        for aspect_ids_for_review in pre_extracted_aspect_ids_batch:\n",
    "            # PyTorch 텐서로 변환\n",
    "            # ReviewDataset의 collate_fn이 없으므로, DataLoader는 이 리스트를 그대로 전달\n",
    "            # 따라서 각 요소는 길이가 다른 리스트가 될 수 있음\n",
    "            # MultiheadAttention은 (Batch, SeqLen, EmbDim) 형태를 기대하므로,\n",
    "            # 여기서는 각 리뷰의 속성들을 개별적으로 처리하여 unsqueeze(0)로 배치 차원 추가\n",
    "            \n",
    "            # 비어있는 경우 (추출된 속성이 없는 경우) UNK 토큰 사용\n",
    "            if not aspect_ids_for_review:\n",
    "                # 미리 pre_extract_aspect_ids_for_df에서 <UNK>를 넣어주므로 이 분기는 거의 타지 않음.\n",
    "                # 하지만 안전을 위해 UNK 처리 로직 유지 (ID 1이 <UNK> 가정)\n",
    "                embedded_terms = self.aspect_embedding(\n",
    "                    torch.tensor([1], dtype=torch.long).to(self.aspect_embedding.weight.device)\n",
    "                )\n",
    "            else:\n",
    "                embedded_terms = self.aspect_embedding(\n",
    "                    torch.tensor(aspect_ids_for_review, dtype=torch.long).to(self.aspect_embedding.weight.device)\n",
    "                )\n",
    "            \n",
    "            input_tensor = embedded_terms.unsqueeze(0) # (1, num_aspect_terms, embedding_dim)\n",
    "            attn_output, _ = self.multihead_attn(input_tensor, input_tensor, input_tensor)\n",
    "            pooled_output = attn_output.mean(dim=1) # (1, embedding_dim)\n",
    "            aspect_features = self.mlp(pooled_output) # (1, output_dim)\n",
    "            batch_aspect_features.append(aspect_features)\n",
    "        \n",
    "        # 모든 리뷰의 속성 특징을 하나의 배치 텐서로 결합\n",
    "        return torch.cat(batch_aspect_features, dim=0)\n",
    "\n",
    "    # 이 메서드는 이제 ReviewDataset 초기화 단계에서만 사용되므로, \n",
    "    # ReviewAspectTermExtractionModule 클래스에서 제거하거나 비활성화해도 됨.\n",
    "    # 코드의 가독성을 위해 일단 주석 처리하여 '더 이상 사용되지 않음'을 명시\n",
    "    # def _extract_aspect_terms_with_pyabsa(...):\n",
    "    #     pass\n",
    "\n",
    "\n",
    "class RatingPredictionModule(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dims):\n",
    "        super(RatingPredictionModule, self).__init__()\n",
    "        layers = []\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    def forward(self, combined_features):\n",
    "        raw_prediction = self.mlp(combined_features)\n",
    "        prediction = torch.sigmoid(raw_prediction) * 4 + 1 # 1~5점 스케일로 정규화\n",
    "        return prediction\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, num_aspect_terms, aspect_embedding_dim, num_attn_heads,\n",
    "                 aspect_mlp_dims, final_mlp_dims): # ate_extractor_instance, aspect_to_id_map 인자 제거\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        # ate_extractor_instance, aspect_to_id_map 인자 제거\n",
    "        self.aspect_extraction_module = ReviewAspectTermExtractionModule(\n",
    "            num_aspect_terms, aspect_embedding_dim, num_attn_heads, aspect_mlp_dims\n",
    "        )\n",
    "        combined_feature_dim = self.customer_restaurant_module.output_dim + \\\n",
    "                               self.aspect_extraction_module.output_dim\n",
    "        self.rating_prediction_module = RatingPredictionModule(\n",
    "            combined_feature_dim, final_mlp_dims\n",
    "        )\n",
    "    # review_texts 대신 pre_extracted_aspect_ids를 입력으로 받음\n",
    "    def forward(self, user_indices, business_indices, pre_extracted_aspect_ids):\n",
    "        interaction_features = self.customer_restaurant_module(user_indices, business_indices)\n",
    "        aspect_features = self.aspect_extraction_module(pre_extracted_aspect_ids)\n",
    "        combined_features = torch.cat((interaction_features, aspect_features), dim=-1)\n",
    "        predicted_rating = self.rating_prediction_module(combined_features).squeeze()\n",
    "        return predicted_rating\n",
    "\n",
    "print(\"AATRec 모델 구성 요소 정의 완료.\")\n",
    "\n",
    "# 4단계: 모델 학습 및 평가\n",
    "print(\"\\n--- 4단계: 모델 학습 및 평가 시작 ---\")\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "USER_BIZ_MLP_DIMS = [128, 64]\n",
    "ASPECT_EMBEDDING_DIM = 128\n",
    "NUM_ATTN_HEADS = 8\n",
    "ASPECT_MLP_DIMS = [64, 32]\n",
    "FINAL_MLP_DIMS = [32, 16]\n",
    "\n",
    "# DataLoader의 batch_size는 ReviewDataset에서 반환하는 데이터 구조에 따라 유연하게 설정\n",
    "# 현재 aspect_ids가 가변 길이 리스트이므로, collate_fn을 정의하지 않으면 batch_size=1이 강제될 수 있음\n",
    "# 작은 데이터셋이므로 일단 기본 동작을 유지하며, 필요시 collate_fn 구현 고려\n",
    "BATCH_SIZE = 1 # 가변 길이 시퀀스 때문에 기본적으로 1로 설정하는 것이 안전.\n",
    "                # 그러나 PyTorch 2.x 이상에서는 일부 collate_fn이 기본적으로 작동하기도 함.\n",
    "                # 에러 발생 시 BATCH_SIZE=1로 변경하거나 collate_fn 구현 필요\n",
    "train_loader = DataLoader(ReviewDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(ReviewDataset(val_df), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(ReviewDataset(test_df), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = AATRec(\n",
    "    num_users, num_businesses, EMBEDDING_DIM,\n",
    "    USER_BIZ_MLP_DIMS, NUM_ASPECT_TERMS, ASPECT_EMBEDDING_DIM, NUM_ATTN_HEADS,\n",
    "    ASPECT_MLP_DIMS, FINAL_MLP_DIMS\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"모델을 '{device}' 장치로 이동했습니다.\")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 5\n",
    "MIN_DELTA = 0.001\n",
    "MODEL_SAVE_PATH = 'best_aatrec_model_pyabsa.pt'\n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(f\"\\n모델 학습 시작 (총 {NUM_EPOCHS} 에포크, 배치 크기: {BATCH_SIZE}, 학습률: {LEARNING_RATE})\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_indices, business_indices, extracted_aspect_ids, stars in train_loader:\n",
    "        user_indices, business_indices, stars = user_indices.to(device), business_indices.to(device), stars.to(device)\n",
    "        # extracted_aspect_ids는 텐서가 아닌 파이썬 리스트의 리스트 형태이므로 to(device) 적용 불가\n",
    "        # 이 부분은 ReviewAspectTermExtractionModule 내부에서 처리됨 (개별 텐서로 변환 후 to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_stars = model(user_indices, business_indices, extracted_aspect_ids)\n",
    "        loss = criterion(predicted_stars, stars)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for user_indices, business_indices, extracted_aspect_ids, stars in val_loader:\n",
    "            user_indices, business_indices, stars = user_indices.to(device), business_indices.to(device), stars.to(device)\n",
    "            predicted_stars = model(user_indices, business_indices, extracted_aspect_ids)\n",
    "            total_val_loss += criterion(predicted_stars, stars).item()\n",
    "            val_preds.extend(predicted_stars.cpu().numpy())\n",
    "            val_true.extend(stars.cpu().numpy())\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true, val_preds))\n",
    "\n",
    "    sys.stdout.write(f\"\\rEpoch {epoch+1}/{NUM_EPOCHS}, \"\n",
    "                     f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                     f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                     f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "    if current_val_rmse < best_val_rmse - MIN_DELTA:\n",
    "        best_val_rmse = current_val_rmse\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        sys.stdout.write(f\" --> 검증 RMSE 개선됨. 최적 모델 저장됨: {best_val_rmse:.4f}\\n\")\n",
    "        sys.stdout.flush()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == PATIENCE:\n",
    "            sys.stdout.write(f\" --> 조기 종료! {PATIENCE} 에포크 동안 검증 RMSE 개선이 없었습니다.\\n\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "        else:\n",
    "            sys.stdout.write(f\" --> 검증 RMSE 개선되지 않음. 대기 중... ({epochs_no_improve}/{PATIENCE})\\n\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "sys.stdout.write(\"\\n\")\n",
    "print(\"모델 학습 완료!\")\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(f\"최적의 모델 가중치 '{MODEL_SAVE_PATH}' 로드 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 최적의 모델 가중치 '{MODEL_SAVE_PATH}'를 찾을 수 없습니다. 현재 모델 상태로 테스트를 진행합니다.\")\n",
    "\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for user_indices, business_indices, extracted_aspect_ids, stars in test_loader:\n",
    "        user_indices, business_indices, stars = user_indices.to(device), business_indices.to(device), stars.to(device)\n",
    "        predicted_stars = model(user_indices, business_indices, extracted_aspect_ids)\n",
    "        test_preds.extend(predicted_stars.cpu().numpy())\n",
    "        test_true.extend(stars.cpu().numpy())\n",
    "\n",
    "mse = mean_squared_error(test_true, test_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true, test_preds)\n",
    "mape = mean_absolute_percentage_error(test_true, test_preds)\n",
    "\n",
    "print(f\"\\n--- 최종 모델 성능 평가 (학습률: {LEARNING_RATE}, 배치 크기: {BATCH_SIZE}) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348f005-c631-4194-8af0-4fc4927272a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pyabsa\n",
    "print(pyabsa.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe04a42c-eede-487e-b77e-4ee6e671604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1단계: 데이터 로드 및 전처리 시작 ---\n",
      "'447796'개의 리뷰 데이터를 성공적으로 로드했습니다.\n",
      "'27807'명의 고유 사용자와 '6831'개의 고유 레스토랑을 매핑했습니다.\n",
      "학습 세트 크기: 313457개 리뷰\n",
      "검증 세트 크기: 44779개 리뷰\n",
      "테스트 세트 크기: 89560개 리뷰\n",
      "\n",
      "--- 2단계: absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 시작 ---\n",
      "'absa_atepc_results.json' 파일에서 447796개의 리뷰 속성 데이터를 성공적으로 로드했습니다.\n",
      "동적으로 구축된 속성 어휘집 크기 (학습 데이터 기반): 39160개 키워드\n",
      "어휘집 상위 10개 키워드: [('food', 3), ('service', 4), ('staff', 5), ('place', 6), ('atmosphere', 7), ('prices', 8), ('they', 9), ('price', 10), ('pizza', 11), ('it', 12)]...\n",
      "구축된 감성 어휘집 크기: 5개 감성 ([('<PAD>', 0), ('<UNK>', 1), ('positive', 2), ('negative', 3), ('neutral', 4)])\n",
      "absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 완료.\n",
      "\n",
      "--- 2.5단계: 로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 시작 ---\n",
      "로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 완료.\n",
      "\n",
      "--- 3단계: AAT-Rec 모델 구성 요소 정의 (감성 통합) ---\n",
      "AATRec 모델 구성 요소 정의 완료.\n",
      "\n",
      "--- 4단계: 단일 하이퍼파라미터 조합으로 모델 학습 및 저장 시작 ---\n",
      "학습 장치: 'cuda'\n",
      "현재 파라미터: {'embedding_dim': 64, 'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 32, 'num_attn_heads': 8, 'learning_rate': 0.001, 'batch_size': 128, 'dropout_rate': 0.2, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'final_mlp_dims': [32, 16]}\n",
      "\n",
      "--- 모델 학습 시작 ---\n",
      "  Epoch 1/50, Train Loss: 0.7957, Val Loss: 0.6931, Val RMSE: 0.8326 --> 최적 검증 RMSE 개선됨: 0.8326. 모델 저장됨.\n",
      "  Epoch 3/50, Train Loss: 0.6475, Val Loss: 0.6762, Val RMSE: 0.8223 --> 최적 검증 RMSE 개선됨: 0.8223. 모델 저장됨.\n",
      "  Epoch 8/50, Train Loss: 0.4920, Val Loss: 0.7268, Val RMSE: 0.8526 --> 조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다.\n",
      "\n",
      "--- 모델 학습 완료 ---\n",
      "최종 저장된 모델의 검증 RMSE: 0.8223\n",
      "저장 경로: final_best_aatrec_model_multihead_aspect_sentiment.pt\n",
      "\n",
      "--- 최종 모델 테스트 시작 (최적 파라미터 사용) ---\n",
      "최적의 모델 가중치 'final_best_aatrec_model_multihead_aspect_sentiment.pt' 로드 완료.\n",
      "\n",
      "--- 최종 모델 성능 평가 (최적 파라미터) ---\n",
      "Root Mean Squared Error (RMSE): 0.8529\n",
      "Mean Absolute Error (MAE): 0.6799\n",
      "Mean Absolute Percentage Error (MAPE): 25.19%\n",
      "Mean Squared Error (MSE): 0.7274\n",
      "사용된 최적 하이퍼파라미터: {'embedding_dim': 64, 'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 32, 'num_attn_heads': 8, 'learning_rate': 0.001, 'batch_size': 128, 'dropout_rate': 0.2, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'final_mlp_dims': [32, 16]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return np.nan # 모든 y_true가 0인 경우 NaN 반환\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 0. 파일 경로 설정 ---\n",
    "review_json_path = 'review.json'\n",
    "absa_results_path = 'absa_atepc_results.json' # .json 확장자로 변경\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "print(\"--- 1단계: 데이터 로드 및 전처리 시작 ---\")\n",
    "try:\n",
    "    data = []\n",
    "    with open(review_json_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"'{len(df)}'개의 리뷰 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{review_json_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"오류: '{review_json_path}' 파일 파싱 중 오류 발생: {e}. 파일 내용이 올바른 JSON 형식을 따르는지 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['business_idx'] = business_encoder.fit_transform(df['business_id'])\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"'{num_users}'명의 고유 사용자와 '{num_businesses}'개의 고유 레스토랑을 매핑했습니다.\")\n",
    "\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='ms') # timestamp in milliseconds\n",
    "except ValueError:\n",
    "    df['date'] = pd.to_datetime(df['date']) # assume standard date string format if ms fails\n",
    "\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "total_reviews = len(df)\n",
    "train_split = int(total_reviews * 0.7)\n",
    "val_split_idx = int(total_reviews * (0.7 + 0.1)) # 검증 세트의 끝 인덱스\n",
    "train_df = df.iloc[:train_split].copy()\n",
    "val_df = df.iloc[train_split:val_split_idx].copy()\n",
    "test_df = df.iloc[val_split_idx:].copy() # 나머지 20%를 테스트 세트로\n",
    "print(f\"학습 세트 크기: {len(train_df)}개 리뷰\")\n",
    "print(f\"검증 세트 크기: {len(val_df)}개 리뷰\")\n",
    "print(f\"테스트 세트 크기: {len(test_df)}개 리뷰\")\n",
    "\n",
    "print(\"\\n--- 2단계: absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 시작 ---\")\n",
    "\n",
    "absa_data = {}\n",
    "try:\n",
    "    with open(absa_results_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            absa_data[entry['review_id']] = entry['aspects']\n",
    "    print(f\"'{absa_results_path}' 파일에서 {len(absa_data)}개의 리뷰 속성 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{absa_results_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"오류: '{absa_results_path}' 파일 파싱 중 오류 발생: {e}. 파일 내용이 올바른 JSON 형식을 따르는지 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "all_extracted_aspect_terms_from_file = []\n",
    "all_extracted_sentiments_from_file = []\n",
    "\n",
    "for review_id in train_df['review_id']:\n",
    "    aspects = absa_data.get(review_id, [])\n",
    "    if not aspects: # 속성이 없는 경우 'general' 및 'neutral'로 대체\n",
    "        all_extracted_aspect_terms_from_file.append('general')\n",
    "        all_extracted_sentiments_from_file.append('neutral')\n",
    "    else:\n",
    "        for aspect in aspects:\n",
    "            if 'term' in aspect and 'sentiment' in aspect:\n",
    "                all_extracted_aspect_terms_from_file.append(aspect['term'].lower())\n",
    "                # 감성 라벨을 소문자로 통일 (Positive, Negative, Neutral)\n",
    "                all_extracted_sentiments_from_file.append(aspect['sentiment'].lower())\n",
    "\n",
    "# 속성 키워드 어휘집 구축\n",
    "term_counts = Counter(all_extracted_aspect_terms_from_file)\n",
    "# <PAD>는 0번, <UNK>는 1번, 'general'은 2번 인덱스를 가집니다.\n",
    "ASPECT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'general': 2}\n",
    "next_id = 3\n",
    "MIN_TERM_FREQUENCY = 1 # 어휘집 구축 시 최소 등장 빈도\n",
    "filtered_terms = [term for term, count in term_counts.items() if count >= MIN_TERM_FREQUENCY]\n",
    "filtered_terms.sort(key=lambda x: term_counts[x], reverse=True)\n",
    "\n",
    "for term in filtered_terms:\n",
    "    if term not in ASPECT_TO_ID:\n",
    "        ASPECT_TO_ID[term] = next_id\n",
    "        next_id += 1\n",
    "NUM_ASPECT_TERMS = len(ASPECT_TO_ID)\n",
    "\n",
    "# 감성 어휘집 구축 (고정된 긍정, 부정, 중립)\n",
    "SENTIMENT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'positive': 2, 'negative': 3, 'neutral': 4}\n",
    "# PyABSA 결과에 따라 'Positive', 'Negative', 'Neutral'을 소문자로 통일하여 처리\n",
    "NUM_SENTIMENTS = len(SENTIMENT_TO_ID)\n",
    "\n",
    "print(f\"동적으로 구축된 속성 어휘집 크기 (학습 데이터 기반): {NUM_ASPECT_TERMS}개 키워드\")\n",
    "print(f\"어휘집 상위 10개 키워드: {list(ASPECT_TO_ID.items())[3:13]}...\") # 0,1,2 제외하고 출력\n",
    "print(f\"구축된 감성 어휘집 크기: {NUM_SENTIMENTS}개 감성 ({list(SENTIMENT_TO_ID.items())})\")\n",
    "print(\"absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 완료.\")\n",
    "\n",
    "print(\"\\n--- 2.5단계: 로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 시작 ---\")\n",
    "\n",
    "def map_aspect_and_sentiment_ids_from_file(df_subset, absa_data_map, aspect_to_id_map, sentiment_to_id_map):\n",
    "    extracted_aspect_ids_list = []\n",
    "    extracted_sentiment_ids_list = []\n",
    "    \n",
    "    for _, row in df_subset.iterrows():\n",
    "        review_id = row['review_id']\n",
    "        aspects_for_review = absa_data_map.get(review_id, [])\n",
    "        \n",
    "        aspect_ids_for_review = []\n",
    "        sentiment_ids_for_review = []\n",
    "        \n",
    "        if aspects_for_review:\n",
    "            for aspect in aspects_for_review:\n",
    "                if 'term' in aspect and 'sentiment' in aspect:\n",
    "                    aspect_id = aspect_to_id_map.get(aspect['term'].lower(), aspect_to_id_map['<UNK>'])\n",
    "                    sentiment_id = sentiment_to_id_map.get(aspect['sentiment'].lower(), sentiment_to_id_map['<UNK>']) # 감성 ID도 매핑\n",
    "                    \n",
    "                    aspect_ids_for_review.append(aspect_id)\n",
    "                    sentiment_ids_for_review.append(sentiment_id)\n",
    "        \n",
    "        if not aspect_ids_for_review: # 추출된 속성이 없으면 'general' 및 'neutral' 감성 사용\n",
    "            aspect_ids_for_review.append(aspect_to_id_map['general'])\n",
    "            sentiment_ids_for_review.append(sentiment_to_id_map['neutral']) # 'general'과 함께 'neutral' 감성 할당\n",
    "            \n",
    "        extracted_aspect_ids_list.append(aspect_ids_for_review)\n",
    "        extracted_sentiment_ids_list.append(sentiment_ids_for_review)\n",
    "        \n",
    "    return extracted_aspect_ids_list, extracted_sentiment_ids_list\n",
    "\n",
    "# 각 DataFrame에 속성 ID와 감성 ID 리스트 매핑\n",
    "train_df['extracted_aspect_ids'], train_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(train_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "val_df['extracted_aspect_ids'], val_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(val_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "test_df['extracted_aspect_ids'], test_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(test_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "\n",
    "print(\"로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 완료.\")\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_indices = torch.tensor(df['user_idx'].values, dtype=torch.long)\n",
    "        self.business_indices = torch.tensor(df['business_idx'].values, dtype=torch.long)\n",
    "        self.extracted_aspect_ids = df['extracted_aspect_ids'].values.tolist()\n",
    "        self.extracted_sentiment_ids = df['extracted_sentiment_ids'].values.tolist() # 감성 ID 추가\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.user_indices[idx], self.business_indices[idx],\n",
    "                self.extracted_aspect_ids[idx], self.extracted_sentiment_ids[idx], # 감성 ID 반환\n",
    "                self.stars[idx])\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    user_indices, business_indices, extracted_aspect_ids_list, extracted_sentiment_ids_list, stars = zip(*batch)\n",
    "\n",
    "    user_indices = torch.stack(user_indices)\n",
    "    business_indices = torch.stack(business_indices)\n",
    "    stars = torch.stack(stars)\n",
    "\n",
    "    # MultiheadAttention 입력을 위한 패딩 및 마스크 생성\n",
    "    max_aspect_len = max(len(ids) for ids in extracted_aspect_ids_list)\n",
    "    \n",
    "    padded_aspect_ids = [ids + [ASPECT_TO_ID['<PAD>']] * (max_aspect_len - len(ids)) for ids in extracted_aspect_ids_list]\n",
    "    padded_aspect_ids_tensor = torch.tensor(padded_aspect_ids, dtype=torch.long)\n",
    "    \n",
    "    padded_sentiment_ids = [ids + [SENTIMENT_TO_ID['<PAD>']] * (max_aspect_len - len(ids)) for ids in extracted_sentiment_ids_list]\n",
    "    padded_sentiment_ids_tensor = torch.tensor(padded_sentiment_ids, dtype=torch.long)\n",
    "    \n",
    "    # key_padding_mask: True는 무시할 요소 (패딩)\n",
    "    attn_mask = (padded_aspect_ids_tensor == ASPECT_TO_ID['<PAD>']) # aspect_ids를 기준으로 마스크 생성\n",
    "\n",
    "    return user_indices, business_indices, padded_aspect_ids_tensor, padded_sentiment_ids_tensor, stars, attn_mask\n",
    "\n",
    "print(\"\\n--- 3단계: AAT-Rec 모델 구성 요소 정의 (감성 통합) ---\")\n",
    "\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims, dropout_rate):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "\n",
    "    def forward(self, user_indices, business_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        business_emb = self.business_embedding(business_indices)\n",
    "        combined_emb = torch.cat((user_emb, business_emb), dim=-1)\n",
    "        interaction_features = self.mlp(combined_emb)\n",
    "        return interaction_features\n",
    "\n",
    "# 리뷰 속성별 키워드 추출 모듈 (MultiheadAttention 사용) - 감성 정보 통합\n",
    "class ReviewAspectTermExtractionModule(nn.Module):\n",
    "    def __init__(self, num_aspect_terms, aspect_embedding_dim, num_sentiments, sentiment_embedding_dim, num_heads, mlp_dims, dropout_rate):\n",
    "        super(ReviewAspectTermExtractionModule, self).__init__()\n",
    "        self.aspect_embedding = nn.Embedding(num_aspect_terms, aspect_embedding_dim, padding_idx=ASPECT_TO_ID['<PAD>'])\n",
    "        self.sentiment_embedding = nn.Embedding(num_sentiments, sentiment_embedding_dim, padding_idx=SENTIMENT_TO_ID['<PAD>']) # 감성 임베딩 추가\n",
    "        \n",
    "        # MultiheadAttention의 embed_dim은 이제 속성 임베딩과 감성 임베딩을 합친 차원이 됩니다.\n",
    "        combined_embedding_dim = aspect_embedding_dim + sentiment_embedding_dim\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=combined_embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = combined_embedding_dim # MultiheadAttention 출력 차원은 combined_embedding_dim과 동일\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "            \n",
    "    def forward(self, pre_extracted_aspect_ids_batch, pre_extracted_sentiment_ids_batch, attn_mask):\n",
    "        embedded_terms = self.aspect_embedding(pre_extracted_aspect_ids_batch)\n",
    "        embedded_sentiments = self.sentiment_embedding(pre_extracted_sentiment_ids_batch)\n",
    "        \n",
    "        # 속성 임베딩과 감성 임베딩을 결합 (Concatenate)\n",
    "        combined_embeddings = torch.cat((embedded_terms, embedded_sentiments), dim=-1) # dim=-1은 마지막 차원 기준으로 합침\n",
    "        \n",
    "        # MultiheadAttention에 key_padding_mask 적용\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            combined_embeddings, \n",
    "            combined_embeddings, \n",
    "            combined_embeddings, \n",
    "            key_padding_mask=attn_mask\n",
    "        )\n",
    "\n",
    "        # 패딩된 요소들을 0으로 만들고 유효한 요소들만 평균 풀링\n",
    "        valid_attn_output = attn_output * (~attn_mask.unsqueeze(-1)).float()\n",
    "        pooled_output = valid_attn_output.sum(dim=1) / (~attn_mask).sum(dim=1, keepdim=True).float().clamp(min=1)\n",
    "        \n",
    "        aspect_features = self.mlp(pooled_output)\n",
    "        return aspect_features\n",
    "\n",
    "class RatingPredictionModule(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dims, dropout_rate):\n",
    "        super(RatingPredictionModule, self).__init__()\n",
    "        layers = []\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    def forward(self, combined_features):\n",
    "        raw_prediction = self.mlp(combined_features)\n",
    "        prediction = torch.sigmoid(raw_prediction) * 4 + 1 # 1~5점 스케일로 정규화\n",
    "        return prediction\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, num_aspect_terms, aspect_embedding_dim,\n",
    "                 num_sentiments, sentiment_embedding_dim, # 감성 관련 파라미터 추가\n",
    "                 num_attn_heads, aspect_mlp_dims, final_mlp_dims, dropout_rate):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims, dropout_rate\n",
    "        )\n",
    "        self.aspect_extraction_module = ReviewAspectTermExtractionModule(\n",
    "            num_aspect_terms, aspect_embedding_dim, num_sentiments, sentiment_embedding_dim, # 감성 관련 파라미터 전달\n",
    "            num_attn_heads, aspect_mlp_dims, dropout_rate\n",
    "        )\n",
    "        combined_feature_dim = self.customer_restaurant_module.output_dim + \\\n",
    "                               self.aspect_extraction_module.output_dim\n",
    "        self.rating_prediction_module = RatingPredictionModule(\n",
    "            combined_feature_dim, final_mlp_dims, dropout_rate\n",
    "        )\n",
    "    def forward(self, user_indices, business_indices, pre_extracted_aspect_ids, pre_extracted_sentiment_ids, attn_mask): # 감성 ID 추가\n",
    "        interaction_features = self.customer_restaurant_module(user_indices, business_indices)\n",
    "        aspect_features = self.aspect_extraction_module(pre_extracted_aspect_ids, pre_extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "        combined_features = torch.cat((interaction_features, aspect_features), dim=-1)\n",
    "        predicted_rating = self.rating_prediction_module(combined_features).squeeze()\n",
    "        return predicted_rating\n",
    "\n",
    "print(\"AATRec 모델 구성 요소 정의 완료.\")\n",
    "\n",
    "\n",
    "# --- 4. 하이퍼파라미터 설정 및 모델 학습 ---\n",
    "\n",
    "print(\"\\n--- 4단계: 단일 하이퍼파라미터 조합으로 모델 학습 및 저장 시작 ---\")\n",
    "\n",
    "# Dataset 인스턴스 생성\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df) # 테스트는 학습 후 최종 평가에만 사용\n",
    "\n",
    "# 학습에 사용할 단일 하이퍼파라미터 조합 설정\n",
    "best_params = {\n",
    "    'embedding_dim': 64,\n",
    "    'aspect_embedding_dim': 96, # 속성 임베딩 차원\n",
    "    'sentiment_embedding_dim': 32, # 감성 임베딩 차원 (새로 추가)\n",
    "    'num_attn_heads': 8,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 128,\n",
    "    'dropout_rate': 0.2,\n",
    "    'user_biz_mlp_dims': [128, 64],\n",
    "    'aspect_mlp_dims': [64, 32],\n",
    "    'final_mlp_dims': [32, 16]\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"학습 장치: '{device}'\")\n",
    "\n",
    "best_overall_rmse = float('inf') # 최적 모델 저장을 위한 초기화\n",
    "best_model_path = 'final_best_aatrec_model_multihead_aspect_sentiment.pt' # 최종 최적 모델 저장 경로 (이름 변경)\n",
    "\n",
    "print(f\"현재 파라미터: {best_params}\")\n",
    "\n",
    "# 현재 조합의 하이퍼파라미터 설정\n",
    "EMBEDDING_DIM = best_params['embedding_dim']\n",
    "ASPECT_EMBEDDING_DIM = best_params['aspect_embedding_dim']\n",
    "SENTIMENT_EMBEDDING_DIM = best_params['sentiment_embedding_dim'] # 새로운 파라미터\n",
    "NUM_ATTN_HEADS = best_params['num_attn_heads']\n",
    "LEARNING_RATE = best_params['learning_rate']\n",
    "BATCH_SIZE = best_params['batch_size']\n",
    "DROPOUT_RATE = best_params['dropout_rate']\n",
    "USER_BIZ_MLP_DIMS = best_params['user_biz_mlp_dims']\n",
    "ASPECT_MLP_DIMS = best_params['aspect_mlp_dims']\n",
    "FINAL_MLP_DIMS = best_params['final_mlp_dims']\n",
    "\n",
    "# DataLoader 생성 (custom_collate_fn 다시 사용)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "model = AATRec(\n",
    "    num_users, num_businesses, EMBEDDING_DIM,\n",
    "    USER_BIZ_MLP_DIMS, NUM_ASPECT_TERMS, ASPECT_EMBEDDING_DIM,\n",
    "    NUM_SENTIMENTS, SENTIMENT_EMBEDDING_DIM, # 감성 관련 파라미터 전달\n",
    "    NUM_ATTN_HEADS, ASPECT_MLP_DIMS, FINAL_MLP_DIMS, DROPOUT_RATE\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 조기 종료 설정\n",
    "PATIENCE = 5 # 조기 종료 대기 횟수\n",
    "MIN_DELTA = 0.001 # 검증 RMSE 개선을 위한 최소 변화량\n",
    "current_best_val_rmse = float('inf') # 'current_best_val_rmse' 초기화\n",
    "epochs_no_improve = 0\n",
    "\n",
    "NUM_EPOCHS_PER_COMBINATION = 50 # 최대 에포크\n",
    "\n",
    "print(\"\\n--- 모델 학습 시작 ---\")\n",
    "for epoch in range(NUM_EPOCHS_PER_COMBINATION):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in train_loader: # 감성 ID 추가\n",
    "        user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "            user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device) # 감성 ID to device\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_stars = model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "        loss = criterion(predicted_stars, stars)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in val_loader: # 감성 ID 추가\n",
    "            user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "                user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device) # 감성 ID to device\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            predicted_stars = model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "            total_val_loss += criterion(predicted_stars, stars).item()\n",
    "            val_preds.extend(predicted_stars.cpu().numpy())\n",
    "            val_true.extend(stars.cpu().numpy())\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # 모델 출력에서 1~5점 스케일링이 이미 되어 있으므로, 추가 클리핑은 선택 사항이지만 안전을 위해 유지\n",
    "    val_preds_clipped = np.clip(val_preds, 1.0, 5.0)\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true, val_preds_clipped))\n",
    "\n",
    "    sys.stdout.write(f\"\\r  Epoch {epoch+1}/{NUM_EPOCHS_PER_COMBINATION}, \"\n",
    "                     f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                     f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                     f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if current_val_rmse < current_best_val_rmse - MIN_DELTA:\n",
    "        current_best_val_rmse = current_val_rmse\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), best_model_path) # 최적 모델 저장\n",
    "        sys.stdout.write(f\" --> 최적 검증 RMSE 개선됨: {current_best_val_rmse:.4f}. 모델 저장됨.\\n\")\n",
    "        sys.stdout.flush()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == PATIENCE:\n",
    "            sys.stdout.write(f\" --> 조기 종료! {PATIENCE} 에포크 동안 검증 RMSE 개선이 없었습니다.\\n\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "            \n",
    "print(\"\\n--- 모델 학습 완료 ---\")\n",
    "print(f\"최종 저장된 모델의 검증 RMSE: {current_best_val_rmse:.4f}\")\n",
    "print(f\"저장 경로: {best_model_path}\")\n",
    "\n",
    "\n",
    "# --- 최종 모델 테스트 ---\n",
    "print(\"\\n--- 최종 모델 테스트 시작 (최적 파라미터 사용) ---\")\n",
    "\n",
    "if os.path.exists(best_model_path) and best_params:\n",
    "    # 최적 파라미터로 모델 재구성 (저장된 모델 로드)\n",
    "    final_model = AATRec(\n",
    "        num_users, num_businesses, best_params['embedding_dim'],\n",
    "        best_params['user_biz_mlp_dims'], NUM_ASPECT_TERMS, best_params['aspect_embedding_dim'],\n",
    "        NUM_SENTIMENTS, best_params['sentiment_embedding_dim'], # 감성 관련 파라미터 전달\n",
    "        best_params['num_attn_heads'], best_params['aspect_mlp_dims'], best_params['final_mlp_dims'], best_params['dropout_rate']\n",
    "    )\n",
    "    final_model.load_state_dict(torch.load(best_model_path, map_location=device)) # map_location 추가\n",
    "    final_model.to(device)\n",
    "    print(f\"최적의 모델 가중치 '{best_model_path}' 로드 완료.\")\n",
    "else:\n",
    "    print(\"경고: 최적의 모델 가중치를 찾을 수 없거나 최적 파라미터가 설정되지 않았습니다. 테스트를 건너뜜.\")\n",
    "    sys.exit()\n",
    "\n",
    "# 테스트 로더도 custom_collate_fn 사용\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "final_model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in test_loader: # 감성 ID 추가\n",
    "        user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "            user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device) # 감성 ID to device\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        predicted_stars = final_model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "        test_preds.extend(predicted_stars.cpu().numpy())\n",
    "        test_true.extend(stars.cpu().numpy())\n",
    "\n",
    "# 예측 범위 클리핑 (1점 ~ 5점)\n",
    "test_preds_clipped = np.clip(test_preds, 1.0, 5.0)\n",
    "\n",
    "mse = mean_squared_error(test_true, test_preds_clipped)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true, test_preds_clipped)\n",
    "mape = mean_absolute_percentage_error(test_true, test_preds_clipped)\n",
    "\n",
    "print(f\"\\n--- 최종 모델 성능 평가 (최적 파라미터) ---\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"사용된 최적 하이퍼파라미터: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5dcd98a-6c0d-4cb0-90dc-5a1051ed197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1단계: 데이터 로드 및 전처리 시작 ---\n",
      "'447796'개의 리뷰 데이터를 성공적으로 로드했습니다.\n",
      "'27807'명의 고유 사용자와 '6831'개의 고유 레스토랑을 매핑했습니다.\n",
      "학습 세트 크기: 313457개 리뷰\n",
      "검증 세트 크기: 44779개 리뷰\n",
      "테스트 세트 크기: 89560개 리뷰\n",
      "\n",
      "--- 2단계: absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 시작 ---\n",
      "'absa_atepc_results.json' 파일에서 447796개의 리뷰 속성 데이터를 성공적으로 로드했습니다.\n",
      "동적으로 구축된 속성 어휘집 크기 (학습 데이터 기반): 39160개 키워드\n",
      "어휘집 상위 10개 키워드: [('food', 3), ('service', 4), ('staff', 5), ('place', 6), ('atmosphere', 7), ('prices', 8), ('they', 9), ('price', 10), ('pizza', 11), ('it', 12)]...\n",
      "구축된 감성 어휘집 크기: 5개 감성 ([('<PAD>', 0), ('<UNK>', 1), ('positive', 2), ('negative', 3), ('neutral', 4)])\n",
      "absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 완료.\n",
      "\n",
      "--- 2.5단계: 로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 시작 ---\n",
      "로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 완료.\n",
      "\n",
      "--- 3단계: AAT-Rec 모델 구성 요소 정의 (감성 통합) ---\n",
      "AATRec 모델 구성 요소 정의 완료.\n",
      "\n",
      "--- 4단계: 그리드 서치를 통한 모델 학습 및 저장 시작 ---\n",
      "학습 장치: 'cuda'\n",
      "총 9개의 하이퍼파라미터 조합을 탐색합니다.\n",
      "\n",
      "--- 조합 1/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 64, 'sentiment_embedding_dim': 16, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 1/30, Train Loss: 0.9054, Val Loss: 0.7311, Val RMSE: 0.8550 --> 전체 최적 RMSE 개선됨: 0.8550. 모델 저장됨.\n",
      "    Epoch 2/30, Train Loss: 0.8001, Val Loss: 0.7200, Val RMSE: 0.8486 --> 전체 최적 RMSE 개선됨: 0.8486. 모델 저장됨.\n",
      "    Epoch 3/30, Train Loss: 0.7793, Val Loss: 0.7190, Val RMSE: 0.8479 --> 전체 최적 RMSE 개선됨: 0.8479. 모델 저장됨.\n",
      "    Epoch 4/30, Train Loss: 0.7616, Val Loss: 0.7054, Val RMSE: 0.8399 --> 전체 최적 RMSE 개선됨: 0.8399. 모델 저장됨.\n",
      "    Epoch 5/30, Train Loss: 0.7473, Val Loss: 0.7038, Val RMSE: 0.8390 --> 전체 최적 RMSE 개선됨: 0.8390. 모델 저장됨.\n",
      "    Epoch 6/30, Train Loss: 0.7336, Val Loss: 0.6980, Val RMSE: 0.8355 --> 전체 최적 RMSE 개선됨: 0.8355. 모델 저장됨.\n",
      "    Epoch 7/30, Train Loss: 0.7234, Val Loss: 0.6898, Val RMSE: 0.8306 --> 전체 최적 RMSE 개선됨: 0.8306. 모델 저장됨.\n",
      "    Epoch 9/30, Train Loss: 0.7023, Val Loss: 0.6897, Val RMSE: 0.8305 --> 전체 최적 RMSE 개선됨: 0.8305. 모델 저장됨.\n",
      "    Epoch 12/30, Train Loss: 0.6763, Val Loss: 0.7014, Val RMSE: 0.8375\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 2/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 64, 'sentiment_embedding_dim': 32, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 9/30, Train Loss: 0.7027, Val Loss: 0.6895, Val RMSE: 0.8304 --> 전체 최적 RMSE 개선됨: 0.8304. 모델 저장됨.\n",
      "    Epoch 14/30, Train Loss: 0.6576, Val Loss: 0.6913, Val RMSE: 0.8314\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 3/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 64, 'sentiment_embedding_dim': 48, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 10/30, Train Loss: 0.6955, Val Loss: 0.6985, Val RMSE: 0.8358\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 4/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 16, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 13/30, Train Loss: 0.6573, Val Loss: 0.7072, Val RMSE: 0.8409\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 5/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 32, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 16/30, Train Loss: 0.6344, Val Loss: 0.6925, Val RMSE: 0.8322\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 6/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 48, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 15/30, Train Loss: 0.6457, Val Loss: 0.6873, Val RMSE: 0.8290 --> 전체 최적 RMSE 개선됨: 0.8290. 모델 저장됨.\n",
      "    Epoch 20/30, Train Loss: 0.6064, Val Loss: 0.7118, Val RMSE: 0.8437\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 7/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 128, 'sentiment_embedding_dim': 16, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 12/30, Train Loss: 0.6579, Val Loss: 0.6984, Val RMSE: 0.8357\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 8/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 128, 'sentiment_embedding_dim': 32, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 10/30, Train Loss: 0.6787, Val Loss: 0.7151, Val RMSE: 0.8456\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 조합 9/9 학습 시작 ---\n",
      "현재 파라미터: {'aspect_embedding_dim': 128, 'sentiment_embedding_dim': 48, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "    Epoch 12/30, Train Loss: 0.6606, Val Loss: 0.6949, Val RMSE: 0.8336\n",
      "    조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\n",
      "\n",
      "--- 그리드 서치 완료 ---\n",
      "최종 최적 RMSE: 0.8290\n",
      "최적 하이퍼파라미터: {'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 48, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n",
      "최적 모델 저장 경로: best_aatrec_model_grid_search_final_fixed_params.pt\n",
      "\n",
      "--- 최종 모델 테스트 시작 (그리드 서치를 통해 찾은 최적 파라미터 사용) ---\n",
      "최적의 모델 가중치 'best_aatrec_model_grid_search_final_fixed_params.pt' 로드 완료.\n",
      "\n",
      "--- 최종 모델 성능 평가 (그리드 서치를 통해 찾은 최적 파라미터) ---\n",
      "Root Mean Squared Error (RMSE): 0.8563\n",
      "Mean Absolute Error (MAE): 0.6840\n",
      "Mean Absolute Percentage Error (MAPE): 24.52%\n",
      "Mean Squared Error (MSE): 0.7333\n",
      "사용된 최적 하이퍼파라미터: {'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 48, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'embedding_dim': 64, 'learning_rate': 0.0001, 'batch_size': 128, 'final_mlp_dims': [32, 16], 'dropout_rate': 0.2, 'num_attn_heads': 8}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "from collections import Counter\n",
    "import os\n",
    "import itertools # 조합 생성을 위해 추가\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return np.nan # 모든 y_true가 0인 경우 NaN 반환\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 0. 파일 경로 설정 ---\n",
    "review_json_path = 'review.json'\n",
    "absa_results_path = 'absa_atepc_results.json' \n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "print(\"--- 1단계: 데이터 로드 및 전처리 시작 ---\")\n",
    "try:\n",
    "    data = []\n",
    "    with open(review_json_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"'{len(df)}'개의 리뷰 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{review_json_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"오류: '{review_json_path}' 파일 파싱 중 오류 발생: {e}. 파일 내용이 올바른 JSON 형식을 따르는지 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['business_idx'] = business_encoder.fit_transform(df['business_id'])\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"'{num_users}'명의 고유 사용자와 '{num_businesses}'개의 고유 레스토랑을 매핑했습니다.\")\n",
    "\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='ms') # timestamp in milliseconds\n",
    "except ValueError:\n",
    "    df['date'] = pd.to_datetime(df['date']) # assume standard date string format if ms fails\n",
    "\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "total_reviews = len(df)\n",
    "train_split = int(total_reviews * 0.7)\n",
    "val_split_idx = int(total_reviews * (0.7 + 0.1)) # 검증 세트의 끝 인덱스\n",
    "train_df = df.iloc[:train_split].copy()\n",
    "val_df = df.iloc[train_split:val_split_idx].copy()\n",
    "test_df = df.iloc[val_split_idx:].copy() # 나머지 20%를 테스트 세트로\n",
    "print(f\"학습 세트 크기: {len(train_df)}개 리뷰\")\n",
    "print(f\"검증 세트 크기: {len(val_df)}개 리뷰\")\n",
    "print(f\"테스트 세트 크기: {len(test_df)}개 리뷰\")\n",
    "\n",
    "print(\"\\n--- 2단계: absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 시작 ---\")\n",
    "\n",
    "absa_data = {}\n",
    "try:\n",
    "    with open(absa_results_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            absa_data[entry['review_id']] = entry['aspects']\n",
    "    print(f\"'{absa_results_path}' 파일에서 {len(absa_data)}개의 리뷰 속성 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{absa_results_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"오류: '{absa_results_path}' 파일 파싱 중 오류 발생: {e}. 파일 내용이 올바른 JSON 형식을 따르는지 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "all_extracted_aspect_terms_from_file = []\n",
    "all_extracted_sentiments_from_file = []\n",
    "\n",
    "for review_id in train_df['review_id']:\n",
    "    aspects = absa_data.get(review_id, [])\n",
    "    if not aspects: # 속성이 없는 경우 'general' 및 'neutral'로 대체\n",
    "        all_extracted_aspect_terms_from_file.append('general')\n",
    "        all_extracted_sentiments_from_file.append('neutral')\n",
    "    else:\n",
    "        for aspect in aspects:\n",
    "            if 'term' in aspect and 'sentiment' in aspect:\n",
    "                all_extracted_aspect_terms_from_file.append(aspect['term'].lower())\n",
    "                # 감성 라벨을 소문자로 통일 (Positive, Negative, Neutral)\n",
    "                all_extracted_sentiments_from_file.append(aspect['sentiment'].lower())\n",
    "\n",
    "# 속성 키워드 어휘집 구축\n",
    "term_counts = Counter(all_extracted_aspect_terms_from_file)\n",
    "# <PAD>는 0번, <UNK>는 1번, 'general'은 2번 인덱스를 가집니다.\n",
    "ASPECT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'general': 2}\n",
    "next_id = 3\n",
    "MIN_TERM_FREQUENCY = 1 # 어휘집 구축 시 최소 등장 빈도\n",
    "filtered_terms = [term for term, count in term_counts.items() if count >= MIN_TERM_FREQUENCY]\n",
    "filtered_terms.sort(key=lambda x: term_counts[x], reverse=True)\n",
    "\n",
    "for term in filtered_terms:\n",
    "    if term not in ASPECT_TO_ID:\n",
    "        ASPECT_TO_ID[term] = next_id\n",
    "        next_id += 1\n",
    "NUM_ASPECT_TERMS = len(ASPECT_TO_ID)\n",
    "\n",
    "# 감성 어휘집 구축 (고정된 긍정, 부정, 중립)\n",
    "SENTIMENT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'positive': 2, 'negative': 3, 'neutral': 4}\n",
    "NUM_SENTIMENTS = len(SENTIMENT_TO_ID)\n",
    "\n",
    "print(f\"동적으로 구축된 속성 어휘집 크기 (학습 데이터 기반): {NUM_ASPECT_TERMS}개 키워드\")\n",
    "print(f\"어휘집 상위 10개 키워드: {list(ASPECT_TO_ID.items())[3:13]}...\")\n",
    "print(f\"구축된 감성 어휘집 크기: {NUM_SENTIMENTS}개 감성 ({list(SENTIMENT_TO_ID.items())})\")\n",
    "print(\"absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 완료.\")\n",
    "\n",
    "print(\"\\n--- 2.5단계: 로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 시작 ---\")\n",
    "\n",
    "def map_aspect_and_sentiment_ids_from_file(df_subset, absa_data_map, aspect_to_id_map, sentiment_to_id_map):\n",
    "    extracted_aspect_ids_list = []\n",
    "    extracted_sentiment_ids_list = []\n",
    "    \n",
    "    for _, row in df_subset.iterrows():\n",
    "        review_id = row['review_id']\n",
    "        aspects_for_review = absa_data_map.get(review_id, [])\n",
    "        \n",
    "        aspect_ids_for_review = []\n",
    "        sentiment_ids_for_review = []\n",
    "        \n",
    "        if aspects_for_review:\n",
    "            for aspect in aspects_for_review:\n",
    "                if 'term' in aspect and 'sentiment' in aspect:\n",
    "                    aspect_id = aspect_to_id_map.get(aspect['term'].lower(), aspect_to_id_map['<UNK>'])\n",
    "                    sentiment_id = sentiment_to_id_map.get(aspect['sentiment'].lower(), sentiment_to_id_map['<UNK>'])\n",
    "                    \n",
    "                    aspect_ids_for_review.append(aspect_id)\n",
    "                    sentiment_ids_for_review.append(sentiment_id)\n",
    "        \n",
    "        if not aspect_ids_for_review:\n",
    "            aspect_ids_for_review.append(aspect_to_id_map['general'])\n",
    "            sentiment_ids_for_review.append(sentiment_to_id_map['neutral'])\n",
    "            \n",
    "        extracted_aspect_ids_list.append(aspect_ids_for_review)\n",
    "        extracted_sentiment_ids_list.append(sentiment_ids_for_review)\n",
    "        \n",
    "    return extracted_aspect_ids_list, extracted_sentiment_ids_list\n",
    "\n",
    "train_df['extracted_aspect_ids'], train_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(train_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "val_df['extracted_aspect_ids'], val_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(val_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "test_df['extracted_aspect_ids'], test_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(test_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "\n",
    "print(\"로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 완료.\")\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_indices = torch.tensor(df['user_idx'].values, dtype=torch.long)\n",
    "        self.business_indices = torch.tensor(df['business_idx'].values, dtype=torch.long)\n",
    "        self.extracted_aspect_ids = df['extracted_aspect_ids'].values.tolist()\n",
    "        self.extracted_sentiment_ids = df['extracted_sentiment_ids'].values.tolist()\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.user_indices[idx], self.business_indices[idx],\n",
    "                self.extracted_aspect_ids[idx], self.extracted_sentiment_ids[idx],\n",
    "                self.stars[idx])\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    user_indices, business_indices, extracted_aspect_ids_list, extracted_sentiment_ids_list, stars = zip(*batch)\n",
    "\n",
    "    user_indices = torch.stack(user_indices)\n",
    "    business_indices = torch.stack(business_indices)\n",
    "    stars = torch.stack(stars)\n",
    "\n",
    "    max_aspect_len = max(len(ids) for ids in extracted_aspect_ids_list)\n",
    "    \n",
    "    padded_aspect_ids = [ids + [ASPECT_TO_ID['<PAD>']] * (max_aspect_len - len(ids)) for ids in extracted_aspect_ids_list]\n",
    "    padded_aspect_ids_tensor = torch.tensor(padded_aspect_ids, dtype=torch.long)\n",
    "    \n",
    "    padded_sentiment_ids = [ids + [SENTIMENT_TO_ID['<PAD>']] * (max_aspect_len - len(ids)) for ids in extracted_sentiment_ids_list]\n",
    "    padded_sentiment_ids_tensor = torch.tensor(padded_sentiment_ids, dtype=torch.long)\n",
    "    \n",
    "    attn_mask = (padded_aspect_ids_tensor == ASPECT_TO_ID['<PAD>'])\n",
    "\n",
    "    return user_indices, business_indices, padded_aspect_ids_tensor, padded_sentiment_ids_tensor, stars, attn_mask\n",
    "\n",
    "print(\"\\n--- 3단계: AAT-Rec 모델 구성 요소 정의 (감성 통합) ---\")\n",
    "\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims, dropout_rate):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "\n",
    "    def forward(self, user_indices, business_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        business_emb = self.business_embedding(business_indices)\n",
    "        combined_emb = torch.cat((user_emb, business_emb), dim=-1)\n",
    "        interaction_features = self.mlp(combined_emb)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectTermExtractionModule(nn.Module):\n",
    "    def __init__(self, num_aspect_terms, aspect_embedding_dim, num_sentiments, sentiment_embedding_dim, num_heads, mlp_dims, dropout_rate):\n",
    "        super(ReviewAspectTermExtractionModule, self).__init__()\n",
    "        self.aspect_embedding = nn.Embedding(num_aspect_terms, aspect_embedding_dim, padding_idx=ASPECT_TO_ID['<PAD>'])\n",
    "        self.sentiment_embedding = nn.Embedding(num_sentiments, sentiment_embedding_dim, padding_idx=SENTIMENT_TO_ID['<PAD>'])\n",
    "        \n",
    "        combined_embedding_dim = aspect_embedding_dim + sentiment_embedding_dim\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=combined_embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = combined_embedding_dim\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0: # 드롭아웃 레이어 조건부 추가\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "            \n",
    "    def forward(self, pre_extracted_aspect_ids_batch, pre_extracted_sentiment_ids_batch, attn_mask):\n",
    "        embedded_terms = self.aspect_embedding(pre_extracted_aspect_ids_batch)\n",
    "        embedded_sentiments = self.sentiment_embedding(pre_extracted_sentiment_ids_batch)\n",
    "        \n",
    "        combined_embeddings = torch.cat((embedded_terms, embedded_sentiments), dim=-1)\n",
    "        \n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            combined_embeddings, \n",
    "            combined_embeddings, \n",
    "            combined_embeddings, \n",
    "            key_padding_mask=attn_mask\n",
    "        )\n",
    "\n",
    "        valid_attn_output = attn_output * (~attn_mask.unsqueeze(-1)).float()\n",
    "        pooled_output = valid_attn_output.sum(dim=1) / (~attn_mask).sum(dim=1, keepdim=True).float().clamp(min=1)\n",
    "        \n",
    "        aspect_features = self.mlp(pooled_output)\n",
    "        return aspect_features\n",
    "\n",
    "class RatingPredictionModule(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dims, dropout_rate):\n",
    "        super(RatingPredictionModule, self).__init__()\n",
    "        layers = []\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0: # 드롭아웃 레이어 조건부 추가\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, combined_features):\n",
    "        raw_prediction = self.mlp(combined_features)\n",
    "        prediction = torch.sigmoid(raw_prediction) * 4 + 1\n",
    "        return prediction\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, num_aspect_terms, aspect_embedding_dim,\n",
    "                 num_sentiments, sentiment_embedding_dim,\n",
    "                 num_attn_heads, aspect_mlp_dims, final_mlp_dims, dropout_rate):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims, dropout_rate\n",
    "        )\n",
    "        self.aspect_extraction_module = ReviewAspectTermExtractionModule(\n",
    "            num_aspect_terms, aspect_embedding_dim, num_sentiments, sentiment_embedding_dim,\n",
    "            num_attn_heads, aspect_mlp_dims, dropout_rate\n",
    "        )\n",
    "        combined_feature_dim = self.customer_restaurant_module.output_dim + \\\n",
    "                               self.aspect_extraction_module.output_dim\n",
    "        self.rating_prediction_module = RatingPredictionModule(\n",
    "            combined_feature_dim, final_mlp_dims, dropout_rate\n",
    "        )\n",
    "    def forward(self, user_indices, business_indices, pre_extracted_aspect_ids, pre_extracted_sentiment_ids, attn_mask):\n",
    "        interaction_features = self.customer_restaurant_module(user_indices, business_indices)\n",
    "        aspect_features = self.aspect_extraction_module(pre_extracted_aspect_ids, pre_extracted_sentiment_ids, attn_mask)\n",
    "        combined_features = torch.cat((interaction_features, aspect_features), dim=-1)\n",
    "        predicted_rating = self.rating_prediction_module(combined_features).squeeze()\n",
    "        return predicted_rating\n",
    "\n",
    "print(\"AATRec 모델 구성 요소 정의 완료.\")\n",
    "\n",
    "\n",
    "# --- 4. 하이퍼파라미터 설정 및 그리드 서치 수행 ---\n",
    "\n",
    "print(\"\\n--- 4단계: 그리드 서치를 통한 모델 학습 및 저장 시작 ---\")\n",
    "\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"학습 장치: '{device}'\")\n",
    "\n",
    "# --- 고정된 하이퍼파라미터 (명시된 대로) ---\n",
    "FIXED_EMBEDDING_DIM = 64\n",
    "FIXED_LEARNING_RATE = 1e-4\n",
    "FIXED_BATCH_SIZE = 128\n",
    "FIXED_FINAL_MLP_DIMS = [32, 16] # 2개의 은닉층 + 1개 출력층 = 총 3개 선형 레이어\n",
    "FIXED_DROPOUT_RATE = 0.2 # 드롭아웃 고정 \n",
    "FIXED_NUM_ATTN_HEADS = 8 # 헤드 수 고정\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 그리드 서치할 나머지 하이퍼파라미터 공간 정의\n",
    "param_grid = {\n",
    "    'aspect_embedding_dim': [64, 96, 128], # 속성 키워드 임베딩 차원\n",
    "    'sentiment_embedding_dim': [16, 32, 48], # 감성 임베딩 차원 (총합 고려하여 조절)\n",
    "    'user_biz_mlp_dims': [[128, 64]], # [256, 128] 제거\n",
    "    'aspect_mlp_dims': [[64, 32]], # [128, 64] 제거\n",
    "}\n",
    "\n",
    "best_overall_rmse = float('inf')\n",
    "best_params = None\n",
    "best_model_path = 'best_aatrec_model_grid_search_final_fixed_params.pt' # 파일명 변경\n",
    "\n",
    "# 하이퍼파라미터 조합 생성\n",
    "keys = param_grid.keys()\n",
    "combinations = itertools.product(*param_grid.values())\n",
    "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
    "print(f\"총 {total_combinations}개의 하이퍼파라미터 조합을 탐색합니다.\")\n",
    "\n",
    "for i, values in enumerate(combinations):\n",
    "    current_params = dict(zip(keys, values))\n",
    "    \n",
    "    # 고정된 파라미터 추가\n",
    "    current_params['embedding_dim'] = FIXED_EMBEDDING_DIM\n",
    "    current_params['learning_rate'] = FIXED_LEARNING_RATE\n",
    "    current_params['batch_size'] = FIXED_BATCH_SIZE\n",
    "    current_params['final_mlp_dims'] = FIXED_FINAL_MLP_DIMS \n",
    "    current_params['dropout_rate'] = FIXED_DROPOUT_RATE \n",
    "    current_params['num_attn_heads'] = FIXED_NUM_ATTN_HEADS \n",
    "\n",
    "    print(f\"\\n--- 조합 {i+1}/{total_combinations} 학습 시작 ---\")\n",
    "    print(f\"현재 파라미터: {current_params}\")\n",
    "\n",
    "    EMBEDDING_DIM = current_params['embedding_dim']\n",
    "    ASPECT_EMBEDDING_DIM = current_params['aspect_embedding_dim']\n",
    "    SENTIMENT_EMBEDDING_DIM = current_params['sentiment_embedding_dim']\n",
    "    NUM_ATTN_HEADS = current_params['num_attn_heads']\n",
    "    LEARNING_RATE = current_params['learning_rate']\n",
    "    BATCH_SIZE = current_params['batch_size']\n",
    "    DROPOUT_RATE = current_params['dropout_rate']\n",
    "    USER_BIZ_MLP_DIMS = current_params['user_biz_mlp_dims']\n",
    "    ASPECT_MLP_DIMS = current_params['aspect_mlp_dims']\n",
    "    FINAL_MLP_DIMS = current_params['final_mlp_dims']\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "    model = AATRec(\n",
    "        num_users, num_businesses, EMBEDDING_DIM,\n",
    "        USER_BIZ_MLP_DIMS, NUM_ASPECT_TERMS, ASPECT_EMBEDDING_DIM,\n",
    "        NUM_SENTIMENTS, SENTIMENT_EMBEDDING_DIM,\n",
    "        NUM_ATTN_HEADS, ASPECT_MLP_DIMS, FINAL_MLP_DIMS, DROPOUT_RATE\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    PATIENCE = 5\n",
    "    MIN_DELTA = 0.001\n",
    "    current_val_rmse_for_combo = float('inf') \n",
    "    epochs_no_improve = 0\n",
    "    NUM_EPOCHS_PER_COMBINATION = 30 \n",
    "\n",
    "    for epoch in range(NUM_EPOCHS_PER_COMBINATION):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in train_loader:\n",
    "            user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "                user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device)\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predicted_stars = model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask)\n",
    "            loss = criterion(predicted_stars, stars)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        with torch.no_grad():\n",
    "            for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in val_loader:\n",
    "                user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "                    user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device)\n",
    "                attn_mask = attn_mask.to(device)\n",
    "                predicted_stars = model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask)\n",
    "                total_val_loss += criterion(predicted_stars, stars).item()\n",
    "                val_preds.extend(predicted_stars.cpu().numpy())\n",
    "                val_true.extend(stars.cpu().numpy())\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        val_preds_clipped = np.clip(val_preds, 1.0, 5.0)\n",
    "        current_val_rmse = np.sqrt(mean_squared_error(val_true, val_preds_clipped))\n",
    "\n",
    "        sys.stdout.write(f\"\\r    Epoch {epoch+1}/{NUM_EPOCHS_PER_COMBINATION}, \"\n",
    "                         f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                         f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                         f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if current_val_rmse < current_val_rmse_for_combo - MIN_DELTA:\n",
    "            current_val_rmse_for_combo = current_val_rmse\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            \n",
    "        if current_val_rmse < best_overall_rmse:\n",
    "            best_overall_rmse = current_val_rmse\n",
    "            best_params = current_params.copy() \n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            sys.stdout.write(f\" --> 전체 최적 RMSE 개선됨: {best_overall_rmse:.4f}. 모델 저장됨.\\n\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if epochs_no_improve == PATIENCE:\n",
    "            sys.stdout.write(f\"\\n    조기 종료! {PATIENCE} 에포크 동안 검증 RMSE 개선이 없었습니다 (현재 조합).\\n\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "\n",
    "print(\"\\n--- 그리드 서치 완료 ---\")\n",
    "print(f\"최종 최적 RMSE: {best_overall_rmse:.4f}\")\n",
    "print(f\"최적 하이퍼파라미터: {best_params}\")\n",
    "print(f\"최적 모델 저장 경로: {best_model_path}\")\n",
    "\n",
    "\n",
    "# --- 최종 모델 테스트 ---\n",
    "print(\"\\n--- 최종 모델 테스트 시작 (그리드 서치를 통해 찾은 최적 파라미터 사용) ---\")\n",
    "\n",
    "if os.path.exists(best_model_path) and best_params:\n",
    "    final_model = AATRec(\n",
    "        num_users, num_businesses, best_params['embedding_dim'],\n",
    "        best_params['user_biz_mlp_dims'], NUM_ASPECT_TERMS, best_params['aspect_embedding_dim'],\n",
    "        NUM_SENTIMENTS, best_params['sentiment_embedding_dim'],\n",
    "        best_params['num_attn_heads'], best_params['aspect_mlp_dims'], best_params['final_mlp_dims'], best_params['dropout_rate']\n",
    "    )\n",
    "    final_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    final_model.to(device)\n",
    "    print(f\"최적의 모델 가중치 '{best_model_path}' 로드 완료.\")\n",
    "else:\n",
    "    print(\"경고: 최적의 모델 가중치를 찾을 수 없거나 최적 파라미터가 설정되지 않았습니다. 테스트를 건너뜜.\")\n",
    "    sys.exit()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "final_model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in test_loader:\n",
    "        user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "            user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        predicted_stars = final_model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask)\n",
    "        test_preds.extend(predicted_stars.cpu().numpy())\n",
    "        test_true.extend(stars.cpu().numpy())\n",
    "\n",
    "test_preds_clipped = np.clip(test_preds, 1.0, 5.0)\n",
    "\n",
    "mse = mean_squared_error(test_true, test_preds_clipped)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true, test_preds_clipped)\n",
    "mape = mean_absolute_percentage_error(test_true, test_preds_clipped)\n",
    "\n",
    "print(f\"\\n--- 최종 모델 성능 평가 (그리드 서치를 통해 찾은 최적 파라미터) ---\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"사용된 최적 하이퍼파라미터: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6c76f-6476-4ae8-b969-923cdb4e31a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My ABSA Project 3.10)",
   "language": "python",
   "name": "my_absa_project_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
