{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07416759",
   "metadata": {},
   "source": [
    "#### 평점 기반 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a86251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중: review_5up_5aspect_3sentiment_vectorized_clean.json\n",
      "총 451,185개 평점, 28,465명 사용자, 6,832개 아이템\n",
      "학습/테스트 데이터 분리 중...\n",
      "학습: 422,720개, 테스트: 28,465개\n",
      "아이템-사용자 맵 구성 중...\n",
      "아이템 유사도 계산 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "아이템 유사도 계산: 100%|██████████| 6828/6828 [03:30<00:00, 32.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위 5개 아이템 추천 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28465/28465 [06:04<00:00, 78.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성능 평가 중...\n",
      "Precision@5: 0.0561\n",
      "Recall@5: 0.0561\n",
      "NDCG@5: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "간단한 Item-based CF 추천 시스템 (Jupyter Notebook용)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_rating(path):\n",
    "    \"\"\"평점 데이터를 로드합니다.\"\"\"\n",
    "    rows = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            rows.append(\n",
    "                {\"user\": d[\"user_id\"], \"biz\": d[\"business_id\"], \"stars\": d[\"stars\"]}\n",
    "            )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def leave_one_out(ratings):\n",
    "    \"\"\"Leave-One-Out 방식으로 학습/테스트 데이터를 분리합니다.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    train_idx = []\n",
    "    test = {}  # user->biz\n",
    "\n",
    "    for u, grp in ratings.groupby(\"user\"):\n",
    "        idx = grp.index.values\n",
    "        if len(idx) > 1:\n",
    "            hold = np.random.choice(idx)\n",
    "            test[u] = ratings.loc[hold, \"biz\"]\n",
    "            train_idx.extend([i for i in idx if i != hold])\n",
    "        else:\n",
    "            train_idx.extend(idx)\n",
    "\n",
    "    return ratings.loc[train_idx].reset_index(drop=True), test\n",
    "\n",
    "\n",
    "def build_item_user_maps(ratings):\n",
    "    \"\"\"아이템-사용자 및 사용자-아이템 맵을 구성합니다.\"\"\"\n",
    "    item_users = defaultdict(dict)\n",
    "    user_items = defaultdict(dict)\n",
    "\n",
    "    for _, r in ratings.iterrows():\n",
    "        item_users[r[\"biz\"]][r[\"user\"]] = r[\"stars\"]\n",
    "        user_items[r[\"user\"]][r[\"biz\"]] = r[\"stars\"]\n",
    "\n",
    "    return item_users, user_items\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"두 벡터 간의 코사인 유사도를 계산합니다.\"\"\"\n",
    "    common = set(a) & set(b)\n",
    "    if not common:\n",
    "        return 0.0\n",
    "\n",
    "    num = sum(a[u] * b[u] for u in common)\n",
    "    den = (\n",
    "        math.sqrt(sum(v * v for v in a.values()))\n",
    "        * math.sqrt(sum(v * v for v in b.values()))\n",
    "        + 1e-9\n",
    "    )\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def precompute_item_sim(item_users):\n",
    "    \"\"\"모든 아이템 쌍 간의 유사도를 미리 계산합니다.\"\"\"\n",
    "    items = list(item_users)\n",
    "    sims = defaultdict(dict)\n",
    "\n",
    "    for i, a in tqdm(enumerate(items), total=len(items), desc=\"아이템 유사도 계산\"):\n",
    "        for b in items[i + 1:]:\n",
    "            s = cosine_similarity(item_users[a], item_users[b])\n",
    "            if s > 0:\n",
    "                sims[a][b] = s\n",
    "                sims[b][a] = s\n",
    "\n",
    "    return sims\n",
    "\n",
    "\n",
    "def recommend(user, user_items, item_sims, n=5):\n",
    "    \"\"\"사용자에게 추천할 상위 N개 아이템을 반환합니다.\"\"\"\n",
    "    seen = set(user_items[user].keys())\n",
    "    scores = defaultdict(float)\n",
    "\n",
    "    for item, rating in user_items[user].items():\n",
    "        for similar_item, sim in item_sims.get(item, {}).items():\n",
    "            if similar_item not in seen:\n",
    "                scores[similar_item] += sim * rating\n",
    "\n",
    "    return [item for item, _ in sorted(scores.items(), key=lambda x: -x[1])[:n]]\n",
    "\n",
    "\n",
    "def precision_at_k(test, recs, k=5):\n",
    "    return sum(1 for u, gt in test.items() if gt in recs.get(u, [])[:k]) / len(test)\n",
    "\n",
    "\n",
    "def recall_at_k(test, recs, k=5):\n",
    "    return precision_at_k(test, recs, k)\n",
    "\n",
    "\n",
    "def ndcg_at_k(test, recs, k=5):\n",
    "    total = 0.0\n",
    "    for u, gt in test.items():\n",
    "        rec_list = recs.get(u, [])[:k]\n",
    "        if gt in rec_list:\n",
    "            idx = rec_list.index(gt)\n",
    "            total += 1 / math.log2(idx + 2)\n",
    "    return total / len(test)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Jupyter 환경 실행 코드\n",
    "# ================================\n",
    "rating_path = \"review_5up_5aspect_3sentiment_vectorized_clean.json\"  # 경로를 실제 위치에 맞게 수정\n",
    "topn = 5\n",
    "min_ratings = 5\n",
    "\n",
    "print(f\"데이터 로드 중: {rating_path}\")\n",
    "ratings = load_rating(rating_path)\n",
    "\n",
    "user_counts = ratings.groupby(\"user\").size()\n",
    "valid_users = user_counts[user_counts >= min_ratings].index\n",
    "ratings = ratings[ratings[\"user\"].isin(valid_users)]\n",
    "\n",
    "print(\n",
    "    f\"총 {len(ratings):,}개 평점, {ratings['user'].nunique():,}명 사용자, {ratings['biz'].nunique():,}개 아이템\"\n",
    ")\n",
    "\n",
    "print(\"학습/테스트 데이터 분리 중...\")\n",
    "train, test = leave_one_out(ratings)\n",
    "print(f\"학습: {len(train):,}개, 테스트: {len(test):,}개\")\n",
    "\n",
    "print(\"아이템-사용자 맵 구성 중...\")\n",
    "item_users, user_items = build_item_user_maps(train)\n",
    "\n",
    "print(\"아이템 유사도 계산 중...\")\n",
    "item_sims = precompute_item_sim(item_users)\n",
    "\n",
    "print(f\"상위 {topn}개 아이템 추천 중...\")\n",
    "recommendations = {}\n",
    "for user in tqdm(test.keys()):\n",
    "    if user in user_items and len(user_items[user]) > 0:\n",
    "        recommendations[user] = recommend(user, user_items, item_sims, topn)\n",
    "\n",
    "print(\"성능 평가 중...\")\n",
    "p5 = precision_at_k(test, recommendations, 5)\n",
    "r5 = recall_at_k(test, recommendations, 5)\n",
    "n5 = ndcg_at_k(test, recommendations, 5)\n",
    "\n",
    "print(f\"Precision@5: {p5:.4f}\")\n",
    "print(f\"Recall@5: {r5:.4f}\")\n",
    "print(f\"NDCG@5: {n5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6951dd",
   "metadata": {},
   "source": [
    "#### 하이브리드 추천(평점 0.8/ absa0.2)\n",
    "\n",
    "수정하시려면 precompute_hybrid_sims 부분에 alpha값 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중: review_5up_5aspect_3sentiment_vectorized_clean.json\n",
      "총 451,185개 평점, 28,465명 사용자, 6,832개 아이템\n",
      "학습/테스트 데이터 분리 중...\n",
      "학습: 422,720개, 테스트: 28,465개\n",
      "맵 및 감성 벡터 평균 계산 중...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m학습: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개, 테스트: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    134\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m맵 및 감성 벡터 평균 계산 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m item_users, user_items, item_sentiment_avg = \u001b[43mbuild_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m하이브리드 유사도 계산 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    138\u001b[39m item_sims = precompute_hybrid_sims(item_users, item_sentiment_avg, alpha=alpha)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mbuild_maps\u001b[39m\u001b[34m(train_df)\u001b[39m\n\u001b[32m     42\u001b[39m item_sentiments = defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, r \u001b[38;5;129;01min\u001b[39;00m train_df.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     item_users[r[\u001b[33m\"\u001b[39m\u001b[33mbiz\u001b[39m\u001b[33m\"\u001b[39m]][\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m] = r[\u001b[33m\"\u001b[39m\u001b[33mstars\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     45\u001b[39m     user_items[r[\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m]][r[\u001b[33m\"\u001b[39m\u001b[33mbiz\u001b[39m\u001b[33m\"\u001b[39m]] = r[\u001b[33m\"\u001b[39m\u001b[33mstars\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     46\u001b[39m     item_sentiments[r[\u001b[33m\"\u001b[39m\u001b[33mbiz\u001b[39m\u001b[33m\"\u001b[39m]].append(r[\u001b[33m\"\u001b[39m\u001b[33msentiment_vector\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\82104\\anaconda3\\envs\\absa-env\\Lib\\site-packages\\pandas\\core\\series.py:967\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[43mcheck_deprecated_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    968\u001b[39m     key = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\82104\\anaconda3\\envs\\absa-env\\Lib\\site-packages\\pandas\\core\\indexing.py:2656\u001b[39m, in \u001b[36mcheck_deprecated_indexers\u001b[39m\u001b[34m(key)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2645\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m   2646\u001b[39m \u001b[33;03m    -------\u001b[39;00m\n\u001b[32m   2647\u001b[39m \u001b[33;03m    bool\u001b[39;00m\n\u001b[32m   2648\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2649\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   2650\u001b[39m         obj.start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2651\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m obj.stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2652\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (obj.step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m obj.step != \u001b[32m1\u001b[39m)\n\u001b[32m   2653\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2656\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_deprecated_indexers\u001b[39m(key) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2657\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Checks if the key is a deprecated indexer.\"\"\"\u001b[39;00m\n\u001b[32m   2658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2659\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[32m   2660\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[32m   2661\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[32m   2662\u001b[39m     ):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- Load data with sentiment vector -----\n",
    "def load_rating_with_sentiment(path):\n",
    "    rows = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            rows.append({\n",
    "                \"user\": d[\"user_id\"],\n",
    "                \"biz\": d[\"business_id\"],\n",
    "                \"stars\": d[\"stars\"],\n",
    "                \"sentiment_vector\": np.array(d[\"sentiment_vector\"])\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ----- Leave-One-Out split -----\n",
    "def leave_one_out(ratings):\n",
    "    np.random.seed(42)\n",
    "    train_idx = []\n",
    "    test = {}\n",
    "    for u, grp in ratings.groupby(\"user\"):\n",
    "        idx = grp.index.values\n",
    "        if len(idx) > 1:\n",
    "            hold = np.random.choice(idx)\n",
    "            test[u] = ratings.loc[hold, \"biz\"]\n",
    "            train_idx.extend([i for i in idx if i != hold])\n",
    "        else:\n",
    "            train_idx.extend(idx)\n",
    "    return ratings.loc[train_idx].reset_index(drop=True), test\n",
    "\n",
    "# ----- Build mappings -----\n",
    "def build_maps(train_df):\n",
    "    item_users = defaultdict(dict)\n",
    "    user_items = defaultdict(dict)\n",
    "    item_sentiments = defaultdict(list)\n",
    "    for _, r in train_df.iterrows():\n",
    "        item_users[r[\"biz\"]][r[\"user\"]] = r[\"stars\"]\n",
    "        user_items[r[\"user\"]][r[\"biz\"]] = r[\"stars\"]\n",
    "        item_sentiments[r[\"biz\"]].append(r[\"sentiment_vector\"])\n",
    "    # 평균 벡터 계산\n",
    "    item_sentiment_avg = {biz: np.mean(vectors, axis=0) for biz, vectors in item_sentiments.items()}\n",
    "    return item_users, user_items, item_sentiment_avg\n",
    "\n",
    "# ----- Cosine similarity -----\n",
    "def cosine_similarity_dict(a, b):\n",
    "    common = set(a) & set(b)\n",
    "    if not common:\n",
    "        return 0.0\n",
    "    num = sum(a[u] * b[u] for u in common)\n",
    "    den = (\n",
    "        math.sqrt(sum(v * v for v in a.values())) *\n",
    "        math.sqrt(sum(v * v for v in b.values())) + 1e-9\n",
    "    )\n",
    "    return num / den\n",
    "\n",
    "def cosine_similarity_vec(a, b):\n",
    "    if np.linalg.norm(a) == 0 or np.linalg.norm(b) == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
    "\n",
    "# ----- Precompute hybrid item similarities -----\n",
    "def precompute_hybrid_sims(item_users, item_sentiment_avg, alpha=0.8):\n",
    "    items = list(item_users)\n",
    "    sims = defaultdict(dict)\n",
    "\n",
    "    for i, a in tqdm(enumerate(items), total=len(items), desc=\"하이브리드 유사도 계산\"):\n",
    "        for b in items[i + 1:]:\n",
    "            rating_sim = cosine_similarity_dict(item_users[a], item_users[b])\n",
    "            sent_sim = cosine_similarity_vec(\n",
    "                item_sentiment_avg.get(a, np.zeros(15)),\n",
    "                item_sentiment_avg.get(b, np.zeros(15))\n",
    "            )\n",
    "            hybrid_sim = alpha * rating_sim + (1 - alpha) * sent_sim\n",
    "            if hybrid_sim > 0:\n",
    "                sims[a][b] = hybrid_sim\n",
    "                sims[b][a] = hybrid_sim\n",
    "    return sims\n",
    "\n",
    "# ----- Recommendation -----\n",
    "def recommend(user, user_items, item_sims, n=5):\n",
    "    seen = set(user_items[user].keys())\n",
    "    scores = defaultdict(float)\n",
    "    for item, rating in user_items[user].items():\n",
    "        for similar_item, sim in item_sims.get(item, {}).items():\n",
    "            if similar_item not in seen:\n",
    "                scores[similar_item] += sim * rating\n",
    "    return [item for item, _ in sorted(scores.items(), key=lambda x: -x[1])[:n]]\n",
    "\n",
    "# ----- Evaluation -----\n",
    "def precision_at_k(test, recs, k=5):\n",
    "    return sum(1 for u, gt in test.items() if gt in recs.get(u, [])[:k]) / len(test)\n",
    "\n",
    "def recall_at_k(test, recs, k=5):\n",
    "    return precision_at_k(test, recs, k)\n",
    "\n",
    "def ndcg_at_k(test, recs, k=5):\n",
    "    total = 0.0\n",
    "    for u, gt in test.items():\n",
    "        rec_list = recs.get(u, [])[:k]\n",
    "        if gt in rec_list:\n",
    "            idx = rec_list.index(gt)\n",
    "            total += 1 / math.log2(idx + 2)\n",
    "    return total / len(test)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 실행 코드 (Jupyter 셀에서 사용)\n",
    "# ================================\n",
    "rating_path = \"review_5up_5aspect_3sentiment_vectorized_clean.json\"\n",
    "topn = 5\n",
    "min_ratings = 5\n",
    "alpha = 0.8  # 평점 기반 가중치\n",
    "\n",
    "print(f\"데이터 로드 중: {rating_path}\")\n",
    "ratings = load_rating_with_sentiment(rating_path)\n",
    "\n",
    "user_counts = ratings.groupby(\"user\").size()\n",
    "valid_users = user_counts[user_counts >= min_ratings].index\n",
    "ratings = ratings[ratings[\"user\"].isin(valid_users)]\n",
    "\n",
    "print(f\"총 {len(ratings):,}개 평점, {ratings['user'].nunique():,}명 사용자, {ratings['biz'].nunique():,}개 아이템\")\n",
    "\n",
    "print(\"학습/테스트 데이터 분리 중...\")\n",
    "train, test = leave_one_out(ratings)\n",
    "print(f\"학습: {len(train):,}개, 테스트: {len(test):,}개\")\n",
    "\n",
    "print(\"맵 및 감성 벡터 평균 계산 중...\")\n",
    "item_users, user_items, item_sentiment_avg = build_maps(train)\n",
    "\n",
    "print(\"하이브리드 유사도 계산 중...\")\n",
    "item_sims = precompute_hybrid_sims(item_users, item_sentiment_avg, alpha=alpha)\n",
    "\n",
    "print(f\"상위 {topn}개 아이템 추천 중...\")\n",
    "recommendations = {}\n",
    "for user in tqdm(test.keys()):\n",
    "    if user in user_items and len(user_items[user]) > 0:\n",
    "        recommendations[user] = recommend(user, user_items, item_sims, topn)\n",
    "\n",
    "print(\"성능 평가 중...\")\n",
    "p5 = precision_at_k(test, recommendations, 5)\n",
    "r5 = recall_at_k(test, recommendations, 5)\n",
    "n5 = ndcg_at_k(test, recommendations, 5)\n",
    "\n",
    "print(f\"Precision@5: {p5:.4f}\")\n",
    "print(f\"Recall@5: {r5:.4f}\")\n",
    "print(f\"NDCG@5: {n5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
