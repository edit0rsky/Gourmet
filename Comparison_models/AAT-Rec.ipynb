{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe04a42c-eede-487e-b77e-4ee6e671604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1단계: 데이터 로드 및 전처리 시작 ---\n",
      "'447796'개의 리뷰 데이터를 성공적으로 로드했습니다.\n",
      "'27807'명의 고유 사용자와 '6831'개의 고유 레스토랑을 매핑했습니다.\n",
      "학습 세트 크기: 313457개 리뷰\n",
      "검증 세트 크기: 44779개 리뷰\n",
      "테스트 세트 크기: 89560개 리뷰\n",
      "\n",
      "--- 2단계: absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 시작 ---\n",
      "'absa_atepc_results.json' 파일에서 447796개의 리뷰 속성 데이터를 성공적으로 로드했습니다.\n",
      "동적으로 구축된 속성 어휘집 크기 (학습 데이터 기반): 39160개 키워드\n",
      "어휘집 상위 10개 키워드: [('food', 3), ('service', 4), ('staff', 5), ('place', 6), ('atmosphere', 7), ('prices', 8), ('they', 9), ('price', 10), ('pizza', 11), ('it', 12)]...\n",
      "구축된 감성 어휘집 크기: 5개 감성 ([('<PAD>', 0), ('<UNK>', 1), ('positive', 2), ('negative', 3), ('neutral', 4)])\n",
      "absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 완료.\n",
      "\n",
      "--- 2.5단계: 로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 시작 ---\n",
      "로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 완료.\n",
      "\n",
      "--- 3단계: AAT-Rec 모델 구성 요소 정의 (감성 통합) ---\n",
      "AATRec 모델 구성 요소 정의 완료.\n",
      "\n",
      "--- 4단계: 단일 하이퍼파라미터 조합으로 모델 학습 및 저장 시작 ---\n",
      "학습 장치: 'cuda'\n",
      "현재 파라미터: {'embedding_dim': 64, 'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 32, 'num_attn_heads': 8, 'learning_rate': 0.001, 'batch_size': 128, 'dropout_rate': 0.2, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'final_mlp_dims': [32, 16]}\n",
      "\n",
      "--- 모델 학습 시작 ---\n",
      "  Epoch 1/50, Train Loss: 0.7957, Val Loss: 0.6931, Val RMSE: 0.8326 --> 최적 검증 RMSE 개선됨: 0.8326. 모델 저장됨.\n",
      "  Epoch 3/50, Train Loss: 0.6475, Val Loss: 0.6762, Val RMSE: 0.8223 --> 최적 검증 RMSE 개선됨: 0.8223. 모델 저장됨.\n",
      "  Epoch 8/50, Train Loss: 0.4920, Val Loss: 0.7268, Val RMSE: 0.8526 --> 조기 종료! 5 에포크 동안 검증 RMSE 개선이 없었습니다.\n",
      "\n",
      "--- 모델 학습 완료 ---\n",
      "최종 저장된 모델의 검증 RMSE: 0.8223\n",
      "저장 경로: final_best_aatrec_model_multihead_aspect_sentiment.pt\n",
      "\n",
      "--- 최종 모델 테스트 시작 (최적 파라미터 사용) ---\n",
      "최적의 모델 가중치 'final_best_aatrec_model_multihead_aspect_sentiment.pt' 로드 완료.\n",
      "\n",
      "--- 최종 모델 성능 평가 (최적 파라미터) ---\n",
      "Root Mean Squared Error (RMSE): 0.8529\n",
      "Mean Absolute Error (MAE): 0.6799\n",
      "Mean Absolute Percentage Error (MAPE): 25.19%\n",
      "Mean Squared Error (MSE): 0.7274\n",
      "사용된 최적 하이퍼파라미터: {'embedding_dim': 64, 'aspect_embedding_dim': 96, 'sentiment_embedding_dim': 32, 'num_attn_heads': 8, 'learning_rate': 0.001, 'batch_size': 128, 'dropout_rate': 0.2, 'user_biz_mlp_dims': [128, 64], 'aspect_mlp_dims': [64, 32], 'final_mlp_dims': [32, 16]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return np.nan # 모든 y_true가 0인 경우 NaN 반환\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 0. 파일 경로 설정 ---\n",
    "review_json_path = 'review.json'\n",
    "absa_results_path = 'absa_atepc_results.json' # .json 확장자로 변경\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "print(\"--- 1단계: 데이터 로드 및 전처리 시작 ---\")\n",
    "try:\n",
    "    data = []\n",
    "    with open(review_json_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"'{len(df)}'개의 리뷰 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{review_json_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"오류: '{review_json_path}' 파일 파싱 중 오류 발생: {e}. 파일 내용이 올바른 JSON 형식을 따르는지 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "df['business_idx'] = business_encoder.fit_transform(df['business_id'])\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "print(f\"'{num_users}'명의 고유 사용자와 '{num_businesses}'개의 고유 레스토랑을 매핑했습니다.\")\n",
    "\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='ms') # timestamp in milliseconds\n",
    "except ValueError:\n",
    "    df['date'] = pd.to_datetime(df['date']) # assume standard date string format if ms fails\n",
    "\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "total_reviews = len(df)\n",
    "train_split = int(total_reviews * 0.7)\n",
    "val_split_idx = int(total_reviews * (0.7 + 0.1)) # 검증 세트의 끝 인덱스\n",
    "train_df = df.iloc[:train_split].copy()\n",
    "val_df = df.iloc[train_split:val_split_idx].copy()\n",
    "test_df = df.iloc[val_split_idx:].copy() # 나머지 20%를 테스트 세트로\n",
    "print(f\"학습 세트 크기: {len(train_df)}개 리뷰\")\n",
    "print(f\"검증 세트 크기: {len(val_df)}개 리뷰\")\n",
    "print(f\"테스트 세트 크기: {len(test_df)}개 리뷰\")\n",
    "\n",
    "print(\"\\n--- 2단계: absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 시작 ---\")\n",
    "\n",
    "absa_data = {}\n",
    "try:\n",
    "    with open(absa_results_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            absa_data[entry['review_id']] = entry['aspects']\n",
    "    print(f\"'{absa_results_path}' 파일에서 {len(absa_data)}개의 리뷰 속성 데이터를 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{absa_results_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    sys.exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"오류: '{absa_results_path}' 파일 파싱 중 오류 발생: {e}. 파일 내용이 올바른 JSON 형식을 따르는지 확인해주세요.\")\n",
    "    sys.exit()\n",
    "\n",
    "all_extracted_aspect_terms_from_file = []\n",
    "all_extracted_sentiments_from_file = []\n",
    "\n",
    "for review_id in train_df['review_id']:\n",
    "    aspects = absa_data.get(review_id, [])\n",
    "    if not aspects: # 속성이 없는 경우 'general' 및 'neutral'로 대체\n",
    "        all_extracted_aspect_terms_from_file.append('general')\n",
    "        all_extracted_sentiments_from_file.append('neutral')\n",
    "    else:\n",
    "        for aspect in aspects:\n",
    "            if 'term' in aspect and 'sentiment' in aspect:\n",
    "                all_extracted_aspect_terms_from_file.append(aspect['term'].lower())\n",
    "                # 감성 라벨을 소문자로 통일 (Positive, Negative, Neutral)\n",
    "                all_extracted_sentiments_from_file.append(aspect['sentiment'].lower())\n",
    "\n",
    "# 속성 키워드 어휘집 구축\n",
    "term_counts = Counter(all_extracted_aspect_terms_from_file)\n",
    "# <PAD>는 0번, <UNK>는 1번, 'general'은 2번 인덱스를 가집니다.\n",
    "ASPECT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'general': 2}\n",
    "next_id = 3\n",
    "MIN_TERM_FREQUENCY = 1 # 어휘집 구축 시 최소 등장 빈도\n",
    "filtered_terms = [term for term, count in term_counts.items() if count >= MIN_TERM_FREQUENCY]\n",
    "filtered_terms.sort(key=lambda x: term_counts[x], reverse=True)\n",
    "\n",
    "for term in filtered_terms:\n",
    "    if term not in ASPECT_TO_ID:\n",
    "        ASPECT_TO_ID[term] = next_id\n",
    "        next_id += 1\n",
    "NUM_ASPECT_TERMS = len(ASPECT_TO_ID)\n",
    "\n",
    "# 감성 어휘집 구축 (고정된 긍정, 부정, 중립)\n",
    "SENTIMENT_TO_ID = {'<PAD>': 0, '<UNK>': 1, 'positive': 2, 'negative': 3, 'neutral': 4}\n",
    "# PyABSA 결과에 따라 'Positive', 'Negative', 'Neutral'을 소문자로 통일하여 처리\n",
    "NUM_SENTIMENTS = len(SENTIMENT_TO_ID)\n",
    "\n",
    "print(f\"동적으로 구축된 속성 어휘집 크기 (학습 데이터 기반): {NUM_ASPECT_TERMS}개 키워드\")\n",
    "print(f\"어휘집 상위 10개 키워드: {list(ASPECT_TO_ID.items())[3:13]}...\") # 0,1,2 제외하고 출력\n",
    "print(f\"구축된 감성 어휘집 크기: {NUM_SENTIMENTS}개 감성 ({list(SENTIMENT_TO_ID.items())})\")\n",
    "print(\"absa_atepc_results.json 파일에서 속성 데이터 로드 및 동적 어휘집 구축 완료.\")\n",
    "\n",
    "print(\"\\n--- 2.5단계: 로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 시작 ---\")\n",
    "\n",
    "def map_aspect_and_sentiment_ids_from_file(df_subset, absa_data_map, aspect_to_id_map, sentiment_to_id_map):\n",
    "    extracted_aspect_ids_list = []\n",
    "    extracted_sentiment_ids_list = []\n",
    "    \n",
    "    for _, row in df_subset.iterrows():\n",
    "        review_id = row['review_id']\n",
    "        aspects_for_review = absa_data_map.get(review_id, [])\n",
    "        \n",
    "        aspect_ids_for_review = []\n",
    "        sentiment_ids_for_review = []\n",
    "        \n",
    "        if aspects_for_review:\n",
    "            for aspect in aspects_for_review:\n",
    "                if 'term' in aspect and 'sentiment' in aspect:\n",
    "                    aspect_id = aspect_to_id_map.get(aspect['term'].lower(), aspect_to_id_map['<UNK>'])\n",
    "                    sentiment_id = sentiment_to_id_map.get(aspect['sentiment'].lower(), sentiment_to_id_map['<UNK>']) # 감성 ID도 매핑\n",
    "                    \n",
    "                    aspect_ids_for_review.append(aspect_id)\n",
    "                    sentiment_ids_for_review.append(sentiment_id)\n",
    "        \n",
    "        if not aspect_ids_for_review: # 추출된 속성이 없으면 'general' 및 'neutral' 감성 사용\n",
    "            aspect_ids_for_review.append(aspect_to_id_map['general'])\n",
    "            sentiment_ids_for_review.append(sentiment_to_id_map['neutral']) # 'general'과 함께 'neutral' 감성 할당\n",
    "            \n",
    "        extracted_aspect_ids_list.append(aspect_ids_for_review)\n",
    "        extracted_sentiment_ids_list.append(sentiment_ids_for_review)\n",
    "        \n",
    "    return extracted_aspect_ids_list, extracted_sentiment_ids_list\n",
    "\n",
    "# 각 DataFrame에 속성 ID와 감성 ID 리스트 매핑\n",
    "train_df['extracted_aspect_ids'], train_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(train_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "val_df['extracted_aspect_ids'], val_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(val_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "test_df['extracted_aspect_ids'], test_df['extracted_sentiment_ids'] = map_aspect_and_sentiment_ids_from_file(test_df, absa_data, ASPECT_TO_ID, SENTIMENT_TO_ID)\n",
    "\n",
    "print(\"로드된 속성 데이터를 DataFrame에 매핑 및 캐싱 완료.\")\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_indices = torch.tensor(df['user_idx'].values, dtype=torch.long)\n",
    "        self.business_indices = torch.tensor(df['business_idx'].values, dtype=torch.long)\n",
    "        self.extracted_aspect_ids = df['extracted_aspect_ids'].values.tolist()\n",
    "        self.extracted_sentiment_ids = df['extracted_sentiment_ids'].values.tolist() # 감성 ID 추가\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.user_indices[idx], self.business_indices[idx],\n",
    "                self.extracted_aspect_ids[idx], self.extracted_sentiment_ids[idx], # 감성 ID 반환\n",
    "                self.stars[idx])\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    user_indices, business_indices, extracted_aspect_ids_list, extracted_sentiment_ids_list, stars = zip(*batch)\n",
    "\n",
    "    user_indices = torch.stack(user_indices)\n",
    "    business_indices = torch.stack(business_indices)\n",
    "    stars = torch.stack(stars)\n",
    "\n",
    "    # MultiheadAttention 입력을 위한 패딩 및 마스크 생성\n",
    "    max_aspect_len = max(len(ids) for ids in extracted_aspect_ids_list)\n",
    "    \n",
    "    padded_aspect_ids = [ids + [ASPECT_TO_ID['<PAD>']] * (max_aspect_len - len(ids)) for ids in extracted_aspect_ids_list]\n",
    "    padded_aspect_ids_tensor = torch.tensor(padded_aspect_ids, dtype=torch.long)\n",
    "    \n",
    "    padded_sentiment_ids = [ids + [SENTIMENT_TO_ID['<PAD>']] * (max_aspect_len - len(ids)) for ids in extracted_sentiment_ids_list]\n",
    "    padded_sentiment_ids_tensor = torch.tensor(padded_sentiment_ids, dtype=torch.long)\n",
    "    \n",
    "    # key_padding_mask: True는 무시할 요소 (패딩)\n",
    "    attn_mask = (padded_aspect_ids_tensor == ASPECT_TO_ID['<PAD>']) # aspect_ids를 기준으로 마스크 생성\n",
    "\n",
    "    return user_indices, business_indices, padded_aspect_ids_tensor, padded_sentiment_ids_tensor, stars, attn_mask\n",
    "\n",
    "print(\"\\n--- 3단계: AAT-Rec 모델 구성 요소 정의 (감성 통합) ---\")\n",
    "\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims, dropout_rate):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "\n",
    "    def forward(self, user_indices, business_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        business_emb = self.business_embedding(business_indices)\n",
    "        combined_emb = torch.cat((user_emb, business_emb), dim=-1)\n",
    "        interaction_features = self.mlp(combined_emb)\n",
    "        return interaction_features\n",
    "\n",
    "# 리뷰 속성별 키워드 추출 모듈 (MultiheadAttention 사용) - 감성 정보 통합\n",
    "class ReviewAspectTermExtractionModule(nn.Module):\n",
    "    def __init__(self, num_aspect_terms, aspect_embedding_dim, num_sentiments, sentiment_embedding_dim, num_heads, mlp_dims, dropout_rate):\n",
    "        super(ReviewAspectTermExtractionModule, self).__init__()\n",
    "        self.aspect_embedding = nn.Embedding(num_aspect_terms, aspect_embedding_dim, padding_idx=ASPECT_TO_ID['<PAD>'])\n",
    "        self.sentiment_embedding = nn.Embedding(num_sentiments, sentiment_embedding_dim, padding_idx=SENTIMENT_TO_ID['<PAD>']) # 감성 임베딩 추가\n",
    "        \n",
    "        # MultiheadAttention의 embed_dim은 이제 속성 임베딩과 감성 임베딩을 합친 차원이 됩니다.\n",
    "        combined_embedding_dim = aspect_embedding_dim + sentiment_embedding_dim\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=combined_embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = combined_embedding_dim # MultiheadAttention 출력 차원은 combined_embedding_dim과 동일\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = input_dim\n",
    "            \n",
    "    def forward(self, pre_extracted_aspect_ids_batch, pre_extracted_sentiment_ids_batch, attn_mask):\n",
    "        embedded_terms = self.aspect_embedding(pre_extracted_aspect_ids_batch)\n",
    "        embedded_sentiments = self.sentiment_embedding(pre_extracted_sentiment_ids_batch)\n",
    "        \n",
    "        # 속성 임베딩과 감성 임베딩을 결합 (Concatenate)\n",
    "        combined_embeddings = torch.cat((embedded_terms, embedded_sentiments), dim=-1) # dim=-1은 마지막 차원 기준으로 합침\n",
    "        \n",
    "        # MultiheadAttention에 key_padding_mask 적용\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            combined_embeddings, \n",
    "            combined_embeddings, \n",
    "            combined_embeddings, \n",
    "            key_padding_mask=attn_mask\n",
    "        )\n",
    "\n",
    "        # 패딩된 요소들을 0으로 만들고 유효한 요소들만 평균 풀링\n",
    "        valid_attn_output = attn_output * (~attn_mask.unsqueeze(-1)).float()\n",
    "        pooled_output = valid_attn_output.sum(dim=1) / (~attn_mask).sum(dim=1, keepdim=True).float().clamp(min=1)\n",
    "        \n",
    "        aspect_features = self.mlp(pooled_output)\n",
    "        return aspect_features\n",
    "\n",
    "class RatingPredictionModule(nn.Module):\n",
    "    def __init__(self, input_dim, mlp_dims, dropout_rate):\n",
    "        super(RatingPredictionModule, self).__init__()\n",
    "        layers = []\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    def forward(self, combined_features):\n",
    "        raw_prediction = self.mlp(combined_features)\n",
    "        prediction = torch.sigmoid(raw_prediction) * 4 + 1 # 1~5점 스케일로 정규화\n",
    "        return prediction\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, num_aspect_terms, aspect_embedding_dim,\n",
    "                 num_sentiments, sentiment_embedding_dim, # 감성 관련 파라미터 추가\n",
    "                 num_attn_heads, aspect_mlp_dims, final_mlp_dims, dropout_rate):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims, dropout_rate\n",
    "        )\n",
    "        self.aspect_extraction_module = ReviewAspectTermExtractionModule(\n",
    "            num_aspect_terms, aspect_embedding_dim, num_sentiments, sentiment_embedding_dim, # 감성 관련 파라미터 전달\n",
    "            num_attn_heads, aspect_mlp_dims, dropout_rate\n",
    "        )\n",
    "        combined_feature_dim = self.customer_restaurant_module.output_dim + \\\n",
    "                               self.aspect_extraction_module.output_dim\n",
    "        self.rating_prediction_module = RatingPredictionModule(\n",
    "            combined_feature_dim, final_mlp_dims, dropout_rate\n",
    "        )\n",
    "    def forward(self, user_indices, business_indices, pre_extracted_aspect_ids, pre_extracted_sentiment_ids, attn_mask): # 감성 ID 추가\n",
    "        interaction_features = self.customer_restaurant_module(user_indices, business_indices)\n",
    "        aspect_features = self.aspect_extraction_module(pre_extracted_aspect_ids, pre_extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "        combined_features = torch.cat((interaction_features, aspect_features), dim=-1)\n",
    "        predicted_rating = self.rating_prediction_module(combined_features).squeeze()\n",
    "        return predicted_rating\n",
    "\n",
    "print(\"AATRec 모델 구성 요소 정의 완료.\")\n",
    "\n",
    "\n",
    "# --- 4. 하이퍼파라미터 설정 및 모델 학습 ---\n",
    "\n",
    "print(\"\\n--- 4단계: 단일 하이퍼파라미터 조합으로 모델 학습 및 저장 시작 ---\")\n",
    "\n",
    "# Dataset 인스턴스 생성\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df) # 테스트는 학습 후 최종 평가에만 사용\n",
    "\n",
    "# 학습에 사용할 단일 하이퍼파라미터 조합 설정\n",
    "best_params = {\n",
    "    'embedding_dim': 64,\n",
    "    'aspect_embedding_dim': 96, # 속성 임베딩 차원\n",
    "    'sentiment_embedding_dim': 32, # 감성 임베딩 차원 (새로 추가)\n",
    "    'num_attn_heads': 8,\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 128,\n",
    "    'dropout_rate': 0.2,\n",
    "    'user_biz_mlp_dims': [128, 64],\n",
    "    'aspect_mlp_dims': [64, 32],\n",
    "    'final_mlp_dims': [32, 16]\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"학습 장치: '{device}'\")\n",
    "\n",
    "best_overall_rmse = float('inf') # 최적 모델 저장을 위한 초기화\n",
    "best_model_path = 'final_best_aatrec_model_multihead_aspect_sentiment.pt' # 최종 최적 모델 저장 경로 (이름 변경)\n",
    "\n",
    "print(f\"현재 파라미터: {best_params}\")\n",
    "\n",
    "# 현재 조합의 하이퍼파라미터 설정\n",
    "EMBEDDING_DIM = best_params['embedding_dim']\n",
    "ASPECT_EMBEDDING_DIM = best_params['aspect_embedding_dim']\n",
    "SENTIMENT_EMBEDDING_DIM = best_params['sentiment_embedding_dim'] # 새로운 파라미터\n",
    "NUM_ATTN_HEADS = best_params['num_attn_heads']\n",
    "LEARNING_RATE = best_params['learning_rate']\n",
    "BATCH_SIZE = best_params['batch_size']\n",
    "DROPOUT_RATE = best_params['dropout_rate']\n",
    "USER_BIZ_MLP_DIMS = best_params['user_biz_mlp_dims']\n",
    "ASPECT_MLP_DIMS = best_params['aspect_mlp_dims']\n",
    "FINAL_MLP_DIMS = best_params['final_mlp_dims']\n",
    "\n",
    "# DataLoader 생성 (custom_collate_fn 다시 사용)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "model = AATRec(\n",
    "    num_users, num_businesses, EMBEDDING_DIM,\n",
    "    USER_BIZ_MLP_DIMS, NUM_ASPECT_TERMS, ASPECT_EMBEDDING_DIM,\n",
    "    NUM_SENTIMENTS, SENTIMENT_EMBEDDING_DIM, # 감성 관련 파라미터 전달\n",
    "    NUM_ATTN_HEADS, ASPECT_MLP_DIMS, FINAL_MLP_DIMS, DROPOUT_RATE\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 조기 종료 설정\n",
    "PATIENCE = 5 # 조기 종료 대기 횟수\n",
    "MIN_DELTA = 0.001 # 검증 RMSE 개선을 위한 최소 변화량\n",
    "current_best_val_rmse = float('inf') # 'current_best_val_rmse' 초기화\n",
    "epochs_no_improve = 0\n",
    "\n",
    "NUM_EPOCHS_PER_COMBINATION = 50 # 최대 에포크\n",
    "\n",
    "print(\"\\n--- 모델 학습 시작 ---\")\n",
    "for epoch in range(NUM_EPOCHS_PER_COMBINATION):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in train_loader: # 감성 ID 추가\n",
    "        user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "            user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device) # 감성 ID to device\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_stars = model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "        loss = criterion(predicted_stars, stars)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in val_loader: # 감성 ID 추가\n",
    "            user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "                user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device) # 감성 ID to device\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            predicted_stars = model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "            total_val_loss += criterion(predicted_stars, stars).item()\n",
    "            val_preds.extend(predicted_stars.cpu().numpy())\n",
    "            val_true.extend(stars.cpu().numpy())\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # 모델 출력에서 1~5점 스케일링이 이미 되어 있으므로, 추가 클리핑은 선택 사항이지만 안전을 위해 유지\n",
    "    val_preds_clipped = np.clip(val_preds, 1.0, 5.0)\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true, val_preds_clipped))\n",
    "\n",
    "    sys.stdout.write(f\"\\r  Epoch {epoch+1}/{NUM_EPOCHS_PER_COMBINATION}, \"\n",
    "                     f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                     f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "                     f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if current_val_rmse < current_best_val_rmse - MIN_DELTA:\n",
    "        current_best_val_rmse = current_val_rmse\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), best_model_path) # 최적 모델 저장\n",
    "        sys.stdout.write(f\" --> 최적 검증 RMSE 개선됨: {current_best_val_rmse:.4f}. 모델 저장됨.\\n\")\n",
    "        sys.stdout.flush()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == PATIENCE:\n",
    "            sys.stdout.write(f\" --> 조기 종료! {PATIENCE} 에포크 동안 검증 RMSE 개선이 없었습니다.\\n\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "            \n",
    "print(\"\\n--- 모델 학습 완료 ---\")\n",
    "print(f\"최종 저장된 모델의 검증 RMSE: {current_best_val_rmse:.4f}\")\n",
    "print(f\"저장 경로: {best_model_path}\")\n",
    "\n",
    "\n",
    "# --- 최종 모델 테스트 ---\n",
    "print(\"\\n--- 최종 모델 테스트 시작 (최적 파라미터 사용) ---\")\n",
    "\n",
    "if os.path.exists(best_model_path) and best_params:\n",
    "    # 최적 파라미터로 모델 재구성 (저장된 모델 로드)\n",
    "    final_model = AATRec(\n",
    "        num_users, num_businesses, best_params['embedding_dim'],\n",
    "        best_params['user_biz_mlp_dims'], NUM_ASPECT_TERMS, best_params['aspect_embedding_dim'],\n",
    "        NUM_SENTIMENTS, best_params['sentiment_embedding_dim'], # 감성 관련 파라미터 전달\n",
    "        best_params['num_attn_heads'], best_params['aspect_mlp_dims'], best_params['final_mlp_dims'], best_params['dropout_rate']\n",
    "    )\n",
    "    final_model.load_state_dict(torch.load(best_model_path, map_location=device)) # map_location 추가\n",
    "    final_model.to(device)\n",
    "    print(f\"최적의 모델 가중치 '{best_model_path}' 로드 완료.\")\n",
    "else:\n",
    "    print(\"경고: 최적의 모델 가중치를 찾을 수 없거나 최적 파라미터가 설정되지 않았습니다. 테스트를 건너뜜.\")\n",
    "    sys.exit()\n",
    "\n",
    "# 테스트 로더도 custom_collate_fn 사용\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "final_model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "with torch.no_grad():\n",
    "    for user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars, attn_mask in test_loader: # 감성 ID 추가\n",
    "        user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, stars = \\\n",
    "            user_indices.to(device), business_indices.to(device), extracted_aspect_ids.to(device), extracted_sentiment_ids.to(device), stars.to(device) # 감성 ID to device\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        predicted_stars = final_model(user_indices, business_indices, extracted_aspect_ids, extracted_sentiment_ids, attn_mask) # 감성 ID 전달\n",
    "        test_preds.extend(predicted_stars.cpu().numpy())\n",
    "        test_true.extend(stars.cpu().numpy())\n",
    "\n",
    "# 예측 범위 클리핑 (1점 ~ 5점)\n",
    "test_preds_clipped = np.clip(test_preds, 1.0, 5.0)\n",
    "\n",
    "mse = mean_squared_error(test_true, test_preds_clipped)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_true, test_preds_clipped)\n",
    "mape = mean_absolute_percentage_error(test_true, test_preds_clipped)\n",
    "\n",
    "print(f\"\\n--- 최종 모델 성능 평가 (최적 파라미터) ---\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"사용된 최적 하이퍼파라미터: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6c76f-6476-4ae8-b969-923cdb4e31a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My ABSA Project 3.10)",
   "language": "python",
   "name": "my_absa_project_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
