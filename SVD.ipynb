{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6bb79fd-0b69-4cb5-8fec-c8ac17e27766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "상호작용 행렬 희소성: 99.79%\n"
     ]
    }
   ],
   "source": [
    "num_unique_users = data_clean['user_encoded'].nunique()\n",
    "num_unique_businesses = data_clean['business_encoded'].nunique()\n",
    "print(f\"총 고유 사용자 수: {num_unique_users:,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {num_unique_businesses:,}개\")\n",
    "total_elements = interaction_matrix.shape[0] * interaction_matrix.shape[1]\n",
    "non_zero_elements = np.count_nonzero(interaction_matrix)\n",
    "sparsity = (1 - (non_zero_elements / total_elements)) * 100\n",
    "print(f\"상호작용 행렬 희소성: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de837e60-3952-4e63-b3ab-727a5fc3361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "학습 데이터셋 크기 (Surprise): 401,146개\n",
      "테스트 데이터셋 크기 (Surprise): 27,807개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 27807/27807 [14:31<00:00, 31.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5 (Surprise SVD): 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import LeaveOneOut # Use surprise's LOO for proper internal handling\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "# 데이터 로드\n",
    "data = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼만 추출\n",
    "data_clean = data[['user_id', 'business_id', 'stars']].copy() # .copy()를 사용하여 SettingWithCopyWarning 방지\n",
    "\n",
    "# 사용자와 비즈니스 아이디를 숫자로 인코딩 (Surprise에 전달하기 전에 필요)\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "data_clean.loc[:, 'user_encoded'] = user_encoder.fit_transform(data_clean['user_id'])\n",
    "data_clean.loc[:, 'business_encoded'] = business_encoder.fit_transform(data_clean['business_id'])\n",
    "\n",
    "# 중복되는 사용자-비즈니스 조합에 대해 평균 평점 계산 (Surprise는 단일 평점 기대)\n",
    "data_clean = data_clean.groupby(['user_encoded', 'business_encoded'], as_index=False)['stars'].mean()\n",
    "\n",
    "print(f\"총 고유 사용자 수: {data_clean['user_encoded'].nunique():,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {data_clean['business_encoded'].nunique():,}개\")\n",
    "\n",
    "# --- 2. Surprise 라이브러리용 데이터 로드 및 LOO 분할 ---\n",
    "# Reader는 평점 스케일을 지정합니다. (예: 1점 ~ 5점)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# data_clean DataFrame에서 user, item, rating 컬럼을 지정하여 Surprise Dataset으로 로드\n",
    "data_surprise = Dataset.load_from_df(data_clean[['user_encoded', 'business_encoded', 'stars']], reader)\n",
    "\n",
    "# Leave-One-Out 분할 (Surprise 내부 기능 활용)\n",
    "# n_splits=1은 각 사용자당 하나의 아이템만 테스트 세트로 분리합니다.\n",
    "loo_kf = LeaveOneOut(n_splits=1, random_state=42)\n",
    "\n",
    "# next(loo_kf.split(data_surprise))를 통해 단일 훈련/테스트 세트 얻기\n",
    "# trainset은 surprise.Trainset 객체, testset_surprise는 (uid, iid, r_ui) 튜플 리스트\n",
    "trainset, testset_surprise = next(loo_kf.split(data_surprise))\n",
    "\n",
    "print(f\"학습 데이터셋 크기 (Surprise): {trainset.n_ratings:,}개\")\n",
    "print(f\"테스트 데이터셋 크기 (Surprise): {len(testset_surprise):,}개\")\n",
    "\n",
    "# --- 3. SVD 모델 학습 (Surprise SVD) ---\n",
    "# n_factors는 잠재 변수 개수\n",
    "# n_epochs는 학습 반복 횟수\n",
    "# lr_all은 학습률, reg_all은 정규화 파라미터\n",
    "algo = SVD(n_factors=500, random_state=42, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# --- 4. Precision@K 계산 함수 (Surprise에 맞춰 수정) ---\n",
    "def precision_at_k_surprise(predictions, k=5):\n",
    "    \"\"\"\n",
    "    Surprise의 SVD 모델을 사용하여 LOO Precision@K를 계산합니다.\n",
    "    predictions: algo.test()에서 반환된 예측 리스트 (uid, iid, true_r, est, _) 튜플 형태\n",
    "    \"\"\"\n",
    "    # 테스트 세트에 있는 각 사용자의 실제 아이템을 매핑 (외부 ID 사용)\n",
    "    user_to_actual_item = {}\n",
    "    for uid, iid, _, _, _ in predictions: # uid: 사용자 외부 ID, iid: 아이템 외부 ID\n",
    "        user_to_actual_item[uid] = iid\n",
    "\n",
    "    # 모든 사용자에 대해 추천 목록 생성 (훈련 세트에서 보지 않은 아이템만 대상으로)\n",
    "    all_recommendations = {}\n",
    "    \n",
    "    # trainset에 있는 모든 사용자 내부 ID를 순회합니다.\n",
    "    for user_inner_id in tqdm(trainset.all_users(), desc=\"Generating recommendations\"):\n",
    "        uid = trainset.to_raw_uid(user_inner_id) # 내부 ID를 원본 (외부) 사용자 ID로 변환\n",
    "\n",
    "        # 이 사용자가 훈련 세트에서 이미 본 아이템의 내부 ID 목록\n",
    "        seen_items_inner_ids = [item_inner_id for (item_inner_id, _) in trainset.ur[user_inner_id]]\n",
    "        # 내부 ID를 외부 ID로 변환\n",
    "        seen_items_outer_ids = [trainset.to_raw_iid(item_inner_id) for item_inner_id in seen_items_inner_ids]\n",
    "\n",
    "        # 이 사용자가 훈련 세트에서 보지 않은 아이템들의 외부 ID 목록을 생성\n",
    "        unseen_items_outer_ids = []\n",
    "        # Surprise의 모든 아이템 내부 ID를 순회\n",
    "        for item_inner_id in trainset.all_items():\n",
    "            iid = trainset.to_raw_iid(item_inner_id) # 내부 ID를 원본 (외부) 아이템 ID로 변환\n",
    "            if iid not in seen_items_outer_ids: # 본 적 없는 아이템만 추가\n",
    "                unseen_items_outer_ids.append(iid)\n",
    "\n",
    "        # 보지 않은 아이템들에 대한 예측 수행\n",
    "        # predict()는 사용자 ID와 아이템 ID가 \"원본(raw) 형태\"일 것을 기대합니다.\n",
    "        # 따라서 to_raw_uid/iid로 변환된 값들을 사용해야 합니다.\n",
    "        # 또한, Surprise는 trainset에 없는 (즉, 예측할 필요 없는) 조합에 대해서도 predict를 호출할 수 있으므로,\n",
    "        # 실제로 predict 가능한 아이템만 예측하도록 필터링하는 것이 안전합니다 (내부적으로 처리되기도 함).\n",
    "        unseen_predictions = [algo.predict(uid, iid) for iid in unseen_items_outer_ids]\n",
    "\n",
    "        # 예측 점수를 기준으로 내림차순 정렬하여 상위 k개 아이템 선택\n",
    "        unseen_predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "        top_k_recs = [pred.iid for pred in unseen_predictions[:k]] # pred.iid는 예측된 아이템의 외부 ID\n",
    "        all_recommendations[uid] = top_k_recs\n",
    "\n",
    "    # Precision 계산\n",
    "    precisions = []\n",
    "    # 테스트 세트에 있는 각 사용자-실제 아이템 쌍에 대해\n",
    "    for uid, actual_iid in user_to_actual_item.items():\n",
    "        if uid in all_recommendations: # 해당 사용자에 대한 추천이 생성되었다면\n",
    "            if actual_iid in all_recommendations[uid]: # 실제 아이템이 추천 목록에 있다면 Hit!\n",
    "                precisions.append(1)\n",
    "            else: # Hit이 아니라면 Miss\n",
    "                precisions.append(0)\n",
    "        # else: 해당 사용자가 trainset에 없어 추천이 생성되지 않은 경우는 무시 (LOO에서는 대부분 있음)\n",
    "            \n",
    "    return np.mean(precisions) if precisions else 0.0 # 평균 Precision 반환\n",
    "\n",
    "# 모델의 예측 결과 (테스트 세트에 있는 각 사용자-숨겨진 아이템 쌍에 대한 예측)\n",
    "test_predictions = algo.test(testset_surprise)\n",
    "\n",
    "# Precision@5 계산 및 출력\n",
    "precision_surprise = precision_at_k_surprise(test_predictions, k=5)\n",
    "print(f\"Precision@5 (Surprise SVD): {precision_surprise:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b2f05ee-7b5b-4b32-818b-f4022393bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 27807/27807 [14:34<00:00, 31.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5 (Surprise SVD): 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision@5 계산 및 출력\n",
    "precision_surprise = precision_at_k_surprise(test_predictions, k=100)\n",
    "print(f\"Precision@5 (Surprise SVD): {precision_surprise:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "064ed312-1225-4dda-891c-236b9576d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "총 집계된 평점 데이터 수: 428,953개\n",
      "\n",
      "--- 기존 SVD 모델 K-Fold 교차 검증 시작 (ABSA 미반영) ---\n",
      "Fold 1/5 - 학습 중...\n",
      "Fold 1 완료. RMSE: 1.0613\n",
      "Fold 2/5 - 학습 중...\n",
      "Fold 2 완료. RMSE: 1.0627\n",
      "Fold 3/5 - 학습 중...\n",
      "Fold 3 완료. RMSE: 1.0615\n",
      "Fold 4/5 - 학습 중...\n",
      "Fold 4 완료. RMSE: 1.0620\n",
      "Fold 5/5 - 학습 중...\n",
      "Fold 5 완료. RMSE: 1.0659\n",
      "\n",
      "--- 기존 SVD 모델 RMSE 결과 (ABSA 미반영) ---\n",
      "각 Fold의 RMSE: [1.0612557336852626, 1.062658806645337, 1.0615232983255034, 1.0619605971398314, 1.0658725392919286]\n",
      "평균 RMSE: 1.0627\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import KFold # RMSE 평가에 KFold 사용\n",
    "from surprise import accuracy # RMSE를 계산하기 위해 필요\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 (이전과 동일) ---\n",
    "data = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "data_clean = data[['user_id', 'business_id', 'stars']].copy() # sentiment_vector는 일단 제외\n",
    "\n",
    "# 사용자와 비즈니스 아이디를 숫자로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "data_clean.loc[:, 'user_encoded'] = user_encoder.fit_transform(data_clean['user_id'])\n",
    "data_clean.loc[:, 'business_encoded'] = business_encoder.fit_transform(data_clean['business_id'])\n",
    "\n",
    "# 사용자-비즈니스 쌍에 대해 평균 평점 계산 (동일한 user_id, business_id 쌍에 여러 리뷰가 있다면)\n",
    "data_aggregated = data_clean.groupby(['user_encoded', 'business_encoded'], as_index=False)['stars'].mean()\n",
    "\n",
    "print(f\"총 고유 사용자 수: {data_aggregated['user_encoded'].nunique():,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {data_aggregated['business_encoded'].nunique():,}개\")\n",
    "print(f\"총 집계된 평점 데이터 수: {len(data_aggregated):,}개\")\n",
    "\n",
    "# --- 2. Surprise 라이브러리용 데이터 로드 ---\n",
    "reader = Reader(rating_scale=(1, 5)) # 별점 스케일 지정 (예: 1~5)\n",
    "data_surprise = Dataset.load_from_df(data_aggregated[['user_encoded', 'business_encoded', 'stars']], reader)\n",
    "\n",
    "# --- 3. K-Fold 교차 검증 준비 ---\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True) # 5-Fold 교차 검증\n",
    "\n",
    "# --- 4. SVD 모델 학습 및 RMSE 평가 ---\n",
    "# SVD 모델 파라미터 설정 (이전과 동일하게 유지)\n",
    "svd_algo = SVD(n_factors=500, random_state=42, n_epochs=20, lr_all=0.005, reg_all=0.02, verbose=False)\n",
    "\n",
    "# RMSE를 저장할 리스트\n",
    "rmses = []\n",
    "\n",
    "print(\"\\n--- 기존 SVD 모델 K-Fold 교차 검증 시작 (ABSA 미반영) ---\")\n",
    "for i, (trainset, testset) in enumerate(kf.split(data_surprise)):\n",
    "    print(f\"Fold {i+1}/{kf.n_splits} - 학습 중...\")\n",
    "    \n",
    "    # SVD 모델 학습\n",
    "    svd_algo.fit(trainset)\n",
    "    \n",
    "    # 테스트 세트에 대한 예측 생성\n",
    "    predictions = svd_algo.test(testset)\n",
    "    \n",
    "    # RMSE 계산\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    rmses.append(rmse)\n",
    "    print(f\"Fold {i+1} 완료. RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- 기존 SVD 모델 RMSE 결과 (ABSA 미반영) ---\")\n",
    "print(f\"각 Fold의 RMSE: {rmses}\")\n",
    "print(f\"평균 RMSE: {np.mean(rmses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b33018f-8586-4ef7-b410-1cd8f178fa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "총 집계된 평점/ABSA 데이터 수: 428,953개\n",
      "\n",
      "--- ABSA 기반 아이템-아이템 유사도 행렬 계산 중 (시간 소요) ---\n",
      "ABSA 기반 아이템-아이템 유사도 행렬 계산 완료.\n",
      "\n",
      "--- 하이브리드 앙상블 모델 K-Fold 교차 검증 시작 ---\n",
      "\n",
      "Fold 1/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 ABSA Prediction: 100%|██████████| 85791/85791 [00:03<00:00, 21568.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 ABSA Prediction: 100%|██████████| 85791/85791 [00:04<00:00, 19220.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 ABSA Prediction: 100%|██████████| 85791/85791 [00:03<00:00, 22524.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 ABSA Prediction: 100%|██████████| 85790/85790 [00:04<00:00, 19162.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 ABSA Prediction: 100%|██████████| 85790/85790 [00:03<00:00, 22448.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 앙상블 가중치 조합 탐색 시작 ---\n",
      "w_svd: 0.1, w_absa: 0.9, RMSE: 1.1091\n",
      "w_svd: 0.2, w_absa: 0.8, RMSE: 1.0927\n",
      "w_svd: 0.3, w_absa: 0.7, RMSE: 1.0789\n",
      "w_svd: 0.4, w_absa: 0.6, RMSE: 1.0678\n",
      "w_svd: 0.5, w_absa: 0.5, RMSE: 1.0596\n",
      "w_svd: 0.6, w_absa: 0.4, RMSE: 1.0543\n",
      "w_svd: 0.7, w_absa: 0.3, RMSE: 1.0520\n",
      "w_svd: 0.8, w_absa: 0.2, RMSE: 1.0526\n",
      "w_svd: 0.9, w_absa: 0.1, RMSE: 1.0562\n",
      "\n",
      "--- 앙상블 결과 ---\n",
      "최적의 RMSE: 1.0520\n",
      "최적의 가중치 (SVD: 0.7, ABSA: 0.3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import KFold # RMSE 평가에는 KFold가 더 일반적\n",
    "from surprise import accuracy\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "data = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "data_clean = data[['user_id', 'business_id', 'stars', 'sentiment_vector']].copy()\n",
    "\n",
    "# 사용자와 비즈니스 아이디를 숫자로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "data_clean.loc[:, 'user_encoded'] = user_encoder.fit_transform(data_clean['user_id'])\n",
    "data_clean.loc[:, 'business_encoded'] = business_encoder.fit_transform(data_clean['business_id'])\n",
    "\n",
    "# sentiment_vector 컬럼을 각 요소별로 분리하여 새로운 컬럼 생성\n",
    "sentiment_vector_df = pd.DataFrame(data_clean['sentiment_vector'].tolist(),\n",
    "                                   index=data_clean.index,\n",
    "                                   columns=[f'sentiment_vector_{i}' for i in range(len(data_clean['sentiment_vector'].iloc[0]))])\n",
    "\n",
    "data_clean = pd.concat([data_clean.drop('sentiment_vector', axis=1), sentiment_vector_df], axis=1)\n",
    "\n",
    "# ABSA 피처 컬럼 이름 목록 생성\n",
    "absa_feature_cols = [col for col in data_clean.columns if 'sentiment_vector_' in col]\n",
    "\n",
    "# 사용자-비즈니스-평점/ABSA 피처 집계 (평균)\n",
    "group_cols = ['user_encoded', 'business_encoded']\n",
    "agg_funcs = {'stars': 'mean'}\n",
    "for col in absa_feature_cols:\n",
    "    agg_funcs[col] = 'mean'\n",
    "\n",
    "data_aggregated = data_clean.groupby(group_cols, as_index=False).agg(agg_funcs)\n",
    "\n",
    "print(f\"총 고유 사용자 수: {data_aggregated['user_encoded'].nunique():,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {data_aggregated['business_encoded'].nunique():,}개\")\n",
    "print(f\"총 집계된 평점/ABSA 데이터 수: {len(data_aggregated):,}개\")\n",
    "\n",
    "# --- 2. Surprise SVD 모델 학습 및 예측 준비 ---\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data_surprise = Dataset.load_from_df(data_aggregated[['user_encoded', 'business_encoded', 'stars']], reader)\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True) # 5-Fold 교차 검증\n",
    "\n",
    "# --- 3. ABSA 기반 콘텐츠 모델을 위한 데이터 준비 ---\n",
    "\n",
    "# 각 비즈니스별 ABSA 피처 평균 계산 (아이템 콘텐츠 벡터)\n",
    "business_absa_features_avg = data_aggregated.groupby('business_encoded')[absa_feature_cols].mean()\n",
    "\n",
    "# 코사인 유사도 계산을 위해 DataFrame을 numpy 배열로 변환\n",
    "absa_matrix = business_absa_features_avg.values\n",
    "# 비즈니스 ID 인덱스 매핑 (나중에 유사도 행렬에서 ID를 찾기 위해)\n",
    "business_id_to_idx = {business_id: idx for idx, business_id in enumerate(business_absa_features_avg.index)}\n",
    "idx_to_business_id = {idx: business_id for business_id, idx in business_id_to_idx.items()}\n",
    "\n",
    "# 아이템-아이템 코사인 유사도 계산 (ABSA 피처 기반)\n",
    "print(\"\\n--- ABSA 기반 아이템-아이템 유사도 행렬 계산 중 (시간 소요) ---\")\n",
    "item_absa_similarity_matrix = cosine_similarity(absa_matrix)\n",
    "print(\"ABSA 기반 아이템-아이템 유사도 행렬 계산 완료.\")\n",
    "\n",
    "# --- 4. 앙상블을 위한 교차 검증 및 예측 ---\n",
    "\n",
    "svd_predictions_list = []\n",
    "absa_predictions_list = []\n",
    "\n",
    "print(\"\\n--- 하이브리드 앙상블 모델 K-Fold 교차 검증 시작 ---\")\n",
    "\n",
    "for fold_idx, (trainset, testset) in enumerate(kf.split(data_surprise)):\n",
    "    print(f\"\\nFold {fold_idx+1}/{kf.n_splits} - 학습 및 예측 중...\")\n",
    "\n",
    "    # --- 4-1. SVD 모델 학습 및 예측 ---\n",
    "    svd_algo = SVD(n_factors=500, random_state=42, n_epochs=20, lr_all=0.005, reg_all=0.02, verbose=False)\n",
    "    svd_algo.fit(trainset)\n",
    "    svd_fold_predictions = svd_algo.test(testset)\n",
    "    svd_predictions_list.extend(svd_fold_predictions)\n",
    "\n",
    "\n",
    "    # --- 4-2. ABSA 기반 콘텐츠 모델 예측 ---\n",
    "    absa_fold_predictions = []\n",
    "    \n",
    "    # 테스트 세트의 각 (사용자, 아이템) 쌍에 대해 예측 수행\n",
    "    for uid_outer, iid_outer, true_r in tqdm(testset, desc=f\"Fold {fold_idx+1} ABSA Prediction\"):\n",
    "        \n",
    "        # 사용자가 훈련 세트에서 이미 평가한 아이템 정보 가져오기\n",
    "        try:\n",
    "            user_inner_id = trainset.to_inner_uid(uid_outer)\n",
    "            # (item_inner_id, rating) 튜플 리스트\n",
    "            user_ratings_in_train = trainset.ur[user_inner_id]\n",
    "        except ValueError: # 테스트 유저가 훈련셋에 없는 경우 (드묾)\n",
    "            absa_fold_predictions.append((uid_outer, iid_outer, true_r, np.mean(trainset.global_mean), {})) # 평균으로 대체\n",
    "            continue\n",
    "\n",
    "        # 사용자 u가 훈련 세트에서 평가한 비즈니스 ID 및 평점 목록\n",
    "        rated_items_by_user = []\n",
    "        for item_inner_id, rating in user_ratings_in_train:\n",
    "            # 수정된 부분: to_outer_iid 대신 to_raw_iid 사용\n",
    "            rated_items_by_user.append((trainset.to_raw_iid(item_inner_id), rating))\n",
    "\n",
    "        # 타겟 아이템의 ABSA 기반 예측 평점 계산\n",
    "        predicted_absa_rating = np.mean(trainset.global_mean) # 기본값은 전체 평균\n",
    "        \n",
    "        # 타겟 아이템이 ABSA 데이터에 있는지 확인\n",
    "        if iid_outer not in business_id_to_idx:\n",
    "            absa_fold_predictions.append((uid_outer, iid_outer, true_r, predicted_absa_rating, {}))\n",
    "            continue # 다음 아이템으로 넘어감\n",
    "\n",
    "        target_item_absa_idx = business_id_to_idx[iid_outer]\n",
    "        \n",
    "        weighted_sum = 0\n",
    "        similarity_sum = 0\n",
    "        \n",
    "        # 사용자가 훈련 세트에서 평가했던 각 아이템에 대해\n",
    "        for rated_item_outer_id, rated_rating in rated_items_by_user:\n",
    "            if rated_item_outer_id in business_id_to_idx:\n",
    "                rated_item_absa_idx = business_id_to_idx[rated_item_outer_id]\n",
    "                \n",
    "                # 타겟 아이템과 평가했던 아이템 간의 ABSA 유사도\n",
    "                similarity = item_absa_similarity_matrix[target_item_absa_idx, rated_item_absa_idx]\n",
    "                \n",
    "                # 유사도가 0보다 크다면 가중치로 사용 (0이면 상관 없다고 가정)\n",
    "                if similarity > 0:\n",
    "                    weighted_sum += similarity * rated_rating\n",
    "                    similarity_sum += similarity\n",
    "        \n",
    "        if similarity_sum > 0:\n",
    "            predicted_absa_rating = weighted_sum / similarity_sum\n",
    "        else:\n",
    "            # 유사한 아이템을 찾지 못했다면, 해당 사용자의 평균 평점 또는 전체 평균으로 대체\n",
    "            try:\n",
    "                predicted_absa_rating = trainset.mean(user_inner_id) # 사용자 평균 평점\n",
    "            except ValueError: # 사용자 평균도 없을 때 (매우 드묾)\n",
    "                predicted_absa_rating = trainset.global_mean # 전체 평균\n",
    "        \n",
    "        absa_fold_predictions.append((uid_outer, iid_outer, true_r, predicted_absa_rating, {}))\n",
    "    \n",
    "    absa_predictions_list.extend(absa_fold_predictions)\n",
    "\n",
    "# --- 5. 예측 결과 결합 및 RMSE 측정 ---\n",
    "\n",
    "# SVD와 ABSA 예측 결과를 정렬하여 (user, item) 쌍이 일치하도록 합니다.\n",
    "svd_preds_df = pd.DataFrame([(p.uid, p.iid, p.est, p.r_ui) for p in svd_predictions_list], columns=['uid', 'iid', 'svd_est', 'true_r'])\n",
    "absa_preds_df = pd.DataFrame([(p[0], p[1], p[3]) for p in absa_predictions_list], columns=['uid', 'iid', 'absa_est'])\n",
    "\n",
    "# 실제 평점은 SVD 예측 리스트에서 가져오는 것이 가장 정확합니다.\n",
    "combined_preds_df = pd.merge(svd_preds_df, absa_preds_df, on=['uid', 'iid'], how='inner')\n",
    "\n",
    "# 다양한 가중치 조합으로 RMSE 평가 (Grid Search)\n",
    "best_rmse = float('inf')\n",
    "best_w_svd = 0\n",
    "best_w_absa = 0\n",
    "\n",
    "# 가중치 탐색 범위\n",
    "weights_svd = np.linspace(0.1, 0.9, 9) # 0.1부터 0.9까지 0.1 간격\n",
    "weights_absa = 1 - weights_svd # 두 가중치의 합이 1이 되도록\n",
    "\n",
    "print(\"\\n--- 앙상블 가중치 조합 탐색 시작 ---\")\n",
    "results = []\n",
    "for w_svd, w_absa in zip(weights_svd, weights_absa):\n",
    "    combined_preds_df['ensemble_est'] = (w_svd * combined_preds_df['svd_est']) + \\\n",
    "                                        (w_absa * combined_preds_df['absa_est'])\n",
    "    \n",
    "    # 평점 스케일 범위(1~5)를 벗어나지 않도록 클리핑 (선택 사항이지만 권장)\n",
    "    combined_preds_df['ensemble_est'] = np.clip(combined_preds_df['ensemble_est'], 1, 5)\n",
    "\n",
    "    rmse = np.sqrt(np.mean((combined_preds_df['ensemble_est'] - combined_preds_df['true_r'])**2))\n",
    "    \n",
    "    results.append({'w_svd': w_svd, 'w_absa': w_absa, 'rmse': rmse})\n",
    "    print(f\"w_svd: {w_svd:.1f}, w_absa: {w_absa:.1f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_w_svd = w_svd\n",
    "        best_w_absa = w_absa\n",
    "\n",
    "print(\"\\n--- 앙상블 결과 ---\")\n",
    "print(f\"최적의 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd:.1f}, ABSA: {best_w_absa:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69ae8589-d255-4c2c-b6ef-6c8cd3bb2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "총 집계된 평점 데이터 수: 428,953개\n",
      "\n",
      "--- 기존 SVD 모델 K-Fold 교차 검증 시작 (ABSA 미반영) ---\n",
      "Fold 1/5 - 학습 중...\n",
      "Fold 1 완료. RMSE: 1.0613, MAE: 0.8298\n",
      "Fold 2/5 - 학습 중...\n",
      "Fold 2 완료. RMSE: 1.0627, MAE: 0.8325\n",
      "Fold 3/5 - 학습 중...\n",
      "Fold 3 완료. RMSE: 1.0615, MAE: 0.8321\n",
      "Fold 4/5 - 학습 중...\n",
      "Fold 4 완료. RMSE: 1.0620, MAE: 0.8320\n",
      "Fold 5/5 - 학습 중...\n",
      "Fold 5 완료. RMSE: 1.0659, MAE: 0.8345\n",
      "\n",
      "--- 기존 SVD 모델 RMSE, MAE 결과 (ABSA 미반영) ---\n",
      "각 Fold의 RMSE: [1.0612557336852626, 1.062658806645337, 1.0615232983255034, 1.0619605971398314, 1.0658725392919286]\n",
      "평균 RMSE: 1.0627\n",
      "각 Fold의 MAE: [0.8297796587574818, 0.8325079182605186, 0.8320716937758054, 0.8319797545594015, 0.8345271118773612]\n",
      "평균 MAE: 0.8322\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import KFold # RMSE 평가에 KFold 사용\n",
    "from surprise import accuracy # RMSE와 MAE 계산을 위해 필요\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "data = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "data_clean = data[['user_id', 'business_id', 'stars']].copy() # sentiment_vector는 일단 제외\n",
    "\n",
    "# 사용자와 비즈니스 아이디를 숫자로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "data_clean.loc[:, 'user_encoded'] = user_encoder.fit_transform(data_clean['user_id'])\n",
    "data_clean.loc[:, 'business_encoded'] = business_encoder.fit_transform(data_clean['business_id'])\n",
    "\n",
    "# 사용자-비즈니스 쌍에 대해 평균 평점 계산\n",
    "data_aggregated = data_clean.groupby(['user_encoded', 'business_encoded'], as_index=False)['stars'].mean()\n",
    "\n",
    "print(f\"총 고유 사용자 수: {data_aggregated['user_encoded'].nunique():,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {data_aggregated['business_encoded'].nunique():,}개\")\n",
    "print(f\"총 집계된 평점 데이터 수: {len(data_aggregated):,}개\")\n",
    "\n",
    "# --- 2. Surprise 라이브러리용 데이터 로드 ---\n",
    "reader = Reader(rating_scale=(1, 5)) # 별점 스케일 지정 (예: 1~5)\n",
    "data_surprise = Dataset.load_from_df(data_aggregated[['user_encoded', 'business_encoded', 'stars']], reader)\n",
    "\n",
    "# --- 3. K-Fold 교차 검증 준비 ---\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True) # 5-Fold 교차 검증\n",
    "\n",
    "# --- 4. SVD 모델 학습 및 RMSE, MAE 평가 ---\n",
    "# SVD 모델 파라미터 설정\n",
    "svd_algo = SVD(n_factors=500, random_state=42, n_epochs=20, lr_all=0.005, reg_all=0.02, verbose=False)\n",
    "\n",
    "# RMSE와 MAE를 저장할 리스트\n",
    "rmses = []\n",
    "maes = []\n",
    "\n",
    "print(\"\\n--- 기존 SVD 모델 K-Fold 교차 검증 시작 (ABSA 미반영) ---\")\n",
    "for i, (trainset, testset) in enumerate(kf.split(data_surprise)):\n",
    "    print(f\"Fold {i+1}/{kf.n_splits} - 학습 중...\")\n",
    "    \n",
    "    # SVD 모델 학습\n",
    "    svd_algo.fit(trainset)\n",
    "    \n",
    "    # 테스트 세트에 대한 예측 생성\n",
    "    predictions = svd_algo.test(testset)\n",
    "    \n",
    "    # RMSE 계산\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    rmses.append(rmse)\n",
    "    \n",
    "    # MAE 계산\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    maes.append(mae)\n",
    "    \n",
    "    print(f\"Fold {i+1} 완료. RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "print(\"\\n--- 기존 SVD 모델 RMSE, MAE 결과 (ABSA 미반영) ---\")\n",
    "print(f\"각 Fold의 RMSE: {rmses}\")\n",
    "print(f\"평균 RMSE: {np.mean(rmses):.4f}\")\n",
    "print(f\"각 Fold의 MAE: {maes}\")\n",
    "print(f\"평균 MAE: {np.mean(maes):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7ee5bbd-2ba6-449e-9d8a-a90ca4095429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 앙상블 가중치 조합 탐색 시작 ---\n",
      "w_svd: 0.1, w_absa: 0.9, RMSE: 1.1091, MAE: 0.8576\n",
      "w_svd: 0.2, w_absa: 0.8, RMSE: 1.0927, MAE: 0.8478\n",
      "w_svd: 0.3, w_absa: 0.7, RMSE: 1.0789, MAE: 0.8397\n",
      "w_svd: 0.4, w_absa: 0.6, RMSE: 1.0678, MAE: 0.8332\n",
      "w_svd: 0.5, w_absa: 0.5, RMSE: 1.0596, MAE: 0.8285\n",
      "w_svd: 0.6, w_absa: 0.4, RMSE: 1.0543, MAE: 0.8256\n",
      "w_svd: 0.7, w_absa: 0.3, RMSE: 1.0520, MAE: 0.8246\n",
      "w_svd: 0.8, w_absa: 0.2, RMSE: 1.0526, MAE: 0.8254\n",
      "w_svd: 0.9, w_absa: 0.1, RMSE: 1.0562, MAE: 0.8280\n",
      "\n",
      "--- 앙상블 결과 ---\n",
      "최적의 RMSE: 1.0520\n",
      "최적의 가중치 (SVD: 0.7, ABSA: 0.3)\n",
      "최적의 MAE: 0.8246\n",
      "최적의 가중치 (SVD: 0.7, ABSA: 0.3)\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 예측 결과 결합 및 RMSE, MAE 측정 ---\n",
    "\n",
    "# SVD와 ABSA 예측 결과를 정렬하여 (user, item) 쌍이 일치하도록 합니다.\n",
    "svd_preds_df = pd.DataFrame([(p.uid, p.iid, p.est, p.r_ui) for p in svd_predictions_list], columns=['uid', 'iid', 'svd_est', 'true_r'])\n",
    "absa_preds_df = pd.DataFrame([(p[0], p[1], p[3]) for p in absa_predictions_list], columns=['uid', 'iid', 'absa_est'])\n",
    "\n",
    "# 실제 평점은 SVD 예측 리스트에서 가져오는 것이 가장 정확합니다.\n",
    "combined_preds_df = pd.merge(svd_preds_df, absa_preds_df, on=['uid', 'iid'], how='inner')\n",
    "\n",
    "# 다양한 가중치 조합으로 RMSE, MAE 평가 (Grid Search)\n",
    "best_rmse = float('inf')\n",
    "best_mae = float('inf')  # MAE에 대한 변수 추가\n",
    "best_w_svd = 0\n",
    "best_w_absa = 0\n",
    "\n",
    "# 가중치 탐색 범위\n",
    "weights_svd = np.linspace(0.1, 0.9, 9) # 0.1부터 0.9까지 0.1 간격\n",
    "weights_absa = 1 - weights_svd # 두 가중치의 합이 1이 되도록\n",
    "\n",
    "print(\"\\n--- 앙상블 가중치 조합 탐색 시작 ---\")\n",
    "results = []\n",
    "for w_svd, w_absa in zip(weights_svd, weights_absa):\n",
    "    combined_preds_df['ensemble_est'] = (w_svd * combined_preds_df['svd_est']) + \\\n",
    "                                        (w_absa * combined_preds_df['absa_est'])\n",
    "    \n",
    "    # 평점 스케일 범위(1~5)를 벗어나지 않도록 클리핑 (선택 사항이지만 권장)\n",
    "    combined_preds_df['ensemble_est'] = np.clip(combined_preds_df['ensemble_est'], 1, 5)\n",
    "\n",
    "    # RMSE 계산\n",
    "    rmse = np.sqrt(np.mean((combined_preds_df['ensemble_est'] - combined_preds_df['true_r'])**2))\n",
    "\n",
    "    # MAE 계산\n",
    "    mae = np.mean(np.abs(combined_preds_df['ensemble_est'] - combined_preds_df['true_r']))\n",
    "\n",
    "    results.append({'w_svd': w_svd, 'w_absa': w_absa, 'rmse': rmse, 'mae': mae})\n",
    "    print(f\"w_svd: {w_svd:.1f}, w_absa: {w_absa:.1f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "    # 최적 RMSE, MAE 값 업데이트\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_w_svd = w_svd\n",
    "        best_w_absa = w_absa\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_w_svd_mae = w_svd\n",
    "        best_w_absa_mae = w_absa\n",
    "\n",
    "print(\"\\n--- 앙상블 결과 ---\")\n",
    "print(f\"최적의 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd:.1f}, ABSA: {best_w_absa:.1f})\")\n",
    "\n",
    "# 최적 MAE 값도 출력\n",
    "print(f\"최적의 MAE: {best_mae:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd_mae:.1f}, ABSA: {best_w_absa_mae:.1f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "757391da-7469-4ae0-b900-b1420758ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로 생성된 ABSA 피처 컬럼: ['aspect_1_net_sentiment', 'aspect_2_net_sentiment', 'aspect_3_net_sentiment', 'aspect_4_net_sentiment', 'aspect_5_net_sentiment']\n",
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "총 집계된 평점/ABSA 데이터 수: 428,953개\n",
      "\n",
      "--- ABSA 기반 아이템-아이템 유사도 행렬 계산 중 (시간 소요) ---\n",
      "ABSA 기반 아이템-아이템 유사도 행렬 계산 완료.\n",
      "\n",
      "--- 하이브리드 앙상블 모델 K-Fold 교차 검증 시작 (ABSA 피처 엔지니어링 반영) ---\n",
      "\n",
      "Fold 1/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 ABSA Prediction: 100%|██████████| 85791/85791 [00:03<00:00, 23884.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 ABSA Prediction: 100%|██████████| 85791/85791 [00:03<00:00, 23872.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 ABSA Prediction: 100%|██████████| 85791/85791 [00:04<00:00, 20158.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 ABSA Prediction: 100%|██████████| 85790/85790 [00:03<00:00, 24115.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 ABSA Prediction: 100%|██████████| 85790/85790 [00:03<00:00, 24067.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 앙상블 가중치 조합 탐색 시작 (ABSA 피처 엔지니어링 반영) ---\n",
      "w_svd: 0.1, w_absa: 0.9, RMSE: 1.1057\n",
      "w_svd: 0.2, w_absa: 0.8, RMSE: 1.0889\n",
      "w_svd: 0.3, w_absa: 0.7, RMSE: 1.0749\n",
      "w_svd: 0.4, w_absa: 0.6, RMSE: 1.0638\n",
      "w_svd: 0.5, w_absa: 0.5, RMSE: 1.0558\n",
      "w_svd: 0.6, w_absa: 0.4, RMSE: 1.0509\n",
      "w_svd: 0.7, w_absa: 0.3, RMSE: 1.0491\n",
      "w_svd: 0.8, w_absa: 0.2, RMSE: 1.0505\n",
      "w_svd: 0.9, w_absa: 0.1, RMSE: 1.0550\n",
      "\n",
      "--- 앙상블 결과 (ABSA 피처 엔지니어링 반영) ---\n",
      "최적의 RMSE: 1.0491\n",
      "최적의 가중치 (SVD: 0.7, ABSA: 0.3)\n",
      "최적의 MAE: 0.8345\n",
      "최적의 가중치 (SVD: 0.1, ABSA: 0.9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "data = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "data_clean = data[['user_id', 'business_id', 'stars', 'sentiment_vector']].copy()\n",
    "\n",
    "# 사용자와 비즈니스 아이디를 숫자로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "data_clean.loc[:, 'user_encoded'] = user_encoder.fit_transform(data_clean['user_id'])\n",
    "data_clean.loc[:, 'business_encoded'] = business_encoder.fit_transform(data_clean['business_id'])\n",
    "\n",
    "# sentiment_vector 컬럼을 각 요소별로 분리\n",
    "sentiment_vector_df = pd.DataFrame(data_clean['sentiment_vector'].tolist(),\n",
    "                                   index=data_clean.index,\n",
    "                                   columns=[f'sentiment_vector_{i}' for i in range(len(data_clean['sentiment_vector'].iloc[0]))])\n",
    "\n",
    "data_clean = pd.concat([data_clean.drop('sentiment_vector', axis=1), sentiment_vector_df], axis=1)\n",
    "\n",
    "# --- 새로운 ABSA 피처 엔지니어링: 각 측면별 순 감성 점수 추출 ---\n",
    "# 가정: sentiment_vector는 3개씩 묶여 5개 측면의 (부정, 중립, 긍정) 감성 점수를 나타냄\n",
    "new_absa_feature_cols = []\n",
    "num_aspects = 5 # 5개 측면을 가정\n",
    "for i in range(num_aspects):\n",
    "    neg_col = f'sentiment_vector_{i*3}' # 부정 감성 인덱스\n",
    "    pos_col = f'sentiment_vector_{i*3+2}' # 긍정 감성 인덱스\n",
    "    net_sentiment_col_name = f'aspect_{i+1}_net_sentiment'\n",
    "    data_clean[net_sentiment_col_name] = data_clean[pos_col] - data_clean[neg_col]\n",
    "    new_absa_feature_cols.append(net_sentiment_col_name)\n",
    "\n",
    "print(f\"새로 생성된 ABSA 피처 컬럼: {new_absa_feature_cols}\")\n",
    "\n",
    "# 사용자-비즈니스-평점/ABSA 피처 집계 (평균)\n",
    "group_cols = ['user_encoded', 'business_encoded']\n",
    "agg_funcs = {'stars': 'mean'}\n",
    "for col in new_absa_feature_cols:\n",
    "    agg_funcs[col] = 'mean'\n",
    "\n",
    "data_aggregated = data_clean.groupby(group_cols, as_index=False).agg(agg_funcs)\n",
    "\n",
    "print(f\"총 고유 사용자 수: {data_aggregated['user_encoded'].nunique():,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {data_aggregated['business_encoded'].nunique():,}개\")\n",
    "print(f\"총 집계된 평점/ABSA 데이터 수: {len(data_aggregated):,}개\")\n",
    "\n",
    "# --- 2. Surprise SVD 모델 학습 및 예측 준비 ---\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data_surprise = Dataset.load_from_df(data_aggregated[['user_encoded', 'business_encoded', 'stars']], reader)\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# --- 3. ABSA 기반 콘텐츠 모델을 위한 데이터 준비 ---\n",
    "\n",
    "# 각 비즈니스별 새로운 ABSA 피처 평균 계산 (아이템 콘텐츠 벡터)\n",
    "business_absa_features_avg = data_aggregated.groupby('business_encoded')[new_absa_feature_cols].mean()\n",
    "\n",
    "# 코사인 유사도 계산을 위해 DataFrame을 numpy 배열로 변환\n",
    "absa_matrix = business_absa_features_avg.values\n",
    "# 비즈니스 ID 인덱스 매핑\n",
    "business_id_to_idx = {business_id: idx for idx, business_id in enumerate(business_absa_features_avg.index)}\n",
    "idx_to_business_id = {idx: business_id for business_id, idx in business_id_to_idx.items()}\n",
    "\n",
    "# 아이템-아이템 코사인 유사도 계산 (새로운 ABSA 피처 기반)\n",
    "print(\"\\n--- ABSA 기반 아이템-아이템 유사도 행렬 계산 중 (시간 소요) ---\")\n",
    "item_absa_similarity_matrix = cosine_similarity(absa_matrix)\n",
    "print(\"ABSA 기반 아이템-아이템 유사도 행렬 계산 완료.\")\n",
    "\n",
    "# --- 4. 앙상블을 위한 교차 검증 및 예측 ---\n",
    "\n",
    "svd_predictions_list = []\n",
    "absa_predictions_list = []\n",
    "\n",
    "print(\"\\n--- 하이브리드 앙상블 모델 K-Fold 교차 검증 시작 (ABSA 피처 엔지니어링 반영) ---\")\n",
    "\n",
    "for fold_idx, (trainset, testset) in enumerate(kf.split(data_surprise)):\n",
    "    print(f\"\\nFold {fold_idx+1}/{kf.n_splits} - 학습 및 예측 중...\")\n",
    "\n",
    "    # --- 4-1. SVD 모델 학습 및 예측 ---\n",
    "    svd_algo = SVD(n_factors=500, random_state=42, n_epochs=20, lr_all=0.005, reg_all=0.02, verbose=False)\n",
    "    svd_algo.fit(trainset)\n",
    "    svd_fold_predictions = svd_algo.test(testset)\n",
    "    svd_predictions_list.extend(svd_fold_predictions)\n",
    "\n",
    "\n",
    "    # --- 4-2. ABSA 기반 콘텐츠 모델 예측 ---\n",
    "    absa_fold_predictions = []\n",
    "    \n",
    "    for uid_outer, iid_outer, true_r in tqdm(testset, desc=f\"Fold {fold_idx+1} ABSA Prediction\"):\n",
    "        \n",
    "        try:\n",
    "            user_inner_id = trainset.to_inner_uid(uid_outer)\n",
    "            user_ratings_in_train = trainset.ur[user_inner_id] # (item_inner_id, rating) 튜플 리스트\n",
    "            \n",
    "            # 사용자 평균 평점 계산 (수정된 부분)\n",
    "            # 해당 사용자가 훈련 세트에서 평가한 평점들이 존재할 때만 계산\n",
    "            if user_ratings_in_train: \n",
    "                user_avg_rating = np.mean([r for _, r in user_ratings_in_train])\n",
    "            else: # 평가한 아이템이 없다면 전체 평균\n",
    "                user_avg_rating = trainset.global_mean\n",
    "\n",
    "        except ValueError: # 테스트 유저가 훈련셋에 없는 경우\n",
    "            # 이 경우 user_avg_rating은 trainset.global_mean으로 설정\n",
    "            user_avg_rating = trainset.global_mean\n",
    "            user_ratings_in_train = [] # 평가한 아이템 없음을 표시\n",
    "            \n",
    "        rated_items_by_user = []\n",
    "        for item_inner_id, rating in user_ratings_in_train:\n",
    "            rated_items_by_user.append((trainset.to_raw_iid(item_inner_id), rating))\n",
    "\n",
    "        predicted_absa_rating = user_avg_rating # 기본값은 사용자 평균 평점 (없다면 전체 평균)\n",
    "        \n",
    "        if iid_outer not in business_id_to_idx:\n",
    "            absa_fold_predictions.append((uid_outer, iid_outer, true_r, predicted_absa_rating, {}))\n",
    "            continue\n",
    "\n",
    "        target_item_absa_idx = business_id_to_idx[iid_outer]\n",
    "        \n",
    "        weighted_sum = 0\n",
    "        similarity_sum = 0\n",
    "        \n",
    "        for rated_item_outer_id, rated_rating in rated_items_by_user:\n",
    "            if rated_item_outer_id in business_id_to_idx:\n",
    "                rated_item_absa_idx = business_id_to_idx[rated_item_outer_id]\n",
    "                \n",
    "                similarity = item_absa_similarity_matrix[target_item_absa_idx, rated_item_absa_idx]\n",
    "                \n",
    "                if similarity > 0:\n",
    "                    weighted_sum += similarity * rated_rating\n",
    "                    similarity_sum += similarity\n",
    "        \n",
    "        if similarity_sum > 0:\n",
    "            predicted_absa_rating = weighted_sum / similarity_sum\n",
    "        else:\n",
    "            # 유사한 아이템을 찾지 못했다면, 이전에 계산한 사용자 평균 평점 사용\n",
    "            predicted_absa_rating = user_avg_rating\n",
    "        \n",
    "        absa_fold_predictions.append((uid_outer, iid_outer, true_r, predicted_absa_rating, {}))\n",
    "    \n",
    "    absa_predictions_list.extend(absa_fold_predictions)\n",
    "\n",
    "# --- 5. 예측 결과 결합 및 RMSE 측정 ---\n",
    "\n",
    "svd_preds_df = pd.DataFrame([(p.uid, p.iid, p.est, p.r_ui) for p in svd_predictions_list], columns=['uid', 'iid', 'svd_est', 'true_r'])\n",
    "absa_preds_df = pd.DataFrame([(p[0], p[1], p[3]) for p in absa_predictions_list], columns=['uid', 'iid', 'absa_est'])\n",
    "\n",
    "combined_preds_df = pd.merge(svd_preds_df, absa_preds_df, on=['uid', 'iid'], how='inner')\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_mae = float('inf')  # MAE에 대한 변수 추가\n",
    "best_w_svd = 0\n",
    "best_w_absa = 0\n",
    "\n",
    "weights_svd = np.linspace(0.1, 0.9, 9)\n",
    "weights_absa = 1 - weights_svd\n",
    "\n",
    "print(\"\\n--- 앙상블 가중치 조합 탐색 시작 (ABSA 피처 엔지니어링 반영) ---\")\n",
    "results = []\n",
    "for w_svd, w_absa in zip(weights_svd, weights_absa):\n",
    "    combined_preds_df['ensemble_est'] = (w_svd * combined_preds_df['svd_est']) + \\\n",
    "                                        (w_absa * combined_preds_df['absa_est'])\n",
    "    \n",
    "    combined_preds_df['ensemble_est'] = np.clip(combined_preds_df['ensemble_est'], 1, 5)\n",
    "\n",
    "    rmse = np.sqrt(np.mean((combined_preds_df['ensemble_est'] - combined_preds_df['true_r'])**2))\n",
    "    \n",
    "    results.append({'w_svd': w_svd, 'w_absa': w_absa, 'rmse': rmse})\n",
    "    print(f\"w_svd: {w_svd:.1f}, w_absa: {w_absa:.1f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_w_svd = w_svd\n",
    "        best_w_absa = w_absa\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_w_svd_mae = w_svd\n",
    "        best_w_absa_mae = w_absa\n",
    "\n",
    "\n",
    "print(\"\\n--- 앙상블 결과 (ABSA 피처 엔지니어링 반영) ---\")\n",
    "print(f\"최적의 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd:.1f}, ABSA: {best_w_absa:.1f})\")\n",
    "\n",
    "# 최적 MAE 값도 출력\n",
    "print(f\"최적의 MAE: {best_mae:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd_mae:.1f}, ABSA: {best_w_absa_mae:.1f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7f1d150-daea-428e-a245-f60ae9cc8f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 ABSA 피처 컬럼: ['sentiment_vector_0', 'sentiment_vector_1', 'sentiment_vector_2', 'sentiment_vector_3', 'sentiment_vector_4', 'sentiment_vector_5', 'sentiment_vector_6', 'sentiment_vector_7', 'sentiment_vector_8', 'sentiment_vector_9', 'sentiment_vector_10', 'sentiment_vector_11', 'sentiment_vector_12', 'sentiment_vector_13', 'sentiment_vector_14']\n",
      "총 ABSA 피처 개수: 15개\n",
      "총 고유 사용자 수: 27,807명\n",
      "총 고유 비즈니스 수: 6,831개\n",
      "총 집계된 평점/ABSA 데이터 수: 428,953개\n",
      "\n",
      "--- ABSA 기반 아이템-아이템 유사도 행렬 계산 중 (시간 소요) ---\n",
      "ABSA 기반 아이템-아이템 유사도 행렬 계산 완료.\n",
      "\n",
      "--- 하이브리드 앙상블 모델 K-Fold 교차 검증 시작 (15차원 ABSA 피처 반영) ---\n",
      "\n",
      "Fold 1/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 ABSA Prediction: 100%|██████████| 85791/85791 [00:03<00:00, 22514.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 ABSA Prediction: 100%|██████████| 85791/85791 [00:03<00:00, 23181.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 ABSA Prediction: 100%|██████████| 85791/85791 [00:04<00:00, 19070.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 ABSA Prediction: 100%|██████████| 85790/85790 [00:03<00:00, 22893.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5/5 - 학습 및 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 ABSA Prediction: 100%|██████████| 85790/85790 [00:03<00:00, 22844.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 앙상블 가중치 조합 탐색 시작 (15차원 ABSA 피처 반영) ---\n",
      "w_svd: 0.1, w_absa: 0.9, RMSE: 1.1091, MAE: 0.8576\n",
      "w_svd: 0.2, w_absa: 0.8, RMSE: 1.0927, MAE: 0.8478\n",
      "w_svd: 0.3, w_absa: 0.7, RMSE: 1.0789, MAE: 0.8397\n",
      "w_svd: 0.4, w_absa: 0.6, RMSE: 1.0678, MAE: 0.8332\n",
      "w_svd: 0.5, w_absa: 0.5, RMSE: 1.0596, MAE: 0.8285\n",
      "w_svd: 0.6, w_absa: 0.4, RMSE: 1.0543, MAE: 0.8256\n",
      "w_svd: 0.7, w_absa: 0.3, RMSE: 1.0520, MAE: 0.8246\n",
      "w_svd: 0.8, w_absa: 0.2, RMSE: 1.0526, MAE: 0.8254\n",
      "w_svd: 0.9, w_absa: 0.1, RMSE: 1.0562, MAE: 0.8280\n",
      "\n",
      "--- 앙상블 결과 (15차원 ABSA 피처 반영) ---\n",
      "최적의 RMSE: 1.0520\n",
      "최적의 가중치 (SVD: 0.7, ABSA: 0.3)\n",
      "최적의 MAE: 0.8246\n",
      "최적의 가중치 (SVD: 0.7, ABSA: 0.3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Surprise Library Imports ---\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "\n",
    "# --- 1. 데이터 로드 및 전처리 ---\n",
    "data = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "data_clean = data[['user_id', 'business_id', 'stars', 'sentiment_vector']].copy()\n",
    "\n",
    "# 사용자와 비즈니스 아이디를 숫자로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "data_clean.loc[:, 'user_encoded'] = user_encoder.fit_transform(data_clean['user_id'])\n",
    "data_clean.loc[:, 'business_encoded'] = business_encoder.fit_transform(data_clean['business_id'])\n",
    "\n",
    "# sentiment_vector 컬럼을 각 요소별로 분리하여 새로운 컬럼 생성\n",
    "# 이번에는 15개 모든 차원을 피처로 사용합니다.\n",
    "sentiment_vector_df = pd.DataFrame(data_clean['sentiment_vector'].tolist(),\n",
    "                                   index=data_clean.index,\n",
    "                                   columns=[f'sentiment_vector_{i}' for i in range(len(data_clean['sentiment_vector'].iloc[0]))])\n",
    "\n",
    "data_clean = pd.concat([data_clean.drop('sentiment_vector', axis=1), sentiment_vector_df], axis=1)\n",
    "\n",
    "# ABSA 피처 컬럼 이름 목록 생성 (모든 15개 차원)\n",
    "absa_feature_cols = [col for col in data_clean.columns if 'sentiment_vector_' in col]\n",
    "\n",
    "print(f\"사용할 ABSA 피처 컬럼: {absa_feature_cols}\")\n",
    "print(f\"총 ABSA 피처 개수: {len(absa_feature_cols)}개\")\n",
    "\n",
    "\n",
    "# 사용자-비즈니스-평점/ABSA 피처 집계 (평균)\n",
    "group_cols = ['user_encoded', 'business_encoded']\n",
    "agg_funcs = {'stars': 'mean'}\n",
    "for col in absa_feature_cols: # 모든 15개 피처를 집계에 포함\n",
    "    agg_funcs[col] = 'mean'\n",
    "\n",
    "data_aggregated = data_clean.groupby(group_cols, as_index=False).agg(agg_funcs)\n",
    "\n",
    "print(f\"총 고유 사용자 수: {data_aggregated['user_encoded'].nunique():,}명\")\n",
    "print(f\"총 고유 비즈니스 수: {data_aggregated['business_encoded'].nunique():,}개\")\n",
    "print(f\"총 집계된 평점/ABSA 데이터 수: {len(data_aggregated):,}개\")\n",
    "\n",
    "# --- 2. Surprise SVD 모델 학습 및 예측 준비 ---\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data_surprise = Dataset.load_from_df(data_aggregated[['user_encoded', 'business_encoded', 'stars']], reader)\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# --- 3. ABSA 기반 콘텐츠 모델을 위한 데이터 준비 ---\n",
    "\n",
    "# 각 비즈니스별 15개 ABSA 피처 평균 계산 (아이템 콘텐츠 벡터)\n",
    "business_absa_features_avg = data_aggregated.groupby('business_encoded')[absa_feature_cols].mean()\n",
    "\n",
    "# 코사인 유사도 계산을 위해 DataFrame을 numpy 배열로 변환\n",
    "absa_matrix = business_absa_features_avg.values\n",
    "# 비즈니스 ID 인덱스 매핑\n",
    "business_id_to_idx = {business_id: idx for idx, business_id in enumerate(business_absa_features_avg.index)}\n",
    "idx_to_business_id = {idx: business_id for business_id, idx in business_id_to_idx.items()}\n",
    "\n",
    "# 아이템-아이템 코사인 유사도 계산 (15개 ABSA 피처 기반)\n",
    "print(\"\\n--- ABSA 기반 아이템-아이템 유사도 행렬 계산 중 (시간 소요) ---\")\n",
    "item_absa_similarity_matrix = cosine_similarity(absa_matrix)\n",
    "print(\"ABSA 기반 아이템-아이템 유사도 행렬 계산 완료.\")\n",
    "\n",
    "# --- 4. 앙상블을 위한 교차 검증 및 예측 ---\n",
    "\n",
    "svd_predictions_list = []\n",
    "absa_predictions_list = []\n",
    "\n",
    "print(\"\\n--- 하이브리드 앙상블 모델 K-Fold 교차 검증 시작 (15차원 ABSA 피처 반영) ---\")\n",
    "\n",
    "for fold_idx, (trainset, testset) in enumerate(kf.split(data_surprise)):\n",
    "    print(f\"\\nFold {fold_idx+1}/{kf.n_splits} - 학습 및 예측 중...\")\n",
    "\n",
    "    # --- 4-1. SVD 모델 학습 및 예측 ---\n",
    "    svd_algo = SVD(n_factors=500, random_state=42, n_epochs=20, lr_all=0.005, reg_all=0.02, verbose=False)\n",
    "    svd_algo.fit(trainset)\n",
    "    svd_fold_predictions = svd_algo.test(testset)\n",
    "    svd_predictions_list.extend(svd_fold_predictions)\n",
    "\n",
    "\n",
    "    # --- 4-2. ABSA 기반 콘텐츠 모델 예측 ---\n",
    "    absa_fold_predictions = []\n",
    "    \n",
    "    for uid_outer, iid_outer, true_r in tqdm(testset, desc=f\"Fold {fold_idx+1} ABSA Prediction\"):\n",
    "        \n",
    "        try:\n",
    "            user_inner_id = trainset.to_inner_uid(uid_outer)\n",
    "            user_ratings_in_train = trainset.ur[user_inner_id]\n",
    "            \n",
    "            if user_ratings_in_train: \n",
    "                user_avg_rating = np.mean([r for _, r in user_ratings_in_train])\n",
    "            else:\n",
    "                user_avg_rating = trainset.global_mean\n",
    "\n",
    "        except ValueError:\n",
    "            user_avg_rating = trainset.global_mean\n",
    "            user_ratings_in_train = []\n",
    "            \n",
    "        rated_items_by_user = []\n",
    "        for item_inner_id, rating in user_ratings_in_train:\n",
    "            rated_items_by_user.append((trainset.to_raw_iid(item_inner_id), rating))\n",
    "\n",
    "        predicted_absa_rating = user_avg_rating\n",
    "        \n",
    "        if iid_outer not in business_id_to_idx:\n",
    "            absa_fold_predictions.append((uid_outer, iid_outer, true_r, predicted_absa_rating, {}))\n",
    "            continue\n",
    "\n",
    "        target_item_absa_idx = business_id_to_idx[iid_outer]\n",
    "        \n",
    "        weighted_sum = 0\n",
    "        similarity_sum = 0\n",
    "        \n",
    "        for rated_item_outer_id, rated_rating in rated_items_by_user:\n",
    "            if rated_item_outer_id in business_id_to_idx:\n",
    "                rated_item_absa_idx = business_id_to_idx[rated_item_outer_id]\n",
    "                \n",
    "                similarity = item_absa_similarity_matrix[target_item_absa_idx, rated_item_absa_idx]\n",
    "                \n",
    "                if similarity > 0:\n",
    "                    weighted_sum += similarity * rated_rating\n",
    "                    similarity_sum += similarity\n",
    "        \n",
    "        if similarity_sum > 0:\n",
    "            predicted_absa_rating = weighted_sum / similarity_sum\n",
    "        else:\n",
    "            predicted_absa_rating = user_avg_rating\n",
    "        \n",
    "        absa_fold_predictions.append((uid_outer, iid_outer, true_r, predicted_absa_rating, {}))\n",
    "    \n",
    "    absa_predictions_list.extend(absa_fold_predictions)\n",
    "\n",
    "# --- 5. 예측 결과 결합 및 RMSE 측정 ---\n",
    "\n",
    "svd_preds_df = pd.DataFrame([(p.uid, p.iid, p.est, p.r_ui) for p in svd_predictions_list], columns=['uid', 'iid', 'svd_est', 'true_r'])\n",
    "absa_preds_df = pd.DataFrame([(p[0], p[1], p[3]) for p in absa_predictions_list], columns=['uid', 'iid', 'absa_est'])\n",
    "\n",
    "combined_preds_df = pd.merge(svd_preds_df, absa_preds_df, on=['uid', 'iid'], how='inner')\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_w_svd = 0\n",
    "best_w_absa = 0\n",
    "best_mae = float('inf') # MAE도 함께 추적\n",
    "best_w_svd_mae = 0\n",
    "best_w_absa_mae = 0\n",
    "\n",
    "weights_svd = np.linspace(0.1, 0.9, 9)\n",
    "weights_absa = 1 - weights_svd\n",
    "\n",
    "print(\"\\n--- 앙상블 가중치 조합 탐색 시작 (15차원 ABSA 피처 반영) ---\")\n",
    "results = []\n",
    "for w_svd, w_absa in zip(weights_svd, weights_absa):\n",
    "    combined_preds_df['ensemble_est'] = (w_svd * combined_preds_df['svd_est']) + \\\n",
    "                                        (w_absa * combined_preds_df['absa_est'])\n",
    "    \n",
    "    combined_preds_df['ensemble_est'] = np.clip(combined_preds_df['ensemble_est'], 1, 5)\n",
    "\n",
    "    rmse = np.sqrt(np.mean((combined_preds_df['ensemble_est'] - combined_preds_df['true_r'])**2))\n",
    "    mae = np.mean(np.abs(combined_preds_df['ensemble_est'] - combined_preds_df['true_r']))\n",
    "    \n",
    "    results.append({'w_svd': w_svd, 'w_absa': w_absa, 'rmse': rmse, 'mae': mae})\n",
    "    print(f\"w_svd: {w_svd:.1f}, w_absa: {w_absa:.1f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_w_svd = w_svd\n",
    "        best_w_absa = w_absa\n",
    "    \n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_w_svd_mae = w_svd\n",
    "        best_w_absa_mae = w_absa\n",
    "\n",
    "\n",
    "print(\"\\n--- 앙상블 결과 (15차원 ABSA 피처 반영) ---\")\n",
    "print(f\"최적의 RMSE: {best_rmse:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd:.1f}, ABSA: {best_w_absa:.1f})\")\n",
    "print(f\"최적의 MAE: {best_mae:.4f}\")\n",
    "print(f\"최적의 가중치 (SVD: {best_w_svd_mae:.1f}, ABSA: {best_w_absa_mae:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f031be3-08d0-49b2-b8b6-8588f3cedb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
