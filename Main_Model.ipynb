{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b576ab-7b8a-422e-8e0b-724ebe7e19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 447796\n",
      "학습 데이터 수: 313456 (70.00%)\n",
      "검증 데이터 수: 44780 (10.00%)\n",
      "테스트 데이터 수: 89560 (20.00%)\n",
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "Applying pre-selected Best Parameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "==================================================\n",
      "\n",
      "--- Training Final Model with Best Parameters ---\n",
      "Final Train Epoch 1/50, Train Loss: 0.6857, Val RMSE: 0.7278\n",
      "  --> RMSE improved. Model saved: 0.7278\n",
      "Final Train Epoch 2/50, Train Loss: 0.4749, Val RMSE: 0.6924\n",
      "  --> RMSE improved. Model saved: 0.6924\n",
      "Final Train Epoch 3/50, Train Loss: 0.4384, Val RMSE: 0.6936\n",
      "  --> RMSE not improved. (1/10)\n",
      "Final Train Epoch 4/50, Train Loss: 0.4106, Val RMSE: 0.6934\n",
      "  --> RMSE not improved. (2/10)\n",
      "Final Train Epoch 5/50, Train Loss: 0.3860, Val RMSE: 0.6977\n",
      "  --> RMSE not improved. (3/10)\n",
      "Final Train Epoch 6/50, Train Loss: 0.3623, Val RMSE: 0.7046\n",
      "  --> RMSE not improved. (4/10)\n",
      "Final Train Epoch 7/50, Train Loss: 0.3387, Val RMSE: 0.7211\n",
      "  --> RMSE not improved. (5/10)\n",
      "Final Train Epoch 8/50, Train Loss: 0.3117, Val RMSE: 0.7171\n",
      "  --> RMSE not improved. (6/10)\n",
      "Final Train Epoch 9/50, Train Loss: 0.2850, Val RMSE: 0.7340\n",
      "  --> RMSE not improved. (7/10)\n",
      "Final Train Epoch 10/50, Train Loss: 0.2592, Val RMSE: 0.7525\n",
      "  --> RMSE not improved. (8/10)\n",
      "Final Train Epoch 11/50, Train Loss: 0.2332, Val RMSE: 0.7584\n",
      "  --> RMSE not improved. (9/10)\n",
      "Final Train Epoch 12/50, Train Loss: 0.2090, Val RMSE: 0.7810\n",
      "  --> RMSE not improved. (10/10)\n",
      "Early stopping - No validation RMSE improvement for 10 epochs.\n",
      "\n",
      "--- Evaluating Final Model on Test Set ---\n",
      "Loaded best model weights from final_best_aat_rec_model.pt\n",
      "\n",
      "--- Performance Evaluation (Final Model with Best Parameters) ---\n",
      "Selected Hyperparameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "Mean Squared Error (MSE): 0.4777\n",
      "Root Mean Squared Error (RMSE): 0.6911\n",
      "Mean Absolute Error (MAE): 0.5492\n",
      "Mean Absolute Percentage Error (MAPE): 19.65%\n",
      "\n",
      "--- Generating Top-5 Recommendations for FIRST 5 Users ---\n",
      "User smOvOajNG0lS4Pq7d8g4JQ -> Recommended Businesses: ['MYoRNLb5chwjQe3c_k37Gg', 'uPuHiKV7o-7izxLiFJIz2g', '2Gn_WhIitWsxYrDb45VCLQ', 'jFAj4ZTHKukcEnFZXz2DiA', 'AEtZdFFfDi-FBYUVH4CBkg']\n",
      "User IQsF3Rc6IgCzjVV9DE8KXg -> Recommended Businesses: ['MYoRNLb5chwjQe3c_k37Gg', 'jFAj4ZTHKukcEnFZXz2DiA', 'AEtZdFFfDi-FBYUVH4CBkg', 'ruPaJWpkFnyBxsN_LnnmQw', 'yMq9b-R8Z_K6Uhw6z-zZSg']\n",
      "User aFa96pz67TwOFu4Weq5Agg -> Recommended Businesses: ['MYoRNLb5chwjQe3c_k37Gg', 'jFAj4ZTHKukcEnFZXz2DiA', 'Bze5Vj4MmcE0KHGy346xqw', 'pYs54pWZ_ajw_c92ptzB3Q', 'uPuHiKV7o-7izxLiFJIz2g']\n",
      "User ZGjgfSvjQK886kiTzLwfLQ -> Recommended Businesses: ['MYoRNLb5chwjQe3c_k37Gg', 'xTpXA1J2Yl3iLB9RXDGwcw', 'jFAj4ZTHKukcEnFZXz2DiA', 'zCmdpK9TYREr3sO1QO6BCw', 'AEtZdFFfDi-FBYUVH4CBkg']\n",
      "User IKbjLnfBQtEyVzEu8CuOLg -> Recommended Businesses: ['MYoRNLb5chwjQe3c_k37Gg', 'jFAj4ZTHKukcEnFZXz2DiA', 'nFw2YbqSluNq9omto-ToUg', '8xp1f0z30A7aXPe1rSyHrQ', 'mlyTBHNwuDrb7FRGSw3o9g']\n",
      "\n",
      "Cleaned up 'temp_models' directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# --- 1. Utility Functions ---\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return 0.0 # 모든 y_true가 0인 경우 MAPE는 0으로 처리\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "\n",
    "# 파일 로드\n",
    "# IMPORTANT: Adjust this path to where your JSON file is located on your local machine.\n",
    "df = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "df_processed = df[['user_id', 'business_id', 'stars', 'sentiment_vector']].copy()\n",
    "\n",
    "# user_id와 business_id를 연속적인 정수 ID로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "df_processed.loc[:, 'user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed.loc[:, 'business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "# 데이터 분할\n",
    "# 논문에서 제시된 70/10/20 비율로 데이터 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8 # 10% of total data (1/8 of 80%)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "# Determine sentiment_vector_dim dynamically\n",
    "sentiment_vector_dim = len(df_processed['sentiment_vector'].iloc[0]) if not df_processed.empty else 15\n",
    "\n",
    "# --- 3. PyTorch Dataset and DataLoader Definition ---\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.business_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        self.sentiment_vectors = torch.tensor(np.array(df['sentiment_vector'].tolist()), dtype=torch.float)\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.business_ids[idx], self.sentiment_vectors[idx], self.stars[idx]\n",
    "\n",
    "# --- 4. Model Architecture Definition ---\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = mlp_dims[-1] if mlp_dims else embedding_dim * 2\n",
    "\n",
    "    def forward(self, user_ids, business_ids):\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        business_vec = self.business_embedding(business_ids)\n",
    "        combined_vec = torch.cat((user_vec, business_vec), dim=1)\n",
    "        interaction_features = self.mlp(combined_vec)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectModule(nn.Module):\n",
    "    def __init__(self, sentiment_vector_dim, aspect_mlp_dims):\n",
    "        super(ReviewAspectModule, self).__init__()\n",
    "        layers = []\n",
    "        input_dim = sentiment_vector_dim\n",
    "        for dim in aspect_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = aspect_mlp_dims[-1] if aspect_mlp_dims else sentiment_vector_dim\n",
    "\n",
    "    def forward(self, sentiment_vectors):\n",
    "        aspect_features = self.mlp(sentiment_vectors)\n",
    "        return aspect_features\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, aspect_mlp_dims, final_mlp_dims,\n",
    "                 sentiment_vector_dim):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_interaction_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        self.review_aspect_module = ReviewAspectModule(\n",
    "            sentiment_vector_dim, aspect_mlp_dims\n",
    "        )\n",
    "\n",
    "        final_input_dim = self.customer_restaurant_interaction_module.output_dim + \\\n",
    "                          self.review_aspect_module.output_dim\n",
    "\n",
    "        layers = []\n",
    "        input_dim = final_input_dim\n",
    "        for dim in final_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1)) # Final output is rating (1-dimensional)\n",
    "        self.prediction_mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, business_ids, sentiment_vectors):\n",
    "        user_biz_features = self.customer_restaurant_interaction_module(user_ids, business_ids)\n",
    "        aspect_features = self.review_aspect_module(sentiment_vectors)\n",
    "        combined_features = torch.cat((user_biz_features, aspect_features), dim=1)\n",
    "        predicted_rating = self.prediction_mlp(combined_features)\n",
    "        return predicted_rating.squeeze() # Return 1D rating\n",
    "\n",
    "# --- 5. Device Configuration (GPU Setup) ---\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 6. Dataset and DataLoader Creation ---\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df)\n",
    "\n",
    "# --- 7. Apply the Given Best Parameters ---\n",
    "# Previously, these were found via grid search. Now, we explicitly set them.\n",
    "best_params = {\n",
    "    'aspect_mlp_hidden_dims': [64, 32],\n",
    "    'batch_size': 128,\n",
    "    'embedding_dim': 64,\n",
    "    'final_mlp_hidden_dims': [32, 16],\n",
    "    'learning_rate': 0.001,\n",
    "    'user_biz_mlp_hidden_dims': [128, 64]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Applying pre-selected Best Parameters: {best_params}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 8. Final Model Training and Testing (Using Best Parameters) ---\n",
    "final_embedding_dim = best_params['embedding_dim']\n",
    "final_learning_rate = best_params['learning_rate']\n",
    "final_batch_size = best_params['batch_size']\n",
    "final_user_biz_mlp_dims = best_params['user_biz_mlp_hidden_dims']\n",
    "final_aspect_mlp_dims = best_params['aspect_mlp_hidden_dims']\n",
    "final_final_mlp_dims = best_params['final_mlp_hidden_dims']\n",
    "\n",
    "final_model = AATRec(num_users, num_businesses, final_embedding_dim,\n",
    "                     final_user_biz_mlp_dims, final_aspect_mlp_dims, final_final_mlp_dims,\n",
    "                     sentiment_vector_dim).to(device) # Move final model to device\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "final_optimizer = optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "\n",
    "final_train_loader = DataLoader(train_dataset, batch_size=final_batch_size, shuffle=True)\n",
    "final_val_loader = DataLoader(val_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "final_test_loader = DataLoader(test_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "\n",
    "final_epochs = 50 # Ample epochs for final training\n",
    "final_patience = 10 # More patience for final training\n",
    "final_min_delta = 0.0005 # Stricter improvement criterion\n",
    "\n",
    "best_final_val_rmse = float('inf')\n",
    "epochs_no_improve_final = 0\n",
    "final_model_path = 'final_best_aat_rec_model.pt'\n",
    "\n",
    "print(\"\\n--- Training Final Model with Best Parameters ---\")\n",
    "for epoch in range(final_epochs):\n",
    "    # Training phase\n",
    "    final_model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_ids, business_ids, sentiment_vectors, stars in final_train_loader:\n",
    "        user_ids, business_ids, sentiment_vectors, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), stars.to(device)\n",
    "\n",
    "        final_optimizer.zero_grad()\n",
    "        predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "        loss = final_criterion(predictions, stars)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    final_model.eval()\n",
    "    val_predictions = []\n",
    "    val_true_ratings = []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, business_ids, sentiment_vectors, stars in final_val_loader:\n",
    "            user_ids, business_ids, sentiment_vectors, stars = \\\n",
    "                user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), stars.to(device)\n",
    "\n",
    "            predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "            val_predictions.extend(predictions.cpu().tolist())\n",
    "            val_true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true_ratings, val_predictions))\n",
    "\n",
    "    print(f\"Final Train Epoch {epoch+1}/{final_epochs}, \"\n",
    "          f\"Train Loss: {total_train_loss / len(final_train_loader):.4f}, \"\n",
    "          f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "    # Early stopping logic for final model\n",
    "    if current_val_rmse < best_final_val_rmse - final_min_delta:\n",
    "        best_final_val_rmse = current_val_rmse\n",
    "        epochs_no_improve_final = 0\n",
    "        torch.save(final_model.state_dict(), final_model_path)\n",
    "        print(f\"  --> RMSE improved. Model saved: {best_final_val_rmse:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve_final += 1\n",
    "        print(f\"  --> RMSE not improved. ({epochs_no_improve_final}/{final_patience})\")\n",
    "        if epochs_no_improve_final == final_patience:\n",
    "            print(f\"Early stopping - No validation RMSE improvement for {final_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "# --- 9. Final Model Testing ---\n",
    "print(\"\\n--- Evaluating Final Model on Test Set ---\")\n",
    "if os.path.exists(final_model_path):\n",
    "    final_model.load_state_dict(torch.load(final_model_path))\n",
    "    print(f\"Loaded best model weights from {final_model_path}\")\n",
    "else:\n",
    "    print(f\"Could not find optimal final model weights at '{final_model_path}'. Testing with current model state.\")\n",
    "\n",
    "final_model.eval()\n",
    "test_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_ids, business_ids, sentiment_vectors, stars in final_test_loader:\n",
    "        user_ids, business_ids, sentiment_vectors, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), stars.to(device)\n",
    "\n",
    "        predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "mse = mean_squared_error(true_ratings, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "print(f\"\\n--- Performance Evaluation (Final Model with Best Parameters) ---\")\n",
    "print(f\"Selected Hyperparameters: {best_params}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# --- 10. Top-K Recommendation Function ---\n",
    "def recommend_topk_for_all_users(model, df_processed, user_encoder, business_encoder, k=5, device='cpu'):\n",
    "    model.eval()\n",
    "    user_ids_unique = df_processed['user_id'].unique()\n",
    "    business_ids_unique = df_processed['business_id'].unique()\n",
    "\n",
    "    # Calculate average sentiment_vector for each business_id\n",
    "    sentiment_dict = df_processed.groupby('business_id')['sentiment_vector'].apply(\n",
    "        lambda x: np.mean(x.tolist(), axis=0)\n",
    "    ).to_dict()\n",
    "\n",
    "    recommendations = {}\n",
    "\n",
    "    # Iterate through unique users\n",
    "    for user_id in user_ids_unique:\n",
    "        encoded_user = user_encoder.transform([user_id])[0]\n",
    "\n",
    "        # Businesses already rated by the current user\n",
    "        rated_biz = df_processed[df_processed['user_id'] == user_id]['business_id'].unique()\n",
    "        # Businesses not rated by the user and have a sentiment vector available\n",
    "        unrated_biz = [b for b in business_ids_unique if b not in rated_biz and b in sentiment_dict]\n",
    "\n",
    "        if not unrated_biz:\n",
    "            recommendations[user_id] = []\n",
    "            continue\n",
    "\n",
    "        # Prepare tensors for prediction\n",
    "        user_tensor = torch.tensor([encoded_user] * len(unrated_biz), dtype=torch.long).to(device)\n",
    "        biz_encoded = business_encoder.transform(unrated_biz)\n",
    "        biz_tensor = torch.tensor(biz_encoded, dtype=torch.long).to(device)\n",
    "        sentiment_list = [sentiment_dict[b] for b in unrated_biz]\n",
    "        sentiment_tensor = torch.tensor(np.array(sentiment_list), dtype=torch.float).to(device)\n",
    "\n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            predicted_ratings = model(user_tensor, biz_tensor, sentiment_tensor)\n",
    "\n",
    "        # Get Top-K indices and corresponding business IDs\n",
    "        actual_k = min(k, len(predicted_ratings))\n",
    "        if actual_k > 0:\n",
    "            topk_indices = torch.topk(predicted_ratings, actual_k).indices.tolist()\n",
    "            topk_business_ids = [unrated_biz[i] for i in topk_indices]\n",
    "        else:\n",
    "            topk_business_ids = []\n",
    "\n",
    "        recommendations[user_id] = topk_business_ids\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "print(\"\\n--- Generating Top-5 Recommendations for Users ---\")\n",
    "topk_result = recommend_topk_for_all_users(\n",
    "    model=final_model,\n",
    "    df_processed=df_processed,\n",
    "    user_encoder=user_encoder,\n",
    "    business_encoder=business_encoder,\n",
    "    k=5,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print example results (first 5 users)\n",
    "for user_id, recs in list(topk_result.items())[:5]:\n",
    "    print(f\"User {user_id} -> Recommended Businesses: {recs}\")\n",
    "\n",
    "# Clean up temporary models directory if it was created by the original script\n",
    "if os.path.exists('temp_models'):\n",
    "    import shutil\n",
    "    shutil.rmtree('temp_models')\n",
    "    print(\"\\nCleaned up 'temp_models' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb8421-c728-457d-9ca7-cb2894256a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
