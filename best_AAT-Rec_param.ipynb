{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde30f30-62a4-4f35-a9af-7a479eceee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 447796\n",
      "학습 데이터 수: 313456 (70.00%)\n",
      "검증 데이터 수: 44780 (10.00%)\n",
      "테스트 데이터 수: 89560 (20.00%)\n",
      "최적 검증 RMSE: 0.6879\n",
      "최적 파라미터: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "\n",
      " 최적 파라미터로 학습\n",
      "Final Train Epoch 1/50, Train Loss: 0.6888, Val Loss: 0.5094, Val RMSE: 0.7137\n",
      "RMSE 개선됨. 모델 저장됨: 0.7137\n",
      "Final Train Epoch 2/50, Train Loss: 0.4747, Val Loss: 0.4860, Val RMSE: 0.6971\n",
      "RMSE 개선됨. 모델 저장됨: 0.6971\n",
      "Final Train Epoch 3/50, Train Loss: 0.4398, Val Loss: 0.4741, Val RMSE: 0.6885\n",
      "RMSE 개선됨. 모델 저장됨: 0.6885\n",
      "Final Train Epoch 4/50, Train Loss: 0.4129, Val Loss: 0.4892, Val RMSE: 0.6994\n",
      "RMSE 개선되지 않음. (1/10)\n",
      "Final Train Epoch 5/50, Train Loss: 0.3884, Val Loss: 0.4802, Val RMSE: 0.6929\n",
      "RMSE 개선되지 않음. (2/10)\n",
      "Final Train Epoch 6/50, Train Loss: 0.3660, Val Loss: 0.4909, Val RMSE: 0.7006\n",
      "RMSE 개선되지 않음. (3/10)\n",
      "Final Train Epoch 7/50, Train Loss: 0.3420, Val Loss: 0.5080, Val RMSE: 0.7127\n",
      "RMSE 개선되지 않음. (4/10)\n",
      "Final Train Epoch 8/50, Train Loss: 0.3176, Val Loss: 0.5092, Val RMSE: 0.7136\n",
      "RMSE 개선되지 않음. (5/10)\n",
      "Final Train Epoch 9/50, Train Loss: 0.2914, Val Loss: 0.5358, Val RMSE: 0.7320\n",
      "RMSE 개선되지 않음. (6/10)\n",
      "Final Train Epoch 10/50, Train Loss: 0.2646, Val Loss: 0.5423, Val RMSE: 0.7364\n",
      "RMSE 개선되지 않음. (7/10)\n",
      "Final Train Epoch 11/50, Train Loss: 0.2386, Val Loss: 0.5710, Val RMSE: 0.7557\n",
      "RMSE 개선되지 않음. (8/10)\n",
      "Final Train Epoch 12/50, Train Loss: 0.2148, Val Loss: 0.5878, Val RMSE: 0.7666\n",
      "RMSE 개선되지 않음. (9/10)\n",
      "Final Train Epoch 13/50, Train Loss: 0.1929, Val Loss: 0.5922, Val RMSE: 0.7695\n",
      "RMSE 개선되지 않음. (10/10)\n",
      "조기 종료 - 10 epoch 동안 검증 RMSE 개선이 없었음\n",
      "최적 모델 가중치 final_best_aat_rec_model.pt\n",
      "\n",
      "성능 평가 (최적 파라미터)\n",
      "Selected Hyperparameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "Mean Squared Error (MSE): 0.4697\n",
      "Root Mean Squared Error (RMSE): 0.6854\n",
      "Mean Absolute Error (MAE): 0.5390\n",
      "Mean Absolute Percentage Error (MAPE): 18.79%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import itertools # For creating combinations of MLP dims\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return 0.0 # 모든 y_true가 0인 경우 MAPE는 0으로 처리\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "#파일 로드\n",
    "df = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "df_processed = df[['user_id', 'business_id', 'stars', 'sentiment_vector']].copy()\n",
    "\n",
    "# user_id와 business_id를 연속적인 정수 ID로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "df_processed.loc[:, 'user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed.loc[:, 'business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "# 데이터 분할\n",
    "# 논문에서 제시된 70/10/20 비율로 데이터 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8 # 10% of total data (1/8 of 80%)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "# --- PyTorch Dataset 및 DataLoader 정의 ---\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.business_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        # sentiment_vector가 비어있을 수 있으므로 numpy 배열로 변환 후 tolist()\n",
    "        self.sentiment_vectors = torch.tensor(np.array(df['sentiment_vector'].tolist()), dtype=torch.float)\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.business_ids[idx], self.sentiment_vectors[idx], self.stars[idx]\n",
    "\n",
    "# --- 모델 아키텍처 정의 ---\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "        \n",
    "        layers = []\n",
    "        # 논문에 따라 MLP의 첫 입력은 임베딩 결합 벡터 (embedding_dim * 2)\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        # MLP가 없을 경우를 대비하여 output_dim 설정 (최종 레이어 차원)\n",
    "        self.output_dim = mlp_dims[-1] if mlp_dims else embedding_dim * 2\n",
    "\n",
    "    def forward(self, user_ids, business_ids):\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        business_vec = self.business_embedding(business_ids)\n",
    "        combined_vec = torch.cat((user_vec, business_vec), dim=1)\n",
    "        interaction_features = self.mlp(combined_vec)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectModule(nn.Module):\n",
    "    # self-attention 및 키워드 추출 부분은 'sentiment_vector'에 이미 반영되었다고 가정\n",
    "    # 따라서, sentiment_vector_dim이 키워드 특성의 차원이라고 볼 수 있음\n",
    "    def __init__(self, sentiment_vector_dim, aspect_mlp_dims):\n",
    "        super(ReviewAspectModule, self).__init__()\n",
    "        layers = []\n",
    "        input_dim = sentiment_vector_dim\n",
    "        for dim in aspect_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = aspect_mlp_dims[-1] if aspect_mlp_dims else sentiment_vector_dim\n",
    "\n",
    "    def forward(self, sentiment_vectors):\n",
    "        aspect_features = self.mlp(sentiment_vectors)\n",
    "        return aspect_features\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, aspect_mlp_dims, final_mlp_dims,\n",
    "                 sentiment_vector_dim):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_interaction_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        # sentiment_vector_dim은 실제 sentiment_vector의 차원을 가져옴\n",
    "        self.review_aspect_module = ReviewAspectModule(\n",
    "            sentiment_vector_dim, aspect_mlp_dims\n",
    "        )\n",
    "        \n",
    "        # 평점 예측 모듈의 입력 차원 계산\n",
    "        final_input_dim = self.customer_restaurant_interaction_module.output_dim + \\\n",
    "                          self.review_aspect_module.output_dim\n",
    "        \n",
    "        layers = []\n",
    "        input_dim = final_input_dim\n",
    "        for dim in final_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1)) # 최종 출력은 평점 (1차원)\n",
    "        self.prediction_mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, business_ids, sentiment_vectors):\n",
    "        user_biz_features = self.customer_restaurant_interaction_module(user_ids, business_ids)\n",
    "        aspect_features = self.review_aspect_module(sentiment_vectors)\n",
    "        combined_features = torch.cat((user_biz_features, aspect_features), dim=1)\n",
    "        predicted_rating = self.prediction_mlp(combined_features)\n",
    "        return predicted_rating.squeeze() # 1차원 평점 반환\n",
    "\n",
    "# sentiment_vector의 실제 차원을 데이터프레임에서 동적으로 가져옴\n",
    "sentiment_vector_dim = len(df_processed['sentiment_vector'].iloc[0]) if not df_processed.empty else 15 # 데이터 없으면 기본값\n",
    "\n",
    "# --- 데이터셋 및 DataLoader 생성 (여기로 이동!) ---\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df) # test_loader는 최종 평가에만 사용되므로 여기에 포함\n",
    "\n",
    "# --- 하이퍼파라미터 탐색 공간 정의 ---\n",
    "# 논문에서 제시된 값을 기준으로, 주변 값을 탐색\n",
    "param_grid = {\n",
    "    'embedding_dim': [64],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001], # 논문 값 포함하여 주변 탐색\n",
    "    'batch_size': [128, 256, 512], # 논문 값 포함하여 주변 탐색\n",
    "    'user_biz_mlp_hidden_dims': [[128, 64], [64, 32]], # 1번 모듈 MLP 히든 레이어 차원 조합 (출력 차원 자동 결정)\n",
    "    'aspect_mlp_hidden_dims': [[64, 32], [32, 16]], # 2번 모듈 MLP 히든 레이어 차원 조합\n",
    "    'final_mlp_hidden_dims': [[64, 32], [32, 16]] # 최종 평점 예측 모듈 MLP 히든 레이어 차원 조합\n",
    "}\n",
    "\n",
    "best_overall_rmse = float('inf')\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "# 하이퍼파라미터 그리드를 순회\n",
    "for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "    #print(f\"\\n실험 {i+1}/{len(ParameterGrid(param_grid))}\")\n",
    "    #print(f\"현재 파라미터: {params}\")\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    embedding_dim = params['embedding_dim']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    user_biz_mlp_dims = params['user_biz_mlp_hidden_dims']\n",
    "    aspect_mlp_dims = params['aspect_mlp_hidden_dims']\n",
    "    final_mlp_dims = params['final_mlp_hidden_dims']\n",
    "    \n",
    "    epochs = 50 # 각 조합별 최대 에폭\n",
    "    patience = 5 # 조기 종료를 위한 대기 에폭\n",
    "    min_delta = 0.001 # 성능 개선을 판단하는 최소 변화량\n",
    "    \n",
    "    current_best_val_rmse = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    model_save_path = f'temp_best_model_{i}.pt' # 각 조합별 모델 저장 경로\n",
    "\n",
    "    # DataLoader 생성 (batch_size에 따라 새로 생성)\n",
    "    # train_loader와 val_loader는 여기서 새로 생성되어야 합니다.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # test_loader는 최종 평가에만 사용되므로 여기서는 생성하지 않아도 됩니다.\n",
    "\n",
    "    # 모델 인스턴스 생성 및 초기화\n",
    "    model = AATRec(num_users, num_businesses, embedding_dim,\n",
    "                   user_biz_mlp_dims, aspect_mlp_dims, final_mlp_dims,\n",
    "                   sentiment_vector_dim)\n",
    "    \n",
    "    # 손실 함수 및 옵티마이저\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # --- 학습 루프 (조기 종료 포함) ---\n",
    "    for epoch in range(epochs):\n",
    "        # 학습 단계\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for user_ids, business_ids, sentiment_vectors, stars in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_ids, business_ids, sentiment_vectors)\n",
    "            loss = criterion(predictions, stars)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_true_ratings = []\n",
    "        with torch.no_grad():\n",
    "            for user_ids, business_ids, sentiment_vectors, stars in val_loader:\n",
    "                predictions = model(user_ids, business_ids, sentiment_vectors)\n",
    "                loss = criterion(predictions, stars)\n",
    "                total_val_loss += loss.item()\n",
    "                val_predictions.extend(predictions.tolist())\n",
    "                val_true_ratings.extend(stars.tolist())\n",
    "\n",
    "        current_val_rmse = np.sqrt(mean_squared_error(val_true_ratings, val_predictions))\n",
    "\n",
    "        # print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "        #       f\"Train Loss: {total_train_loss / len(train_loader):.4f}, \"\n",
    "        #       f\"Val Loss: {total_val_loss / len(val_loader):.4f}, \"\n",
    "        #       f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "        # 조기 종료 로직\n",
    "        if current_val_rmse < current_best_val_rmse - min_delta:\n",
    "            current_best_val_rmse = current_val_rmse\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), model_save_path) # 현재 조합의 최적 모델 저장\n",
    "            # print(f\"  --> 검증 RMSE 개선됨. 현재 조합의 최적 모델 저장됨: {current_best_val_rmse:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            # print(f\"  --> 검증 RMSE 개선되지 않음. 대기 중... ({epochs_no_improve}/{patience})\")\n",
    "            if epochs_no_improve == patience:\n",
    "                #print(f\"조기 종료! {patience} epoch 동안 RMSE 개선이 없었음\")\n",
    "                break\n",
    "    \n",
    "    # 각 조합별 결과 기록\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'val_rmse': current_best_val_rmse\n",
    "    })\n",
    "\n",
    "    # 전체 최적 파라미터 업데이트\n",
    "    if current_best_val_rmse < best_overall_rmse:\n",
    "        best_overall_rmse = current_best_val_rmse\n",
    "        best_params = params\n",
    "        # 최종 최적 모델 가중치는 이 시점에서 저장하지 않고, 최종 테스트 전에 로드할 temp_best_model_X.pt로 간주\n",
    "        # 또는 best_params를 사용하여 다시 학습시켜 저장 가능\n",
    "\n",
    "print(f\"최적 검증 RMSE: {best_overall_rmse:.4f}\")\n",
    "print(f\"최적 파라미터: {best_params}\")\n",
    "\n",
    "# --- 최종 모델 학습 및 테스트 (최적 파라미터 사용) ---\n",
    "if best_params:\n",
    "    print(\"\\n 최적 파라미터로 학습\")\n",
    "    final_embedding_dim = best_params['embedding_dim']\n",
    "    final_learning_rate = best_params['learning_rate']\n",
    "    final_batch_size = best_params['batch_size']\n",
    "    final_user_biz_mlp_dims = best_params['user_biz_mlp_hidden_dims']\n",
    "    final_aspect_mlp_dims = best_params['aspect_mlp_hidden_dims']\n",
    "    final_final_mlp_dims = best_params['final_mlp_hidden_dims']\n",
    "\n",
    "    final_model = AATRec(num_users, num_businesses, final_embedding_dim,\n",
    "                         final_user_biz_mlp_dims, final_aspect_mlp_dims, final_final_mlp_dims,\n",
    "                         sentiment_vector_dim)\n",
    "    final_criterion = nn.MSELoss()\n",
    "    final_optimizer = optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "\n",
    "    final_train_loader = DataLoader(train_dataset, batch_size=final_batch_size, shuffle=True)\n",
    "    final_val_loader = DataLoader(val_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "    final_test_loader = DataLoader(test_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "    \n",
    "    final_epochs = 50 # 충분한 에폭\n",
    "    final_patience = 10 # 조기 종료 대기 에폭을 더 길게 설정할 수 있음\n",
    "    final_min_delta = 0.0005 # 더 엄격한 개선 기준\n",
    "    \n",
    "    best_final_val_rmse = float('inf')\n",
    "    epochs_no_improve_final = 0\n",
    "    final_model_path = 'final_best_aat_rec_model.pt'\n",
    "\n",
    "    for epoch in range(final_epochs):\n",
    "        # 학습 단계\n",
    "        final_model.train()\n",
    "        total_train_loss = 0\n",
    "        for user_ids, business_ids, sentiment_vectors, stars in final_train_loader:\n",
    "            final_optimizer.zero_grad()\n",
    "            predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "            loss = final_criterion(predictions, stars)\n",
    "            loss.backward()\n",
    "            final_optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # 검증 단계\n",
    "        final_model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_true_ratings = []\n",
    "        with torch.no_grad():\n",
    "            for user_ids, business_ids, sentiment_vectors, stars in final_val_loader:\n",
    "                predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "                loss = final_criterion(predictions, stars)\n",
    "                total_val_loss += loss.item()\n",
    "                val_predictions.extend(predictions.tolist())\n",
    "                val_true_ratings.extend(stars.tolist())\n",
    "        \n",
    "        current_val_rmse = np.sqrt(mean_squared_error(val_true_ratings, val_predictions))\n",
    "\n",
    "        print(f\"Final Train Epoch {epoch+1}/{final_epochs}, \"\n",
    "              f\"Train Loss: {total_train_loss / len(final_train_loader):.4f}, \"\n",
    "              f\"Val Loss: {total_val_loss / len(final_val_loader):.4f}, \"\n",
    "              f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "        # 조기 종료 로직\n",
    "        if current_val_rmse < best_final_val_rmse - final_min_delta:\n",
    "            best_final_val_rmse = current_val_rmse\n",
    "            epochs_no_improve_final = 0\n",
    "            torch.save(final_model.state_dict(), final_model_path)\n",
    "            print(f\"RMSE 개선됨. 모델 저장됨: {best_final_val_rmse:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve_final += 1\n",
    "            print(f\"RMSE 개선되지 않음. ({epochs_no_improve_final}/{final_patience})\")\n",
    "            if epochs_no_improve_final == final_patience:\n",
    "                print(f\"조기 종료 - {final_patience} epoch 동안 검증 RMSE 개선이 없었음\")\n",
    "                break\n",
    "\n",
    "    # --- 최종 모델 테스트 ---\n",
    "    if os.path.exists(final_model_path):\n",
    "        final_model.load_state_dict(torch.load(final_model_path))\n",
    "        print(f\"최적 모델 가중치 {final_model_path}\")\n",
    "    else:\n",
    "        print(f\"최적의 최종 모델 가중치 '{final_model_path}'를 찾을 수 없습니다. 현재 모델 상태로 테스트를 진행합니다.\")\n",
    "\n",
    "    final_model.eval()\n",
    "    test_predictions = []\n",
    "    true_ratings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user_ids, business_ids, sentiment_vectors, stars in final_test_loader:\n",
    "            predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "            test_predictions.extend(predictions.tolist())\n",
    "            true_ratings.extend(stars.tolist())\n",
    "\n",
    "    mse = mean_squared_error(true_ratings, test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "    print(f\"\\n성능 평가 (최적 파라미터)\")\n",
    "    print(f\"Selected Hyperparameters: {best_params}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "else:\n",
    "    print(\"최적 파라미터를 찾지 못해 최종 모델 학습 및 테스트를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351eb21a-77cf-4515-b562-c15b408bca2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
