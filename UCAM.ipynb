{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHCMxhgXtPb0",
    "outputId": "8bd1b59d-a10b-4a5d-bad0-90c9a5757790"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "887a51c86def4defad1a2a3c512e7eb1",
      "548e7b603ab643768a62e6bd4078d8f0",
      "b9594648216c4f448ba8ede050e4c4e2",
      "d29e8fba3b0e41988970747b77885618",
      "b79578a4c59d408da3d9134966e6fbfa",
      "3c7e0e9950da413d9e4565ce45c9e9ea",
      "0bb4b8f7c9074156ab24264600a9ba0c",
      "bd8d1efffa734fd6b40f80fd9a5f7409",
      "e2e76255d4414027bdb69ec1d52577b4",
      "71c9771ce1a54258849078756c8839d1",
      "48050917230f4514a3fbc5b14252726d",
      "8aa50b6fb16f47aea9b4cd0adcdc79de",
      "0a7bd20c14244272a82f62ef5f51f298",
      "9d1ed972bbda403c95b353cedec586cb",
      "22deadc6af724ce1bab979d7e6ec371d",
      "edf9cd61c96e42b6be0df1a07612ce65",
      "5112e13646ce4a44bcc5dcfa1f7d1e86",
      "49c39e663d7e4b3eb6c628e67bf81412",
      "ed5ddc13184b4ce395686c0e34a44dc3",
      "77f368105d0b4ffb8774365ed6772f6a",
      "74a6431a48c343fd81a5d0cde811111c",
      "733f92cc2dad44cdb7510529d9bab5b0",
      "cff3c076b13c4dbf8f84f9b15c7d299e",
      "65d816c279154f21880c49bd239b2117",
      "9d4db5c9d9e849fdb1547ee995d85f59",
      "98e78ca434524bb4a4985265f0cb7fea",
      "5d6be62205dc4b6d90abaa270eab6063",
      "e6467a5777ec48aea27023e36ed847f9",
      "fcbd0a2079a3479d8a6afb0d65eee522",
      "9c78aa3033ae4179bda0d01878972b16",
      "2827e42f071844399fc9c14bee3d147a",
      "64dd00b53b7147db8f7e7a048b880887",
      "d5283d687a9e44cfadca1db5101a00ea",
      "bfa893dacde149e09291bd2ee4d23373",
      "8a803fb133d24522ad707eb7e618253b",
      "2a0eb39b8453407f91266bd4e6f335a2",
      "36108fe41fd3424299999165844fc259",
      "cd5fa852de0445c3b2b3a9e3f6f235a1",
      "1f858eaf77574cde883537542d4f5506",
      "15564f51f1d845478bc8842c7318fbbd",
      "790df2ba0ede412d9de7c12a77315f78",
      "c124d9b42e004661a78285b94cc794fe",
      "a2dfb77c3e0b464588babab8a9e4bd33",
      "c8b23646d8ad419cbffbc6fafd5c96c5",
      "ac92c7cc8c2f4ba9b829fb6ed784996c",
      "bdfd309bf2124c9eab05d81706af44e3",
      "a655447e8cf24508b991a73b4205af8b",
      "3614bce2fce343ecbf6196c47c9f88ce",
      "92a0bd477e6b4210a27707a3ad6d6868",
      "9fc00ba3610642929c229e1422574b67",
      "be00ad59d38042bbac070eb521464e44",
      "66b12f965954439982bf0d6e60804fc5",
      "949dd77b503b4e21b39a911b9c3ccdcf",
      "aec3b2e976884d0e996b1a2cad167f99",
      "54d0b0266d854ca3b31b4ae12ae66de8",
      "96b31a60ebe649868091a92537b0292d",
      "2cb51bb2121843a0b23c7ca3c4f54e9d",
      "a7af1f01fbdc420d824b86793a840d96",
      "4f0c5778aaa845b8b08e22e01a5d18bb",
      "e545d3e73b6b48ffa7e28ee9fea58dbc",
      "0cea89deb3b84546951d44876d66dc61",
      "caf2a05d1d964b3f8da9a467a757c10e",
      "54192307da2c4772920fb719ffe36be3",
      "a56948afd28d47e29f15925d4dfb0c5d",
      "ff9090be24b8428c8e715e268d78fbfa",
      "dbf0bc7d15dd455cb9dd12ec14ddb24e",
      "bb513884c66a4f5aa5cec402db259ac3",
      "1bd4e334dcab4a57b20bdbca1c84effe",
      "4599212b5c4148a2b219e2de0f3726b2",
      "cfd148d43cbf4cedb435db109d63c391",
      "e6e1dacf4d3343b19d1dbc033d942239",
      "1c3b01f5c21b4ddaa53284c84378ae74",
      "3efa5679753e47259b3c1fd1a113ded3",
      "272ee4a25d294b268c77b1e8f34862f2",
      "b9fea86659314f798d83cbea1210908b",
      "12d651162fb34f37aaf7bb00f1b94312",
      "ad0a5f5801c849528db25a1018057205",
      "ec161434eb65497dadbe45a95ad9cbf7",
      "47428f7673dc45809ab3916d941fae57",
      "fc8020074751476ebb18c9a805be1dbc",
      "ac2fdf26d95543e0a0b798ffa04edf41",
      "3343a43543864299bae71d63e63f729d",
      "d4d79e6480794a629bc71c0698a35e3f",
      "b5e06a890e5245a8b55bfce2988a8573",
      "c1a390c71d014958a76a960c6b113722",
      "ed7418b58d46400c998e0112cb340619",
      "c977c1526b5a447f9ee37c9499571c2c",
      "0329103aca984ddfbf25944d0bbe88c0",
      "7e9223449bdd4c17990de5bd12aaf337",
      "378fe8ff5f6c4fb6a5c1c5cc5710a193",
      "9a919e68b7104e8693b52f1824b75898",
      "67c6a311d4b648f489eced82ab07537b",
      "05a8e9418c6a481aa96a882e2d593bf4",
      "69685027682d4bb2a74942c5bb58dc06",
      "f7407eaf725f43ca8a5adde4e031ddbc",
      "bb6f3d2e2d6e4ed6a967ec131f867ab9",
      "31e779b2247d4d2eb61dd2b02eae7eab",
      "432e42efd0444e75adef25f69d13b8da",
      "93f680411fb74288bb48c9e5bc9bd0f3",
      "a0f5862429b84004a0c30ac936c1810e",
      "399394daaa894f34b4a59c6141512817",
      "a86fca957b9b4870adb76016b52394b7",
      "2025d0fe54994b279184517c3a752d41",
      "867224b15fe94cb5aa47d6cfa1f4c31a",
      "da4e2f5fed874d0b8f977347f4afae30",
      "51de426c20494397a60f51d13d954584",
      "1e4968f0184f450db36b948072e03195",
      "410ec90c119c4edd96876fee1d46bc31",
      "693af2078dda4291989c4773c209d954",
      "0f7b243fcf0e46559dd3d553819ae6cb",
      "bb638767a7f94696ac46192afea840a0",
      "08f500eb672a4406970d12ec44957d89",
      "267d55038a9d43e98eff5bd4580ccbfb",
      "c17a272963aa498a99072854d3000115",
      "1b82ba077e3041b9aa016382a9c0d1a3",
      "426ad1b85894449d930ccf40277a660b",
      "46c7cb37b1674b3a93a05a6462e3cd56",
      "3350023bc1ee4cf783b6fe551ceeac49",
      "3da2c5636ac741c388002a47e611450e",
      "d843b70bf07a471eb452e353e234d543",
      "f5244d1674de4ab7b5f9dbe2607aef79",
      "d96f52a4c2d74b638d3deddf59889ea7",
      "d00ece757f784813b1d6471adfa4a052",
      "539aeaa80b674ae3aa68ed53fa4f65b1",
      "64ab5ab2d286483ebda772bd6a249df3",
      "2f3e16c99ae040bcb3352915f304aacf",
      "c767b88ad4f24fad80147fe96e18d9ad",
      "c56a37cb83c34d978e8a5d2ae0db0315",
      "b046026181114674ac49f02f9a114afe",
      "5e90ee3eef0a437a8cc166f55156e914",
      "aa8c39c385114ad980c595ecf255abfa",
      "82512bd192f848538713e7cb213d3767"
     ]
    },
    "id": "uEQGwYGrtSXS",
    "outputId": "b5f43add-cfe7-4505-a5a0-95c8348341b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "887a51c86def4defad1a2a3c512e7eb1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aa50b6fb16f47aea9b4cd0adcdc79de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cff3c076b13c4dbf8f84f9b15c7d299e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfa893dacde149e09291bd2ee4d23373"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac92c7cc8c2f4ba9b829fb6ed784996c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96b31a60ebe649868091a92537b0292d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb513884c66a4f5aa5cec402db259ac3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec161434eb65497dadbe45a95ad9cbf7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e9223449bdd4c17990de5bd12aaf337"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0f5862429b84004a0c30ac936c1810e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb638767a7f94696ac46192afea840a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/13994 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d96f52a4c2d74b638d3deddf59889ea7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ubaa8\ub378 \ud559\uc2b5 \uc2dc\uc791...\n",
      "\n",
      "Epoch 1 | Train Loss: 0.9496 | Val MSE: 0.6885, RMSE: 0.8298, MAE: 0.6568, MAPE: 24.46%\n",
      "  --> \uac1c\uc120\ub428. \ubaa8\ub378 \uc800\uc7a5\ub428 (RMSE: 0.8298)\n",
      "\n",
      "Epoch 2 | Train Loss: 0.6529 | Val MSE: 0.6584, RMSE: 0.8114, MAE: 0.6423, MAPE: 23.44%\n",
      "  --> \uac1c\uc120\ub428. \ubaa8\ub378 \uc800\uc7a5\ub428 (RMSE: 0.8114)\n",
      "\n",
      "Epoch 3 | Train Loss: 0.5948 | Val MSE: 0.6187, RMSE: 0.7866, MAE: 0.6150, MAPE: 22.16%\n",
      "  --> \uac1c\uc120\ub428. \ubaa8\ub378 \uc800\uc7a5\ub428 (RMSE: 0.7866)\n",
      "\n",
      "Epoch 4 | Train Loss: 0.5306 | Val MSE: 0.5976, RMSE: 0.7731, MAE: 0.6007, MAPE: 21.42%\n",
      "  --> \uac1c\uc120\ub428. \ubaa8\ub378 \uc800\uc7a5\ub428 (RMSE: 0.7731)\n",
      "\n",
      "Epoch 5 | Train Loss: 0.4867 | Val MSE: 0.5937, RMSE: 0.7705, MAE: 0.5962, MAPE: 21.58%\n",
      "  --> \uac1c\uc120\ub428. \ubaa8\ub378 \uc800\uc7a5\ub428 (RMSE: 0.7705)\n",
      "\n",
      "Epoch 6 | Train Loss: 0.4509 | Val MSE: 0.5939, RMSE: 0.7706, MAE: 0.5932, MAPE: 20.58%\n",
      "  --> \uac1c\uc120 \uc5c6\uc74c. (1/5)\n",
      "\n",
      "Epoch 7 | Train Loss: 0.4187 | Val MSE: 0.5962, RMSE: 0.7722, MAE: 0.5934, MAPE: 21.08%\n",
      "  --> \uac1c\uc120 \uc5c6\uc74c. (2/5)\n",
      "\n",
      "Epoch 8 | Train Loss: 0.3870 | Val MSE: 0.6036, RMSE: 0.7769, MAE: 0.5972, MAPE: 20.87%\n",
      "  --> \uac1c\uc120 \uc5c6\uc74c. (3/5)\n",
      "\n",
      "Epoch 9 | Train Loss: 0.3572 | Val MSE: 0.6260, RMSE: 0.7912, MAE: 0.6002, MAPE: 22.00%\n",
      "  --> \uac1c\uc120 \uc5c6\uc74c. (4/5)\n",
      "\n",
      "Epoch 10 | Train Loss: 0.3287 | Val MSE: 0.6277, RMSE: 0.7923, MAE: 0.6037, MAPE: 21.32%\n",
      "  --> \uac1c\uc120 \uc5c6\uc74c. (5/5)\n",
      "\uc870\uae30 \uc885\ub8cc \ubc1c\uc0dd.\n",
      "\ucd5c\uc801 \ubaa8\ub378 \ub85c\ub4dc \uc644\ub8cc: best_ucam_model.pt\n",
      "\n",
      "\u2705 [UCAM] \ucd5c\uc885 \ud14c\uc2a4\ud2b8 \ud3c9\uac00 \uc9c0\ud45c:\n",
      "   - MSE  : 0.5937\n",
      "   - RMSE : 0.7705\n",
      "   - MAE  : 0.5962\n",
      "   - MAPE : 21.58%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# -------------------- Step 1: \ub370\uc774\ud130 \ub85c\ub4dc \ubc0f \uc804\ucc98\ub9ac --------------------\n",
    "data = []\n",
    "with open('/content/drive/MyDrive/review_business_5up_with_text.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['user_id', 'business_id', 'stars', 'text']]\n",
    "\n",
    "user2idx = {uid: i for i, uid in enumerate(df['user_id'].unique())}\n",
    "item2idx = {iid: i for i, iid in enumerate(df['business_id'].unique())}\n",
    "df['user'] = df['user_id'].map(user2idx)\n",
    "df['item'] = df['business_id'].map(item2idx)\n",
    "\n",
    "# -------------------- Step 2: SBERT \ubb38\ub9e5 \ubca1\ud130 \uc0dd\uc131 --------------------\n",
    "sbert = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "context_vectors = sbert.encode(df['text'].tolist(), show_progress_bar=True)\n",
    "df['context_vector'] = list(context_vectors)\n",
    "\n",
    "# -------------------- Step 3: Dataset \ud074\ub798\uc2a4 \uc815\uc758 --------------------\n",
    "class UCAMDataset(Dataset):\n",
    "    def __init__(self, users, items, ratings, contexts):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.ratings = ratings\n",
    "        self.contexts = contexts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.users[idx], dtype=torch.long),\n",
    "            torch.tensor(self.items[idx], dtype=torch.long),\n",
    "            torch.tensor(self.contexts[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.ratings[idx], dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# -------------------- Step 4: \ub370\uc774\ud130 \ubd84\ud560 --------------------\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = UCAMDataset(train_df['user'].values, train_df['item'].values,\n",
    "                            train_df['stars'].values, np.stack(train_df['context_vector']))\n",
    "test_dataset = UCAMDataset(test_df['user'].values, test_df['item'].values,\n",
    "                           test_df['stars'].values, np.stack(test_df['context_vector']))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# -------------------- Step 5: \ubaa8\ub378 \uc815\uc758 --------------------\n",
    "class UCAM(nn.Module):\n",
    "    def __init__(self, num_users, num_items, context_dim=384, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(num_users, embed_dim)\n",
    "        self.item_embed = nn.Embedding(num_items, embed_dim)\n",
    "        self.fc1 = nn.Linear(embed_dim * 2 + context_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, context_vecs):\n",
    "        u = self.user_embed(user_ids)\n",
    "        i = self.item_embed(item_ids)\n",
    "        x = torch.cat([u, i, context_vecs], dim=-1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x).squeeze()\n",
    "\n",
    "# -------------------- Step 6: \ubaa8\ub378 \ud559\uc2b5 + \uac80\uc99d + \uc870\uae30 \uc885\ub8cc --------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UCAM(num_users=len(user2idx), num_items=len(item2idx)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "epochs_no_improve = 0\n",
    "patience = 5\n",
    "min_delta = 0.001\n",
    "epochs = 50\n",
    "model_path = 'best_ucam_model.pt'\n",
    "\n",
    "print(\"\ubaa8\ub378 \ud559\uc2b5 \uc2dc\uc791...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for user_ids, business_ids, sentiment_vectors, stars in train_loader:\n",
    "        user_ids = user_ids.to(device)\n",
    "        business_ids = business_ids.to(device)\n",
    "        sentiment_vectors = sentiment_vectors.to(device)\n",
    "        stars = stars.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, business_ids, sentiment_vectors)\n",
    "        loss = criterion(predictions, stars)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # --- \uac80\uc99d ---\n",
    "    model.eval()\n",
    "    val_preds, val_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, business_ids, sentiment_vectors, stars in test_loader:\n",
    "            user_ids = user_ids.to(device)\n",
    "            business_ids = business_ids.to(device)\n",
    "            sentiment_vectors = sentiment_vectors.to(device)\n",
    "            stars = stars.to(device)\n",
    "\n",
    "            preds = model(user_ids, business_ids, sentiment_vectors)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_true.extend(stars.cpu().numpy())\n",
    "\n",
    "    val_preds = np.array(val_preds)\n",
    "    val_true = np.array(val_true)\n",
    "    val_mse = mean_squared_error(val_true, val_preds)\n",
    "    val_rmse = np.sqrt(val_mse)\n",
    "    val_mae = mean_absolute_error(val_true, val_preds)\n",
    "    val_mape = np.mean(np.abs((val_true - val_preds) / (val_true + 1e-10))) * 100\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} | Train Loss: {total_train_loss / len(train_loader):.4f} | \"\n",
    "          f\"Val MSE: {val_mse:.4f}, RMSE: {val_rmse:.4f}, MAE: {val_mae:.4f}, MAPE: {val_mape:.2f}%\")\n",
    "\n",
    "    if val_rmse < best_val_rmse - min_delta:\n",
    "        best_val_rmse = val_rmse\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"  --> \uac1c\uc120\ub428. \ubaa8\ub378 \uc800\uc7a5\ub428 (RMSE: {best_val_rmse:.4f})\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  --> \uac1c\uc120 \uc5c6\uc74c. ({epochs_no_improve}/{patience})\")\n",
    "        if epochs_no_improve == patience:\n",
    "            print(\"\uc870\uae30 \uc885\ub8cc \ubc1c\uc0dd.\")\n",
    "            break\n",
    "\n",
    "# -------------------- Step 7: \ud14c\uc2a4\ud2b8\uc14b \ud3c9\uac00 --------------------\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for users, items, contexts, ratings in data_loader:\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            contexts = contexts.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            output = model(users, items, contexts)\n",
    "            preds.extend(output.cpu().numpy())\n",
    "            targets.extend(ratings.cpu().numpy())\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    mse = mean_squared_error(targets, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((targets - preds) / (targets + 1e-10))) * 100\n",
    "\n",
    "    print(f\"\\n\u2705 [UCAM] \ucd5c\uc885 \ud14c\uc2a4\ud2b8 \ud3c9\uac00 \uc9c0\ud45c:\")\n",
    "    print(f\"   - MSE  : {mse:.4f}\")\n",
    "    print(f\"   - RMSE : {rmse:.4f}\")\n",
    "    print(f\"   - MAE  : {mae:.4f}\")\n",
    "    print(f\"   - MAPE : {mape:.2f}%\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"\ucd5c\uc801 \ubaa8\ub378 \ub85c\ub4dc \uc644\ub8cc: {model_path}\")\n",
    "\n",
    "evaluate_model(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}