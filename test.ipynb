{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlMpaCURZlni",
        "outputId": "80d47b31-7e4e-404a-ebaa-acfd511c431f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvBRguk-Zkv-",
        "outputId": "32e5fd66-bb18-48a5-eaf4-bceeb50c31df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Loss: 0.6152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Loss: 0.4874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Loss: 0.4474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Loss: 0.4139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Loss: 0.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 6] Loss: 0.3614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 7] Loss: 0.3379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 8] Loss: 0.3150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 9] Loss: 0.2932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Loss: 0.2722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 6997/6997 [00:11<00:00, 606.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.3614, RMSE: 0.4871\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Dataset 정의\n",
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        self.data = []\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                self.data.append(json.loads(line))\n",
        "\n",
        "        self.user_ids_raw = [d[\"user_id\"] for d in self.data]\n",
        "        self.item_ids_raw = [d[\"business_id\"] for d in self.data]\n",
        "        self.ratings = torch.tensor([d[\"stars\"] for d in self.data], dtype=torch.float32)\n",
        "        self.sentiments = torch.tensor([d[\"sentiment_vector\"] for d in self.data], dtype=torch.float32)\n",
        "\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.item_encoder = LabelEncoder()\n",
        "        self.user_ids = torch.tensor(self.user_encoder.fit_transform(self.user_ids_raw), dtype=torch.long)\n",
        "        self.item_ids = torch.tensor(self.item_encoder.fit_transform(self.item_ids_raw), dtype=torch.long)\n",
        "\n",
        "        self.num_users = len(self.user_encoder.classes_)\n",
        "        self.num_items = len(self.item_encoder.classes_)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.user_ids[idx], self.item_ids[idx], self.sentiments[idx], self.ratings[idx]\n",
        "\n",
        "# 모델 정의\n",
        "class RatingPredictor(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, sentiment_dim=15):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embedding_dim * 2 + sentiment_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_ids, item_ids, sentiments):\n",
        "        user_vec = self.user_embedding(user_ids)\n",
        "        item_vec = self.item_embedding(item_ids)\n",
        "        x = torch.cat([user_vec, item_vec, sentiments], dim=1)\n",
        "        return self.mlp(x).squeeze()\n",
        "\n",
        "# 파일 경로\n",
        "filepath = \"/content/drive/MyDrive/review_business_5up_5aspect_3sentiment_vectorized_clean.json\"\n",
        "dataset = RatingDataset(filepath)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저\n",
        "model = RatingPredictor(dataset.num_users, dataset.num_items)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "    for user, item, sentiment, rating in loop:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(user, item, sentiment)\n",
        "        loss = loss_fn(pred, rating)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# 평가\n",
        "model.eval()\n",
        "all_preds, all_truths = [], []\n",
        "with torch.no_grad():\n",
        "    for user, item, sentiment, rating in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "        pred = model(user, item, sentiment)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_truths.extend(rating.tolist())\n",
        "\n",
        "mae = mean_absolute_error(all_truths, all_preds)\n",
        "mse = mean_squared_error(all_truths, all_preds)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n"
      ]
    }
  ]
}